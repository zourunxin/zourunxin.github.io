<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>工具类 | Hexo</title><meta name="author" content="John Doe"><meta name="copyright" content="John Doe"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Hexo 参考从0开始搭建个人博客(详细步骤)mac os下搭建hexo+github博客hexo-theme-hikerhexo 文章加密hexo笔记：文章排序  Hexo 安装cnpm 命令无效问题问题描述在安装Hexo admin过程中，输入命令 cnpm install --save hexo-admin光标在控制器中静止不动，且无任何输出响应内容。此时按 crtl C 退出过程解决办法重">
<meta property="og:type" content="article">
<meta property="og:title" content="工具类">
<meta property="og:url" content="http://example.com/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="Hexo 参考从0开始搭建个人博客(详细步骤)mac os下搭建hexo+github博客hexo-theme-hikerhexo 文章加密hexo笔记：文章排序  Hexo 安装cnpm 命令无效问题问题描述在安装Hexo admin过程中，输入命令 cnpm install --save hexo-admin光标在控制器中静止不动，且无任何输出响应内容。此时按 crtl C 退出过程解决办法重">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/img/beijing.jpg">
<meta property="article:published_time" content="2021-10-25T04:13:44.000Z">
<meta property="article:modified_time" content="2022-06-15T09:58:01.718Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/beijing.jpg"><link rel="shortcut icon" href="/img/touxiang.jpg"><link rel="canonical" href="http://example.com/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '工具类',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-06-15 17:58:01'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/background.css"><meta name="generator" content="Hexo 5.4.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">3</div></a></div></div></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/beijing.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Hexo</a></span><div id="menus"><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">工具类</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2021-10-25T04:13:44.000Z" title="Created 2021-10-25 12:13:44">2021-10-25</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2022-06-15T09:58:01.718Z" title="Updated 2022-06-15 17:58:01">2022-06-15</time></span></div><div class="meta-secondline"></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Hexo"><a href="#Hexo" class="headerlink" title="Hexo"></a>Hexo</h1><blockquote>
<p>参考<br><a target="_blank" rel="noopener" href="https://blog.csdn.net/hutongxue434/article/details/106181590">从0开始搭建个人博客(详细步骤)</a><br><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/49c8168c7418">mac os下搭建hexo+github博客</a><br><a target="_blank" rel="noopener" href="https://github.com/iTimeTraveler/hexo-theme-hiker/blob/master/README.cn.md">hexo-theme-hiker</a><br><a target="_blank" rel="noopener" href="https://www.itfanr.cc/2021/04/16/hexo-blog-article-encryption/">hexo 文章加密</a><br><a target="_blank" rel="noopener" href="https://gsy00517.github.io/hexo20200207151318/">hexo笔记：文章排序</a></p>
</blockquote>
<h2 id="Hexo-安装"><a href="#Hexo-安装" class="headerlink" title="Hexo 安装"></a>Hexo 安装</h2><h3 id="cnpm-命令无效问题"><a href="#cnpm-命令无效问题" class="headerlink" title="cnpm 命令无效问题"></a>cnpm 命令无效问题</h3><p><strong>问题描述</strong><br>在安装Hexo admin过程中，输入命令 <code>cnpm install --save hexo-admin</code><br>光标在控制器中静止不动，且无任何输出响应内容。此时按 <code>crtl C</code> 退出过程<br><strong>解决办法</strong><br>重新输入代码：<code>npm config set registry http://registry.cnpmjs.org</code><br>再重新运行 <code>hexo admin</code> 安装指令即可</p>
<h2 id="Hexo-终端命令"><a href="#Hexo-终端命令" class="headerlink" title="Hexo 终端命令"></a>Hexo 终端命令</h2><ul>
<li>启动Hexo服务器：<code>hexo s</code></li>
<li>新建博客（需先进入hexo所在文件夹）<code>hexo n &quot;博客名&quot;</code></li>
<li>将仓库更新到github上<br>分成两步：<ol>
<li>生成静态文件 <code>hexo g</code></li>
<li>部署到远端服务器 <code>hexo d</code>。但会出现更新不及时的情况，即在github上的更新内容需过一段时间后才显示</li>
</ol>
</li>
</ul>
<h2 id="Hexo-相关报错"><a href="#Hexo-相关报错" class="headerlink" title="Hexo 相关报错"></a>Hexo 相关报错</h2><ul>
<li>hexo d中报443Time out错误，尝试翻墙解决</li>
<li>hexo d中报Connection was reset, errno 10054，使用hexo clean、hexo g、hexo d重走一套流程解决</li>
<li>若本机过久没和 github 建立连接，则会连接失败 <code>Connection was reset, errno 10054</code>。重新请求 ssh key 并更新到 github 即可。<a target="_blank" rel="noopener" href="https://blog.csdn.net/Candle_light/article/details/114992784">生成新 shh key 并连接到 github</a></li>
<li>若 github 仓库为私有，再变为公有后访问，仍会出现 404。解决办法是删除原仓库，重新生成新的仓库，重新 hexo d 推送。</li>
<li><code>hexo d</code> 中报错 <code>ERROR Deployer not found: git</code>，在站点目录下通过 <code>npm install hexo-deployer-git --save</code> 安装 hexo-deployer-git 插件即可。<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_21808961/article/details/84476504">ERROR Deployer not found: git</a></li>
</ul>
<hr>
<h1 id="Markdown"><a href="#Markdown" class="headerlink" title="Markdown"></a>Markdown</h1><blockquote>
<p>参考<br><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/399e5a3c7cc5">.MD语法入门</a><br><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/de9c98bba332">Markdown语法</a><br><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/75028c4adfcf">Markdown 实现”多级有序列表”(非完美)</a><br><a target="_blank" rel="noopener" href="https://xianbai.me/learn-md/index.html">Learning-Markdown (Markdown 入门参考)</a></p>
</blockquote>
<h2 id="md-语法"><a href="#md-语法" class="headerlink" title="md 语法"></a>md 语法</h2><p><strong>md 插入图片的第四种方法</strong></p>
<ol>
<li>在blog全局配置文件_config.yml更改设置：<code>post_asset_folder: true</code></li>
<li>当该配置被应用后，使用hexo new命令创建新文章时，会生成相同名字的文件夹，也就是文章资源文件夹。在md文件中输入以下代码可成功引入图片：<code>&#123;% asset_img image.jpg 这是一张图片 %&#125;</code></li>
</ol>
<p><strong>md 使用多级列表</strong><br>一级列表正常；二级列表：空格 + tab</p>
<p><strong>md 段落内换行</strong></p>
<ul>
<li>在要换行的地方输入<code>&lt;br&gt;</code>（该方法使用表格内换行）</li>
<li>在要换行的地方输入两个空格，再换行</li>
</ul>
<p><strong>表格内指定表格宽度</strong></p>
<ul>
<li>在表格内添加<code>&lt;img width=200/&gt;</code>标签，标签后面接要输入的文本</li>
</ul>
<p><strong>行内添加空格</strong></p>
<ul>
<li>插入一个空格：<code>&amp;nbsp;</code> 或 <code>&amp;#160;</code></li>
<li>插入两个空格：<code>&amp;ensp;</code> 或 <code>&amp;#8194;</code></li>
<li>插入四个空格：<code>&amp;emsp;</code> 或 <code>&amp;#8195;</code></li>
</ul>
<p><strong>插入一行可横向滑动的框框</strong></p>
<ul>
<li>换行 + tab</li>
</ul>
<p><strong>删除线</strong></p>
<ul>
<li><del>aaaaa</del></li>
</ul>
<hr>
<h1 id="终端命令"><a href="#终端命令" class="headerlink" title="终端命令"></a>终端命令</h1><h2 id="Win"><a href="#Win" class="headerlink" title="Win"></a>Win</h2><blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/67513308">win 常用命令</a></p>
</blockquote>
<ul>
<li>win 从终端进入移动硬盘：<code>F:</code></li>
<li>文件夹开头带 . 即为隐藏文件夹（mac 和 win 都是，但 mac 仅能通过终端 mkdir 创建该类型文件夹）。mac 显示隐藏文件夹快捷键 <code>shift + command + .</code></li>
<li>win 进入终端：<code>win + R</code> -&gt; 输入 cmd；</li>
<li>win 指定文件夹下进入终端：<ul>
<li>在当前文件夹下，按住 shift 键 + 鼠标右击</li>
<li>在文件夹地址栏输入 cmd</li>
</ul>
</li>
</ul>
<h1 id="Mac"><a href="#Mac" class="headerlink" title="Mac"></a>Mac</h1><ul>
<li>mac 从终端进入移动硬盘：<code>cd ../</code> -&gt; <code>cd volumes</code>，即可看到移动硬盘目录。</li>
<li>mac 运行 shell 脚本 <code>./***.sh</code>。</li>
</ul>
<hr>
<h1 id="Maven"><a href="#Maven" class="headerlink" title="Maven"></a>Maven</h1><blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_15192373/article/details/103263150?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522164879050116781685347957%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=164879050116781685347957&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm_bkp-1-103263150.142%5Ev5%5Epc_search_quality_down&utm_term=win+maven+%E5%AE%89%E8%A3%85&spm=1018.2226.3001.4187">Win 下 maven 安装配置</a></p>
</blockquote>
<h2 id="maven-命令"><a href="#maven-命令" class="headerlink" title="maven 命令"></a>maven 命令</h2><ol>
<li><p>mvn clean：删除工程下的 target 目录。</p>
</li>
<li><p>mvn compile：编译主程序，生成 classes 目录，放到 target 目录下。</p>
</li>
<li><p>mvn test-compile：编译测试程序，生成 test-classes 目录，放到 target 目录下。</p>
</li>
<li><p>mvn test：执行工程 test 目录下的测试类，生成 surefire-reports 测试报告目录，放到 target 目录下。</p>
</li>
<li><p>mvn package：打包工程，java 工程生成 jar 包，web 工程生成 war 包，放在 target 目录下。</p>
</li>
<li><p>mvn install：安装工程，将生成的 jar 包放在本地仓库中。</p>
<p><strong>target 目录是执行命令时自动生成的目录，和 pom.xml 在同一级目录下。</strong></p>
</li>
<li><p>mvn deploy（jar 包部署到远端）：</p>
<ol>
<li>该命令可以将 maven 所打的 jar 包上传到远程的 repository，比如公司的 maven 私服，方便整个公司或其他人使用。</li>
<li><code>mvn deploy:deploy-file -DgroupId=com.vip.vfc -DartifactId=common -Dversion=1.0.0 -Dpackaging=jar -Dfile=E:\common.jar -Durl=http://localhost:8081/nexus/content/repositories/releases -DrepositoryId=releases</code></li>
</ol>
</li>
<li><p>mvn dependency:tree/list（查看项目依赖，冒号前是插件，冒号后是插件的目标）：</p>
<ol>
<li>list 以列表形式展示项目依赖；</li>
<li>tree 以树状结构展示项目依赖，层次比较清晰。</li>
</ol>
<p><code>mvn dependency:tree -DoutputFile=dependency.tree</code> 输出依赖树到 <code>dependency.tree</code> 文件中。</p>
</li>
<li><p>mvn dependency:analyze（查看未显示声明/使用的依赖）：</p>
<ol>
<li>Used undeclared dependencies：使用了没有显示声明的依赖（可能是潜在的风险）；</li>
<li>Unused declared dependencies：没有显示使用的依赖（不必要的依赖）。</li>
</ol>
</li>
</ol>
<h2 id="Maven-语法"><a href="#Maven-语法" class="headerlink" title="Maven 语法"></a>Maven 语法</h2><blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/sq_better/article/details/54630810">maven 语法详解 pom</a></p>
</blockquote>
<p><strong>settings 语法</strong></p>
<ul>
<li><p>maven 修改本地仓库地址 <code>&lt;localRepository&gt;D:/repository&lt;/localRepository&gt;</code>。</p>
</li>
<li><p>maven 配置 mirror </p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">mirrors</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mirror</span>&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">id</span>&gt;</span>alimaven<span class="tag">&lt;/<span class="name">id</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>aliyun maven<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://maven.aliyun.com/nexus/content/groups/public/<span class="tag">&lt;/<span class="name">url</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>central<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mirrors</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>pom 语法</strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--父项目的坐标。继承父项目后，当前项目写依赖就不用写版本号。多用来做依赖管理--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">parent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span> <span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>   <span class="comment">&lt;!--被继承的父项目的构件标识符（项目名）--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span> <span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>   <span class="comment">&lt;!--被继承的父项目的全球唯一标识符--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span> <span class="tag">&lt;/<span class="name">version</span>&gt;</span>   <span class="comment">&lt;!--被继承的父项目的版本--&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--声明项目描述符遵循哪一个 POM 模型版本。虽然模型版本本身很少改变，但它仍然是必不可少的，这是为了当 Maven 引入了新的特性或者其他模型变更的时候，确保稳定性。--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--项目的全球唯一标识符，通常使用全限定的包名区分该项目和其他项目。并且构建时生成的路径也是由此生成， 如 com.mycompany.app 生成的相对路径为：com/company/deparment/test--&gt;</span>    </span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.company.deparment.test<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--构件的标识符，它和 group ID 一起唯一标识一个构件。换句话说，你不能有两个不同的项目拥有同样的 artifact ID 和 groupID；在某个特定的 group ID 下，artifact ID 也必须是唯一的。构件是项目产生的或使用的一个东西，Maven 为项目产生的构件包括：JARs，源码，二进制发布和 WARs 等。--&gt;</span>    </span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-learning<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--该元素描述了项目相关的所有依赖。这些依赖组成了项目构建过程中的一个个环节。它们自动从项目定义的仓库中下载。要获取更多信息，请看项目依赖机制。--&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span>   </span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span>   <span class="comment">&lt;!--各个依赖--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span> <span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>   <span class="comment">&lt;!--依赖在仓库里的 group ID--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span> <span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>   <span class="comment">&lt;!--依赖在仓库里的 artifact ID--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span> <span class="tag">&lt;/<span class="name">version</span>&gt;</span>   <span class="comment">&lt;!--被使用的依赖的版本（或版本范围）--&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--当计算传递依赖时，从依赖构件列表里，列出被排除的依赖构件集。即告诉maven你只依赖指定的项目，不依赖项目的依赖。此元素主要用于解决版本冲突问题--&gt;</span>   </span><br><span class="line">        <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span>  </span><br><span class="line">            <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span>    </span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>    </span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>    </span><br><span class="line">            <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span>    </span><br><span class="line">        <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span>      </span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span>        </span><br></pre></td></tr></table></figure>

<h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><ol>
<li>maven 的依赖如果也有依赖，则根据依赖传递原则，maven 会把依赖的依赖 jar 包也导入当前工程。</li>
</ol>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><ol>
<li><p>mvn 语法报错：<code>Could not transfer artifact com.bytedance:base-dependencies:pom:1.0.0 from/to maven-default-http-blocker (http://0.0.0.0/): Blocked mirror for repositories: [nexus-snapshots (http://ewd.byted.org/nexus/proxy/public/, default, releases+snapshots)]</code><br>因为 maven-3.8.1 限制了使用 http 拉取仓库依赖，而公司由于使用内网所以大多数网址都是 http 的，这就导致在内网环境下无法拉取仓库。设置 setting.xml，删除如下代码可跳过该报错：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">id</span>&gt;</span>maven-default-http-blocker<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>external:http:*<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">name</span>&gt;</span>Pseudo repository to mirror external repositories initially using HTTP.<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://0.0.0.0/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">blocked</span>&gt;</span>true<span class="tag">&lt;/<span class="name">blocked</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>项目在 clean、package 后，仍 import 报错的情况。（pom 文件也有无端报错）<br>通过修改 pom 文件，重新”load maven changes”；把修改去除，再重新”load maven changes”，可修复。</p>
</li>
</ol>
<h2 id="Gradle"><a href="#Gradle" class="headerlink" title="Gradle"></a>Gradle</h2><blockquote>
<p>参考：<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/01702897eeb4" title="简书">Gradle依赖引入</a></p>
</blockquote>
<h3 id="引入依赖基本方式"><a href="#引入依赖基本方式" class="headerlink" title="引入依赖基本方式"></a>引入依赖基本方式</h3><p>理论上gradle支持三种类型的引用（在 build.gradle 文件下），方式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">dependencies &#123;</span><br><span class="line"></span><br><span class="line">    implementation project(&#x27;:projectABC&#x27;)   // 本地项目依赖</span><br><span class="line"></span><br><span class="line">    implementation fileTree(dir: &#x27;libs&#x27;, include: [&#x27;*.jar&#x27;])   // 本地二进制依赖</span><br><span class="line"></span><br><span class="line">    implementation &#x27;androidx.appcompat:appcompat:1.0.2&#x27;   // 远端二进制依赖</span><br><span class="line">    implementation  group: &#x27;androidx.appcompat&#x27;, name:&#x27;appcompat&#x27;, version:&#x27;1.0.2&#x27;   // 远端二进制依赖完整写法</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="配置Gradle使用maven本地仓库"><a href="#配置Gradle使用maven本地仓库" class="headerlink" title="配置Gradle使用maven本地仓库"></a>配置Gradle使用maven本地仓库</h3><ul>
<li><p>这样Gradle就不会重新下载已经存在maven本地仓库的jar包，从而节省时间和空间。</p>
</li>
<li><p>在环境变量中加入新的系统变量：GRADLE_USER_HOME，变量值是maven本地仓库的路径，本文为例D:\Software\Maven\repository</p>
</li>
<li><p>此时，Gradle下载的文件将放到指定的仓库路径中。但是还需要修改build.gradle文件中加入mavenLocal() 引用本地仓库</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">repositories &#123;   <span class="comment">//repositories闭包</span></span><br><span class="line">  mavenLocal()   <span class="comment">//配置先从本地仓库寻找jar包，优先寻找上一个配置，找到不执行下面的配置</span></span><br><span class="line">  mavenCentral()   <span class="comment">//配置从中央仓库寻找</span></span><br><span class="line">  google()   <span class="comment">//第三方仓库</span></span><br><span class="line">  jcenter()   <span class="comment">//代码托管库：设置之后可以在项目中轻松引用jcenter上的开源项目</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<hr>
<h1 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h1><blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/default7/article/details/100068256">git 设置代理的方法</a></p>
</blockquote>
<h2 id="远程分支"><a href="#远程分支" class="headerlink" title="远程分支"></a>远程分支</h2><ul>
<li><p><code>git clone [ssh] [filename]</code>：下载默认分支，filename 是文件下载到本地后的重命名。</p>
</li>
<li><p><code>git clone -b [remote branch] [ssh]</code>，下载指定分支。</p>
</li>
<li><p>将远程分支更新到本地所在分支：</p>
<ul>
<li><p>默认远程同名分支：<code>git pull</code></p>
</li>
<li><p>指定远程分支：<code>git pull origin [remote branch]</code>。</p>
</li>
</ul>
</li>
<li><p><code>git pull [-f] origin [remote branch]:[local branch]</code>，更新远程指定分支到本地指定分支（已存在），<code>-f</code> 表示强制更新。</p>
</li>
<li><p><code>git fetch origin [remote branch]:[local branch]</code>，下载远程分支到本地指定分支（若不存在则新创建本地分支）。</p>
</li>
<li><p><code>git push origin --delete [remote branch]</code>：删除远程指定分支。</p>
</li>
</ul>
<h2 id="本地分支"><a href="#本地分支" class="headerlink" title="本地分支"></a>本地分支</h2><ul>
<li><p><code>git init</code>：初始化本地文件夹为 git 可管理的仓库。</p>
</li>
<li><p><code>git remote add origin [ssh]</code>：本地仓库与远程仓库关联。</p>
</li>
<li><p><code>git branch -m [oldName] [newName]</code>：重命名本地分支。</p>
</li>
<li><p><code>git branch [new branch]</code>：创建新分支，但 head 指针不移动。</p>
</li>
<li><p><code>git checkout -b [branch]</code>：新建且 head 指针切换到该分支。</p>
</li>
<li><p><code>git checkout -b [new branch] origin/[remote branch]</code>：拉取远程分支到本地指定新分支，且 head 指针移动到新分支上。</p>
</li>
<li><p><code>git log [--oneline]</code>，打印 commit 历史，<code>--oneline</code> 表示每条历史仅显示一行。</p>
</li>
<li><p><code>git status</code>：查看当前分支修改情况。</p>
</li>
<li><p><code>git checkout .</code>：撤销当前分支所有未提交（add）的修改。</p>
</li>
<li><p><code>git checkout [filename]</code>：撤销当前分支对指定文件的修改。</p>
</li>
<li><p><code>git stash</code>：保存当前分支的工作内容。</p>
</li>
<li><p><code>git stash pop</code>：恢复当前分支最近一次 stash 的内容。</p>
</li>
<li><p><code>git reset --soft [commitHash]</code>：回退 commit message 历史到指定位置，但保留代码修改。</p>
</li>
<li><p><code>git reset --hard [commitHash]</code>：回退  head 指针到指定 commit 位置处。</p>
</li>
<li><p><code>git diff [local branch]</code>：比较当前分支与指定分支。</p>
</li>
<li><p>合并分支并保持 commit 历史呈线性，假设目前需将 feat02 合并到 feat01 分支：</p>
<ul>
<li><p><code>git checkout feat02</code>；</p>
</li>
<li><p><code>git rebase feat01</code>，此时 feat02 处于 feat01 之后，head 指向 feat02；</p>
</li>
<li><p><code>git checkout feat01</code>；</p>
</li>
<li><p><code>git merge feat02</code>：此时 feat01 与 feat02 合并，head 指针指向 feat01。</p>
<p><em>不推荐使用 <code>git merge [branch]</code>，因为它是在当前分支新建了一个连接上游两个分支的合并节点。</em></p>
</li>
</ul>
</li>
<li><p><code>git push [-f] origin [local branch]:[remote branch]</code>：推送本地指定分支到远程指定分支。不推荐使用 <code>-f</code>，因为会令远程托管仓库该分支的 commit 历史消失。</p>
</li>
<li><p><code>git branch -d [local branch]</code>：删除本地指定分支。</p>
</li>
<li><p><code>git reflog</code>：</p>
</li>
<li><p><code>git rebase -i [commitHash]</code>：</p>
</li>
</ul>
<h2 id="Github"><a href="#Github" class="headerlink" title="Github"></a>Github</h2><ol>
<li>目前终端登录 github 不再使用账号密码，而是用的 github 生成的 token（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），这个 token 会一直有效，在 mac 中的“钥匙串访问”中配置。</li>
<li>这个 token 在使用了 git 后不能再应用在 hexo 中（应用在 hexo 时“钥匙串访问“中该 token 会消失），采用新建 token 解决</li>
</ol>
<hr>
<h1 id="IDEA"><a href="#IDEA" class="headerlink" title="IDEA"></a>IDEA</h1><ol>
<li><p>从 git 新下载仓库，idea 打开后 build 无错误，但代码中 import 错误。分两种情况讨论：</p>
<ol>
<li>若 import 的是同一项目空间内代码报错，可能是 idea 缓存索引错误。在 file -&gt; invalidate caches 中，清除 idea 缓存，重启后即可；</li>
<li>若 import 的是不同项目空间内代码报错，可能是没有相应 jar 包。通过报错空间（或 root 空间）maven 工具的 clean、package，打包新的 jar 包，即可。</li>
</ol>
</li>
<li><p>mac：<code>control + option + H</code> 查看方法调用链，鼠标需放置在方法上。</p>
</li>
<li><p>idea debug 停在抛出指定异常的位置 <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_35193093/article/details/83002360">idea 锁定抛异常位置</a>。</p>
</li>
<li><p>idea 导入依赖失败，External Libraries 里不含 pom.xml 指示的依赖：点击右侧 Maven 的“+”，选中工程的 pom.xml 手动导入。</p>
</li>
<li><p>进入接口实现类快捷键：</p>
<ul>
<li><p>win：ctrl + alt + B；</p>
</li>
<li><p>mac：command + shift + B。</p>
</li>
</ul>
</li>
</ol>
<p>6- <code>ctrl + shift + r</code>：批量替换字符。</p>
<hr>
<h1 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h1><blockquote>
<p>幂等性：一个幂等操作的特点是执行一次或执行多次所产生的影响和执行一次所产生的影响相同<br><a target="_blank" rel="noopener" href="https://www.1024sou.com/article/542603.html">Kafka 原理分析之基础篇</a></p>
</blockquote>
<h2 id="Kafka-是什么"><a href="#Kafka-是什么" class="headerlink" title="Kafka 是什么"></a>Kafka 是什么</h2><p>Kafka 是一个分布式流式处理平台，拥有高吞吐（但不支持 topic 消息有序）、可持久化、可水平扩展、支持流数据处理等特性。<br><strong>整体可划分三个模块：</strong>  </p>
<ol>
<li>消息系统</li>
<li>存储系统</li>
<li>流式处理平台</li>
</ol>
<p><strong>典型结构</strong><br>一个典型的 kafka 体系架构包括若干 producer、若干 broker、若干 consumer，以及一个 ZooKeeper 集群。</p>
<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/kafka_1.jpg" class="">

<h2 id="ZooKeeper"><a href="#ZooKeeper" class="headerlink" title="ZooKeeper"></a>ZooKeeper</h2><p>ZooKeeper 负责 Kafka 集群元数据的管理、控制器的选举等操作。</p>
<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/Kafka_2.jpg" class="">

<h2 id="Producer"><a href="#Producer" class="headerlink" title="Producer"></a>Producer</h2><p>生产者，将消息发送到 Broker。</p>
<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/Kafka_3.jpg" class="">
<p>构造生产者及生产消息示例代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaProducerAnalysis</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String brokerList = <span class="string">&quot;localhost:9092&quot;</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String topic = <span class="string">&quot;topic-demo&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Properties <span class="title">initConfig</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);   <span class="comment">// broker 地址</span></span><br><span class="line">        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        props.put(ProducerConfig.CLIENT_ID_CONFIG, <span class="string">&quot;producer.client.id.demo&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> props;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Properties props = initConfig();</span><br><span class="line">        KafkaProducer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);</span><br><span class="line">        ProducerRecord&lt;String, String&gt; record = <span class="keyword">new</span> ProducerRecord&lt;&gt;(topic, <span class="string">&quot;hello, Kafka!&quot;</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            producer.send(record);   <span class="comment">// 返回类型为 Future&lt;RecordMetadata&gt;</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其中 ProducerRecord 的成员变量如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProducerRecord</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String topic;   <span class="comment">// 主题（必填）</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Integer partition;   <span class="comment">// 分区号</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Headers;   <span class="comment">// 消息头部</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> K key;   <span class="comment">// 键</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span>  V value;   <span class="comment">// 值（必填）</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Long timestamp;   <span class="comment">// 消息的时间戳</span></span><br><span class="line">    <span class="comment">// 省略其他成员方法和构造方法</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Producer-参数配置"><a href="#Producer-参数配置" class="headerlink" title="Producer 参数配置"></a>Producer 参数配置</h3><table>
<thead>
<tr>
<th align="center">参数</th>
<th align="center">含义</th>
<th align="center">默认值</th>
<th align="center">是否必填</th>
<th align="center">备注</th>
</tr>
</thead>
<tbody><tr>
<td align="center">bootstrap.servers</td>
<td align="center">指定生产者客户端连接 kafka 集群所需的 broker 地址清单，如 host1:port1, host2:port2</td>
<td align="center">“”</td>
<td align="center">是</td>
<td align="center">并非需要所有 broker 的地址，但设置至少两个及以上</td>
</tr>
<tr>
<td align="center">key.serializer 和 value.serializer</td>
<td align="center">broker 端接收的消息必须以字节数组(byte[])的形式存在。这两个参数分别用来指定 key 和 value 序列化操作的序列化器，以将 key 和 value 转化为字节数组</td>
<td align="center">无</td>
<td align="center">是</td>
<td align="center">需填写序列化器的全限定名，也可写成 StringSerializer.class.getName()</td>
</tr>
<tr>
<td align="center">client.id</td>
<td align="center">设定 KafkaProducer 对应的客户端 id</td>
<td align="center">“”</td>
<td align="center">否</td>
<td align="center">若不填，KafkaProducer 会自动生成形如“producer-1“的非空字符串</td>
</tr>
<tr>
<td align="center">acks</td>
<td align="center">指定分区中必须要有多少个副本收到这条消息，之后生产者才认为这条消息是成功写入的</td>
<td align="center">1</td>
<td align="center">否</td>
<td align="center">acks 参数类型需是字符串。可为 1、0、(-1 和 all)（都是等待所有副本成功写入才能收到服务端的响应</td>
</tr>
<tr>
<td align="center">max.request.size</td>
<td align="center">指定生产者客户端能发生的消息的最大值</td>
<td align="center">1048576B，即 1MB</td>
<td align="center"></td>
<td align="center">一般来说，默认值即足够满足多数场景，若要修改该参数，需同时修改 broker 端的 message.max.bytes 参数</td>
</tr>
<tr>
<td align="center">retries</td>
<td align="center">用来配置生产者重试的次数</td>
<td align="center">0</td>
<td align="center"></td>
<td align="center">默认在发生异常的时候不进行任何重试动作。重试可以解决如网络抖动、leader 副本选举带来的异常</td>
</tr>
<tr>
<td align="center">retry.backoff.ms</td>
<td align="center">设定两次重试之间的时间间隔</td>
<td align="center">100</td>
<td align="center"></td>
<td align="center">与 retries 参数搭配使用。需注意不能设置太小导致无效的频繁重试，不能设置太大导致生产者过早放弃重试</td>
</tr>
<tr>
<td align="center">compression.type</td>
<td align="center">指定消息的压缩方式</td>
<td align="center">none</td>
<td align="center"></td>
<td align="center">该参数还可以配置为“gzip”、“snappy”和“lz4”。消息压缩是一种使用时间换空间的优化方式</td>
</tr>
<tr>
<td align="center">connections.max.idle.ms</td>
<td align="center">指定在多久之后关闭限制的连接</td>
<td align="center">540000ms，即 9min</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">linger.ms</td>
<td align="center">指定生产者发生 ProducerBatch 之前等待更多消息（ProducerRecord）加入 ProducerBatch 的时间</td>
<td align="center">0</td>
<td align="center"></td>
<td align="center">生产者客户端会在 ProducerBatch 被填满或等待时间超过 linger.ms 值时发生出去。增大这个参数会增加消息的延迟，但能提升一定的吞吐量，该参数与 TCP 中的 Nagle 算法有异曲同工之妙</td>
</tr>
<tr>
<td align="center">receive.buffer.bytes</td>
<td align="center">设置 Socket 接收消息缓冲区（SO_RECBUF)的大小</td>
<td align="center">32768B，即 32KB</td>
<td align="center"></td>
<td align="center">若该值设为 -1，则使用操作系统的默认值</td>
</tr>
<tr>
<td align="center">send.buffer.bytes</td>
<td align="center">设置 Socket 发送消息缓冲区（SO_SNDBUF)的大小</td>
<td align="center">131072B，即 128KB</td>
<td align="center"></td>
<td align="center">若该值设为 -1，则使用操作系统的默认值</td>
</tr>
<tr>
<td align="center">request.timeout.ms</td>
<td align="center">配置 Producer 等待请求响应的最长时间</td>
<td align="center">30000(ms)</td>
<td align="center"></td>
<td align="center">请求超时之后可以选择进行重试。该参数需要比 broker 端参数 replica.lag.time.max.ms 值要大，这样可以减少因客户端重试而引起的消息重复的概率</td>
</tr>
</tbody></table>
<h3 id="batch-调优"><a href="#batch-调优" class="headerlink" title="batch 调优"></a>batch 调优</h3><table>
<thead>
<tr>
<th align="left">参数</th>
<th align="left">默认值</th>
<th align="left">取值范围</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left">batch.size</td>
<td align="left">16K</td>
<td align="left">&gt;=0</td>
<td align="left">单个parition对应的batch大小（bytes），缓存消息达到batch size之后，立即发送</td>
</tr>
<tr>
<td align="left">linger.ms</td>
<td align="left">0ms</td>
<td align="left">&gt;=0</td>
<td align="left">消息在batch中停留时间，达到linger.ms之后，立即发送</td>
</tr>
<tr>
<td align="left">buffer.memory</td>
<td align="left">32M</td>
<td align="left">&gt;=0</td>
<td align="left">producer缓存消息，总的可用memory空间，如果memory用完，produder会立刻发送缓存中的消息</td>
</tr>
</tbody></table>
<p><strong>如何设置参数</strong><br>linger.ms = 业务能接受的延迟，比如 1000ms，5000ms<br>batch.size = 单个 producer 的消息 qps * 消息大小 * linger.ms / partition 数<br>buffer.memory &gt;= batch.size * partition数 * 2；buffer.memory 较小，可能会造成 batch 失效，qps 反而更高</p>
<p><strong>监控</strong></p>
<ul>
<li>消息入流 qps、消息出流 qps；</li>
<li>请求 qps；</li>
<li>batch size 大小（消息条数）；</li>
</ul>
<h3 id="生产者分区策略"><a href="#生产者分区策略" class="headerlink" title="生产者分区策略"></a>生产者分区策略</h3><p>分区策略：决定生产者将消息发送到哪个分区的算法，Kafka提供了默认的分区策略，也支持自定义的分区策略。<a target="_blank" rel="noopener" href="https://juejin.cn/post/7035413272786370573">生产者分区策略</a></p>
<ol>
<li>轮询策略，也称 Round-robin 策略，即顺序分配。<ol>
<li>轮询策略是 Kafka Java 生产者 API 默认提供的分区策略；</li>
<li>轮询策略的负载均衡表现非常优秀，总能保证消息最大限度地被平均分配到所有分区上，默认情况下它是最合理的分区策略。</li>
</ol>
</li>
<li>随机策略，也称 Randomness 策略。所谓随机就是我们随意地将消息放置到任意一个分区上，消息均匀性要逊于轮询策略。事实上，随机策略是老版本生产者使用的分区策略，在新版本中已经改为轮询了。</li>
<li>按消息键保序策略，也称 Key-ordering 策略。<ol>
<li>Kafka 允许为每条消息定义消息键，简称为 Key；</li>
<li>Key 可以是一个有明确业务含义的字符串：客户代码、部门编号、业务ID、用来表征消息的元数据等；</li>
<li>一旦消息被定义了 Key，可以保证同一个 Key 的所有消息都进入到相同的分区里。</li>
</ol>
</li>
</ol>
<h3 id="其它-1"><a href="#其它-1" class="headerlink" title="其它"></a>其它</h3><ul>
<li>KafkaProducer 是线程安全的，可以在多个线程中共享单个 KafkaProducer 实例，也可以将 KafkaProducer 实例进行池化供其他线程调用。</li>
<li>若在创建 KafkaProducer 实例时没有设定 key/value.serializer 这两个配置参数，那么就需要在构造方法中添加对应的序列化器。如<code>KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props, new StringSerializer(), new StringSerializer());</code></li>
<li>生产者客户端的整体架构<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/kafka_5.jpg" class=""></li>
</ul>
<h2 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a>Broker</h2><p>服务代理节点。负责将收到的消息存储到磁盘中。一个或多个 Broker 组成了一个 Kafka 集群。</p>
<h3 id="offset-维护"><a href="#offset-维护" class="headerlink" title="offset 维护"></a>offset 维护</h3><p>在 0.9 版本之前，kafka 默认将 offset 保存在 Zookeeper 中。<br>从 0.9 版本开始，kafka 默认将 offset 保存在一个内置的名为 __consumer_offsets 的 topic 中，以 Consumer Group、Topic、Partition 组成的 key 记录 offset。</p>
<h3 id="主副本间数据同步"><a href="#主副本间数据同步" class="headerlink" title="主副本间数据同步"></a>主副本间数据同步</h3><p><a target="_blank" rel="noopener" href="https://juejin.cn/post/6997058157432274974#heading-1">kafka 是如何保障副本间数据一致的</a> | <a target="_blank" rel="noopener" href="https://www.jianshu.com/p/f9a825c0087a">kafka:replica 副本同步机制</a><br>LEO：标示每个分区中下一条消息的写入点，每一个分区副本都有自己的 LEO。<br>HW：HighWatermark，ISR 中最小的 LEO，俗称高水位，消费者只能拉取 HW 之前的代码。且每个 replica 都有自己的 HW。<br>leader 与 follower 间数据同步：</p>
<ol>
<li>follower 定时与 leader 进行数据同步，若较长时间 leader 没有新消息 fetch，follower 会阻塞，直到 leader 有新消息写入再唤醒。</li>
<li>follower 发出 fetch 请求，里面装有 LEO。</li>
<li>leader 根据 followers 的 LEO，更新 HW。</li>
<li>leader 发送 LEO 及之后的消息、HW 给 follower。</li>
<li>follower 写入 leader 同步的新消息，更新 LEO 和 HW。</li>
<li>重复 2。</li>
</ol>
<h2 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h2><p>消费者，接收信息的一方。负责从 Broker 订阅并消费消息（基于拉模式）。</p>
<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/Kafka_4.jpg" class="">

<h3 id="消费模式"><a href="#消费模式" class="headerlink" title="消费模式"></a>消费模式</h3><p>消费者采用 pull（拉）模式从 broker 中读取数据。<br><strong>为什么不采用 push（推）的模式给消费者数据呢？</strong><br>比如一个 broker 有多个消费者，它们的消费速率不同，一昧的 push 只会给消费者带来拒绝服务以及网络拥塞等风险。而 kafka 显然不能放弃速率低的消费者，因此 kafka 采用了pull 的模式，可以根据消费者的消费能力以适当的速率消费 broker 里的消息。<br>为了避免 kafka 中没有数据时消费者不断 pull - 返回空数据的循环中，Kafka 消费者在消费数据时会被传入一个时长参数 timeout，如果当前没有数据可供消费，kafka 会等待一段时间之后再返回，这段时长即为 timeout。</p>
<h3 id="分区分配策略"><a href="#分区分配策略" class="headerlink" title="分区分配策略"></a>分区分配策略</h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000038712658">消费者消费方式、三种分区分配策略、offset维护</a></p>
</blockquote>
<p><strong>前提条件：</strong></p>
<ol>
<li>kafka 设定了默认的消费逻辑：一个分区只能被同一个消费组（ConsumerGroup）内的一个消费者消费。</li>
<li>kafka 提供了消费者客户端参数 partition.assignment.strategy 用来设置消费者与订阅主题之间的分区分配策略。默认情况下，此参数的值为：org.apache.kafka.clients.consumer.RangeAssignor，即采用 range 分配策略。</li>
</ol>
<p><strong>Range 分配策略</strong><br>Range 分配策略是<strong>面向每个主题</strong>的，首先会对同一个主题里面的分区按照序号进行排序，并把消费者线程按照字母顺序进行排序。然后用分区数除以消费者线程数量来判断每个消费者线程消费几个分区。如果除不尽，那么前面几个消费者线程将会多消费一个分区。</p>
<p><strong>RoundRobin 分配策略</strong><br>RoundRobin 策略是<strong>面向消费者组的</strong>，原理是将消费组内所有消费者以及消费者所订阅的所有 topic 的 partition 按照字典序排序，然后通过轮询算法逐个将分区以此分配给每个消费者。该策略适用于：</p>
<ol>
<li>同一个消费者组里的每个消费者订阅的主题必须相同；</li>
<li>同一个消费者组里面的所有消费者的 num.streams 必须相等。</li>
</ol>
<p><strong>Sticky 分配策略</strong><br>这种分配策略是在kafka的0.11.X版本才开始引入的，是目前最复杂也是最优秀的分配策略。<br>Sticky分配策略的原理比较复杂，它的设计主要实现了两个目的：</p>
<ol>
<li>分区的分配要尽可能的均匀；</li>
<li>分区的分配尽可能的与上次分配的保持相同。<br>如果这两个目的发生了冲突，优先实现第一个目的。<br>Sticky 策略使重分配策略具备一定的“粘性”，尽可能地让前后两次分配相同，进而可以减少系统资源的损耗以及其它异常情况的发生。</li>
</ol>
<p><strong>分区重分配的三个条件</strong></p>
<ol>
<li>同一个 Consumer Group 内新增消费者；</li>
<li>订阅的主题新增分区；</li>
<li>消费者离开当前所属的Consumer Group，包括shuts down 或 crashes。<br>分区的所有权从一个消费者移到另一个消费者称为重新平衡（rebalance）。</li>
</ol>
<h2 id="Kafka-基础概念"><a href="#Kafka-基础概念" class="headerlink" title="Kafka 基础概念"></a>Kafka 基础概念</h2><h3 id="主题与分区"><a href="#主题与分区" class="headerlink" title="主题与分区"></a>主题与分区</h3><p>主题（topic）是逻辑上的概念，分区（partition）在存储层面可看作一个可追加的日志文件。一个 topic 包含一个或多个 partition，但一个 partition 只属于单个 topic。<br>消息在写入某个 topic 时，实际上写入的是 topic 的某个 partition（根据分区规则决定）。消息在被追加到日志文件的时候都会被分配一个特定的偏移量（offset），用来保证消息在分区的顺序性。Kafka 保证分区有序而不是主题有序。分区规则有如下四种：</p>
<ol>
<li>specify partition</li>
<li>random</li>
<li>key hash</li>
<li>custom</li>
</ol>
<h3 id="多副本机制"><a href="#多副本机制" class="headerlink" title="多副本机制"></a>多副本机制</h3><p><strong>作用：</strong></p>
<ol>
<li>提供数据冗余（主要作用）</li>
<li>提供高伸缩性</li>
<li>改善数据局部性</li>
</ol>
<p><strong>基本概念</strong></p>
<ul>
<li>ISR：In-Sync Replics，分区（Partition）中处于同步状态的副本列表。</li>
<li>OSR：Out-of-Sync Replicas，分区中处于同步滞后过多状态的副本列表。</li>
<li>AR = ISR + OSR。</li>
<li>LEO：Log End Offset，各副本中最新消息的 Offset。</li>
<li>HW：High Watermark，高水位，由 partiton 中所有副本的最小 LEO 决定。</li>
<li>同一分区中的不同副本保存的是相同的消息（但在同一时刻，副本之间并非完全一样），副本处于不同的 broker 中，副本之间是“一主多从”关系。</li>
</ul>
<p><strong>Leader 副本</strong></p>
<ul>
<li>leader 副本负责处理读写请求。</li>
<li>leader 副本负责维护和跟踪 ISR 集合中所有 follower 副本的滞后状态。当 follower 副本落后太多或失效时，leader 副本会将其从 ISR 集合中剔除；如果 OSR 集合中有副本“追上”了 leader 副本，则 leader 副本会将它从 OSR 集合转移至 ISR 集合。可通过 Broker 端参数 replica.lag.time.max.ms 配置，默认是 10s。</li>
<li>默认情况下，当 leader 副本出现故障时，只有 ISR 集合中的副本才有资格被选举为新的 leader。但可通过 Broker 端参数 unclean.leader.election.enable 修改，即允许 OSR 列表中的副本参与 leader 选举，此称为 Unclean 领导者选举。该参数开启后，虽然保证了高可用性，但会导致数据丢失（LEO 与元 HW 相距过大，但同时 producer 不再发送这部分的间隙数据），因此不建议开启。</li>
</ul>
<p><strong>Follower 副本</strong></p>
<ul>
<li>follower 副本只负责与 leader 异步拉取消息。</li>
<li>follower 副本每次 fetch（拉取）只能更新上一次 fetch 后的 HW 值：follower fetch leader 时捎带了自身了 LEO，leader 更新 remote LEO，并根据所有副本的 LEO 更新 HW，并复制消息给 follower，更新 follower 的 HW 值。</li>
</ul>
<h3 id="特性与实现"><a href="#特性与实现" class="headerlink" title="特性与实现"></a>特性与实现</h3><ul>
<li>负载均衡：同一 topic 的不同消息分配到不同 partition，不同 partition 分配到不同机器。</li>
<li>可靠性：同一 partition 的不同副本分配到不同的机器</li>
<li>数据一致性：副本区分 leader 和 follower，producer 和 consumer 只和 leader 进行交互，follower 则不停地从 leader 同步数据。</li>
</ul>
<h3 id="数据安全"><a href="#数据安全" class="headerlink" title="数据安全"></a>数据安全</h3><ul>
<li>producer 端：为了让用户设置数据可靠性， Kafka 在 Producer 里面提供了消息确认机制。可以在定义 Producer 时通过 acks 参数指定，该参数有三个枚举值：<ul>
<li>acks = 0：意味着如果生产者能够通过网络把消息发送出去，那么就认为消息已成功写入 Kafka，不必等待 broker 端确认；</li>
<li>acks = 1：意味若 Leader 在收到消息并把它写入到分区数据文件（不一定同步到磁盘上）时会返回确认或错误响应。</li>
<li>acks = all（这个和 request.required.acks = -1 含义一样）：意味着 Leader 在返回确认或错误响应之前，会等待所有同步副本都收到悄息。如果和 min.insync.replicas 参数结合起来，就可以决定在返回确认前至少有多少个副本能够收到悄息，生产者会一直重试直到消息被成功提交。<br><strong>producer 若想保证数据不丢失，则 acks 需为 all；否则若 leader 在发送确认后，follower 在同步新消息完成前 leader 挂掉，则在 HW 和新 commit 的 ofset 间存在数据丢失的情况。</strong></li>
</ul>
</li>
<li>consumer 端：限制 consumer 只能读 HW(High Water Mark) 之前的数据。HW 的值由 ISR 列表里偏移量最小的分区决定，这样一来，若 leader 挂掉，重新推举出的 leader 仍能继续向 consumer 提供服务，<strong>并保证数据不被重复消费</strong>。<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/Kafka_6.jpg" class=""></li>
<li>broker 端：基于 Topic 分区副本，当分区 leader 挂掉后，kafka 会从 ISR(in-sync replicas) 列表中选举一个 follower 成为新的 leader，<strong>保证对外继续提供服务。但对于 producer 和 consumer 端的影响，可参考上面二者的讲解。</strong></li>
</ul>
<p><strong>但 kafka 仍可能丢数，一种极端的情况是：在同步发送、异步写磁盘、ack = 1 的默认配置下，若 kafka 写 mmap，但没来得及刷盘挂了，同时 follower 没来得及拉取消息，则新选出来的 leader 会丢数。<a target="_blank" rel="noopener" href="https://xie.infoq.cn/article/d62160c08a5ecb5dca291e159">刨根问底，kafka 到底会不会丢消息</a></strong></p>
<h3 id="性能分析"><a href="#性能分析" class="headerlink" title="性能分析"></a>性能分析</h3><ul>
<li>多 partition。<ol>
<li>每个 partition 位于不同机器，实现并行处理。</li>
<li>每个 partition 物理上对应一个文件夹，即使多个 partition 位于同一结点，仍然可以通过配置让同一结点的不同 partition 置于不同磁盘上。</li>
</ol>
</li>
<li>攒 batch：即 Producer 端将多个小消息合并，批量发向 Broker 的能力。kafka 采用异步发送的机制，当发送一条消息时，消息并没有发送到 broker 而是缓存起来，然后直接向业务返回成功，当缓存的消息达到一定数量时再批量发送。<br>  <strong>优点</strong><ol>
<li>减少网络传输次数，IO 次数；</li>
<li>多次写硬盘改为一次写。<br><strong>缺点</strong></li>
<li>会占用生产者的内存空间；</li>
<li>若生产者挂掉，则缓存的待发送消息将丢失。<br><em>所以 kafka 利用该机制提高了性能但降低了可靠性。</em><br><strong>为什么 RocketMQ 不在 Producer 端攒 batch？</strong></li>
</ol>
<ul>
<li>RocketMQ 使用 Java 编写，缓存过多容易导致 GC。</li>
<li>Producer 调用发送消息接口，消息未被发送到 Broker 就向业务返回成功，若此时 Producer 宕机，会导致消息丢失，业务出错。</li>
</ul>
</li>
<li>顺序写入：顺序写文件，减少寻址花费的时间。<ul>
<li>收到消息后 kafka 会把数据插入到文件末尾；</li>
<li>这会导致 kafka 无法删除数据，因此 kafka 会把所有数据保留下来；<br><strong>删除数据的策略</strong></li>
<li>基于时间删除；</li>
<li>基于 partition 文件大小删除。</li>
</ul>
</li>
<li>MMap：即 Memory Mapped Files（内存映射文件），异步刷盘。kafka 收到消息后，不立即刷盘，而是写到 Page Cache，然后返回，留给操作系统决定什么时候刷盘。<ul>
<li>写磁盘变成写内存，速度大大提高。</li>
<li>若数据的请求到达时，Page Cache 存在该数据且是最新，则 kafka 直接将该数据发送给用户，避免了读磁盘。<br><strong>同步/异步刷盘</strong></li>
<li>sync：Kafka 写入到 mmap 之后立即 flush，然后再返回 Producer 叫同步；</li>
<li>async：Kafka 写入 mmap 之后立即返回 Producer，而未 flush 叫异步。<br><strong>刷盘的参数控制</strong></li>
<li>producer.type：控制同步/异步刷盘，默认异步刷盘。</li>
<li>log.flush.interval.messages：控制缓存数据多少条后刷盘。</li>
<li>log.flush.interval.ms：控制 kafka 间隔多久刷一次盘。</li>
</ul>
</li>
<li>Zero Copy：<ul>
<li>传统模式下读硬盘文件：先复制到内核空间（read 是系统调用，放到了 DMA，所以用内核空间），然后复制到用户空间(1,2)；从用户空间重新复制到内核空间（你用的 socket 是系统调用，所以它也有自己的内核空间），最后发送给网卡（3、4）。<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/Kafka_7.jpg" class=""></li>
<li>Zero Copy 直接从内核空间（DMA的）到内核空间（Socket的），然后发送网卡。Java 的 NIO 提供了 FileChannle，它的 transferTo、transferFrom 方法就是 Zero Copy。<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/Kafka_8.jpg" class=""></li>
</ul>
</li>
</ul>
<hr>
<h1 id="RocketMQ"><a href="#RocketMQ" class="headerlink" title="RocketMQ"></a>RocketMQ</h1><blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/prestigeding/article/details/79156276">存储机制之 CommitLog、ConsumeQueue 和 index 文件</a></p>
</blockquote>
<ul>
<li>组成：<ul>
<li>Producer</li>
<li>Broker</li>
<li>NameServer</li>
<li>Consumer</li>
</ul>
</li>
<li>存储过程<ul>
<li>CommitLog：producer 发送消息到 topic，实质是发送到某 broker 的 commitlog（一个 broker 只有一个 commitlog，不同 topic 的消息统一存储到一个 commitlog）。commitlog 的底层存储是 mappedFileQueue  里的 mappedFile，使用 mmap 技术实现同步/异步刷盘。</li>
<li>ConsumeQueue：消费者直接消费 commitlog 效率非常低下，因此引入 consumequeue。一个 topic 可以有多个 consumequeue，但一个 consumequeue 只属于一个 topic。消费者根据 consumequeue 的索引找到指定的 commitlog 及指定消息消费。ConsumeQueue 的消息存储格式如下：<ul>
<li>CommitLog Offset</li>
<li>size</li>
<li>Tag Hash 值</li>
</ul>
</li>
<li>Index File：用于根据消息 ID 来查找和消费指定消息。</li>
</ul>
</li>
</ul>
<hr>
<h1 id="SQL"><a href="#SQL" class="headerlink" title="SQL"></a>SQL</h1><h2 id="sql-关键词"><a href="#sql-关键词" class="headerlink" title="sql 关键词"></a>sql 关键词</h2><ul>
<li>partition by col：根据 col 的值对结果进行分区。</li>
<li>distinct：仅能应用于一个字段，若有多个字段，则是这多个字段组成的数据去重。</li>
<li>union 和 union all<br>UNION 操作符用于合并两个或多个 SELECT 语句的结果集，二者的使用有以下需要注意的点：<ul>
<li>UNION 内部的 SELECT 语句必须拥有相同数量的列</li>
<li>列也必须拥有相似的数据类型</li>
<li>每条 SELECT 语句中的列的顺序必须相同</li>
<li>UNION 结果集中的列名总是等于 UNION 中第一个 SELECT 语句中的列名<br>二者的区别如下：</li>
<li>UNION：默认地，UNION 操作符选取不同的值</li>
<li>UNION ALL：如果结果集中允许重复的值，请使用 UNION ALL</li>
</ul>
</li>
<li>where 和 having<br>Where 是一个约束声明，使用 Where 约束来自数据库的数据，Where 是在结果返回之前起作用的，Where 中不能使用聚合函数。<br>Having 是一个过滤声明，是在查询返回结果集以后对查询结果进行的过滤操作，在 Having 中可以使用聚合函数。Having 必须在 gruop by 后使用<br>在查询过程中聚合语句(sum,min,max,avg,count)要比 having 子句优先执行。而 where 子句在查询过程中执行优先级高于聚合语句。</li>
</ul>
<h2 id="sql-函数"><a href="#sql-函数" class="headerlink" title="sql 函数"></a>sql 函数</h2><ul>
<li>over()<ul>
<li>定义：开窗函数。OVER 用于为<strong>行（select 时的行）</strong>定义一个窗口，它对一组值进行操作，不需要使用 GROUP BY 子句对数据进行分组，能够在同一行中同时返回基础行的列和聚合列。</li>
<li>用法：OVER 开窗函数必须与聚合函数或排序函数一起使用，聚合函数一般指SUM(),MAX(),MIN,COUNT(),AVG()等常见函数。排序函数一般指RANK(),ROW_NUMBER(),DENSE_RANK(),NTILE()等。</li>
</ul>
</li>
<li>row_number()<br>ROW_NUMBER() 是一个 Window 函数，它为<strong>结果集的分区中</strong>的每一行分配一个连续的整数（不重复）。行号以每个分区中第一行的行号开头。需与 over() 搭配使用。</li>
<li>rank()<br>与 ROW_NUMBER() 函数类似，为<strong>结果集的分区中</strong>的每一行分配一个连续的整数（排名可重复）。同样需与 over() 搭配使用。</li>
<li>coalesce()<br><code>COALESCE(field1, field2, ..., fieldn)</code>，依次参考各字段，遇到非 null 值即停止并返回该值。如果所有的表达式都是 null，最终将返回一个 null。coalesce 里的参数的类型应统一。<br>类似 <code>coalesce(ad_id, 0)</code>。若字段值不为 null，则取字段值；否则取默认值 0。</li>
<li>concat_ws()<br>concat_ws(VARCHAR delimiter, ARRAY<VARCHAR> input)<ul>
<li>delimiter：VARCHAR 类型，连接符</li>
<li>input：ARRAY 类型，需要进行连接操作的对象。<br>作用：将一个 ARRAY 进行连接操作, 每个元素间通过连接符连接，返回一个连接后的字符串。</li>
</ul>
</li>
<li>concat()<br>concat(ARRAY<VARCHAR> input)<ul>
<li>input：ARRAY 类型，需要进行连接操作的对象。<br>作用：将一个 ARRAY 进行连接操作, 返回一个连接后的字符串,连接符为空字符串””。</li>
</ul>
</li>
<li>unix_timestamp()<ul>
<li>UNIX_TIMESTAMP()：若无参数调用，则返回一个 Unix timestamp (‘1970-01-01 00:00:00’ GMT 之后的秒数) 作为无符号整数，得到当前时间戳。</li>
<li>UNIX_TIMESTAMP(date) ：若将 date 作为参数传入 UNIX_TIMESTAMP()，它会将 date 以’1970-01-01 00:00:00’ GMT后的秒数的形式返回。date 可以是一个 DATE 字符串、一个 DATETIME字符串、一个 TIMESTAMP或一个当地时间的 YYMMDD 或 YYYMMDD 格式的数字。</li>
</ul>
</li>
<li>from_unixtime()<br>from_unixtime(time,’yyyy-MM-dd HH:mm:ss’) 。其中 time 是 10 位的时间戳值，即 1970-1-1 至今的秒，而 13 位的毫秒的是不可以的；’yyyy-MM-dd HH:mm:ss’ 是 time 要转换输出的格式。</li>
</ul>
<hr>
<h1 id="Flink"><a href="#Flink" class="headerlink" title="Flink"></a>Flink</h1><blockquote>
<p><a target="_blank" rel="noopener" href="https://developer.aliyun.com/article/783112">Flink 执行引擎：流批一体的融合之路</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_44318830/article/details/113149695">干货 | 13道精选Flink面试题</a><br><a target="_blank" rel="noopener" href="https://jishuin.proginn.com/p/763bfbd2b5a6">Flink 面试题大全(建议收藏)</a><br><a target="_blank" rel="noopener" href="http://www.hobbin.wang/post/flink%E5%86%85%E9%83%A8%E9%80%9A%E4%BF%A1%E7%BB%84%E4%BB%B6/">Flink内部通信组件</a><br><a target="_blank" rel="noopener" href="https://toutiao.io/posts/9p2cuy2/preview">Flink 核心组件 架构原理 多图剖析</a></p>
</blockquote>
<h2 id=""><a href="#" class="headerlink" title=""></a></h2><h2 id="flink-checkpoint"><a href="#flink-checkpoint" class="headerlink" title="flink checkpoint"></a>flink checkpoint</h2><p>一种由 Flink 自动执行的快照，本质是容错恢复机制。</p>
<ul>
<li>流程：<ol>
<li>当配置了 checkpoint 的应用启动时，Flink 的 JobManager 为其创建一个 Checkpoint Coordinator（检查点协调器），Checkpoint Coordinator全权负责本应用的快照制作。</li>
<li>Checkpoint Coordinator 周期性的向该流应用的所有 source 算子发送 barrier（barrier 包含当前 checkpoint 的 ID）。</li>
<li>当 source 算子收到 barrier 时，会暂停数据处理过程（接收数据但缓存，放在输入缓冲区上），然后把自己的当前状态制作成快照，并保存到指定的持久化存储中。最后向 Checkpoint Coordinator 报告自己快照制作情况及快照存储位置，同时向自身所有下游算子广播该 barrier，恢复数据处理。（此为同步，也可异步处理）</li>
<li>同理其他算子。每个算子按步骤 3 制作快照并向下游广播 barrier，直到 barrier 传递到 sink 算子，快照制作完成。</li>
<li>当 Checkpoint Coordinator 收到所有算子的报告之后，认为该周期的快照制作成功；否则，如果在规定的时间内没有收到所有算子的报告，则认为本周期快照制作失败。</li>
</ol>
</li>
<li>StateBackend：状态后端<ul>
<li>MemoryStateBackend： 默认，小状态，本地调试使用。<ul>
<li>state 存储：TaskManager 内存中；</li>
<li>checkpoint 存储：JobManager 内存中。</li>
</ul>
</li>
<li>FsStateBackend：大状态，长窗口，高可用场景。优点：速度快，缺点：容量小，容易产生 GC 问题。<ul>
<li>state 存储：TaskManager 内存中；</li>
<li>checkpoint 存储：可靠的外部存储文件系统中。本地测试可以是 LocalFs，测试生产用 HDFS。</li>
</ul>
</li>
<li>RocksDBStateBackend：超大状态，长窗口，高可用场景，支持增量 checkpoint（sink 快照完成后，RocksDB 会全量刷盘，然后 flink 再选择没有上传的文件进行备份）。一般需要和 SSD 相配合使用，否则处理速率相对较慢。优点：容量不受限，缺点：速度慢。<ul>
<li>state 存储：TaskManager 内存数据库 RocksDB 中。RocksDB 是一个 key/value 内存存储系统，和其他的 key/value 一样，先将状态放到内存中，如果内存快满时，则写入到磁盘中。类似 Redis 内存数据库。</li>
<li>checkpoint 存储：外部文件系统。</li>
</ul>
</li>
</ul>
</li>
<li>语义<ul>
<li>At Most Once：不开启 checkpoint 时，即为 At Most Once；</li>
<li>Exactly Once：开启 checkpoint 时，各 subTask 需对齐 barrier 后，才进行快照。在对齐 barrier 前，快流的数据被缓存起来。</li>
<li>At Least Once：开启 checkpoint 时，各 subTask 无需对齐 barrier。若快流 barrier 先到达，数据继续处理，直到所有 barrier 到达后进行快照。则在快流 barrier 到达后、慢流 barrier 到达前的快流数据存在重复。比如若 barrier-100 在 source 对齐，但在某个 operator task 没对齐，operator task 消费了部分 barrier-101 的数据，在完成 checkpoint-100 后，任务挂了，则从 barrier-100 的 offset 开始消费，但是没对齐的 operator task 对部分 barrier-101 的数据会重复消费。</li>
</ul>
</li>
<li>checkpoint Interval &amp; Timeout<br>  常见调参为 checkpoint interval 和 checkpoint timeout：<ul>
<li>checkpoint interval: Checkpoint 触发的时间间隔，也可以理解为是 commit offset 的间隔。</li>
<li>checkpoint timeout: 过短会造成 checkpoint 频繁失败。<br><strong>参数建议，需根据作业的状态、并行度、拓扑调整：</strong></li>
<li>如果 state 为 KB / MB / &lt; 10GB 级别，interval 和 timeout 调整为 3min 左右</li>
<li>如果 state 为 &gt;10GB / TB 级别，interval 和 timeout 调整为 10min+<br>通常来讲，interval 取决于业务需要（比如能容忍多长时间（interval + timeout）不 commit offsets 产生的 lag）；timeout 是对 lag 和 checkpoint 的一个权衡，如果 timeout 设置过短，作业可能由于流量陡增、短暂时间的倾斜、或者 Hdfs 慢导致 checkpoint 超时失败；如果设置过长，那么产生的 lag 也会相对大一些。</li>
</ul>
</li>
</ul>
<h2 id="flink-Exactly-once"><a href="#flink-Exactly-once" class="headerlink" title="flink Exactly-once"></a>flink Exactly-once</h2><blockquote>
<p><a target="_blank" rel="noopener" href="https://developer.51cto.com/article/643945.html">Flink Exactly-once 实现原理解析</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/266620519">Flink Exactly-once 实现原理解析</a></p>
</blockquote>
<p><strong>三种数据处理语义：</strong><br>最多一次（At-most-Once）：用户的数据只会被处理一次，不管成功还是失败，不会重试也不会重发。<br>至少一次（At-least-Once）：该语义下，系统会保证数据或事件至少被处理一次。如果中间发生错误或者丢失，那么会从源头重新发送一条然后进入处理系统，所以同一个事件或者消息会被处理至少一次。<br>精确一次（Exactly-Once）：表示每一条数据只会被精确地处理一次，不多也不少。</p>
<p><strong>端到端的 Exactly-once</strong><br>source 端：支持数据重放。<br>flink：基于 checkpoint 实现自身 Exactly-once。<br>sink 端：支持事务写入或幂等写入（从故障恢复时，数据不会重复写入外部系统）。<br><strong>Flink 通过分布式快照和两阶段提交实现 End-to-End Exactly-once。</strong></p>
<h3 id="分布式快照"><a href="#分布式快照" class="headerlink" title="分布式快照"></a>分布式快照</h3><p>核心元素：</p>
<ul>
<li>Barrier（数据栅栏）：Barrier （可理解为一个标记）严格有序，并且随着数据流往下流动。每个 Barrier 都带有自己的 ID，Barrier 极其轻量，并不会干扰正常的数据处理。</li>
<li>异步存储：Flink 在做快照存储时，采用异步方式。每次在把快照存储到我们的状态后端时，如果是同步进行就会阻塞正常任务，从而引入延迟。</li>
<li>增量快照：每次进行的全量 checkpoint，是基于上次进行更新的。由于 checkpoint 是一个全局状态，用户保存的状态可能非常大，多数达 G 或者 T 级别，checkpoint 的创建会非常慢，而且执行时占用的资源也比较多。</li>
</ul>
<h3 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h3><p>JobManager 为协调者，各个算子为参与者（不过只有 sink 一个参与者会执行提交）。</p>
<ol>
<li>JobManager 向 Source 发送 Barrier，开始进入 pre-Commit 阶段。<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/flink_7.png" class=""></li>
<li>进行分布式快照，当 sink 算子接收到 barrier，sink 算子会启动一个事务，将数据写入 kafka 分区日志但标记为未提交。</li>
<li>当所有算子快照生成成功并完成存储后，pre-Commit 阶段完成。<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/flink_8.png" class=""></li>
<li>JobManager 进入 Commit 阶段，告知所有 operator Checkpoint 已经成功，sink 算子执行提交。完成 flink - kafka 的事务。<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/flink_9.png" class=""></li>
<li>若在 pre-Commit 阶段有一个算子快照生成或存储失败，所有其它的 pre-Commit 必须停止，并且 flink 会回滚到最近成功完成的 checkpoint。</li>
</ol>
<h2 id="flink-反压"><a href="#flink-反压" class="headerlink" title="flink 反压"></a>flink 反压</h2><p><a target="_blank" rel="noopener" href="https://developer.aliyun.com/article/727389">如何分析及处理 Flink 反压？</a><br><strong>反压的定义：</strong>在实时计算，特别是流式计算中反压较常见。反压意味着数据管道中某个结点成为瓶颈，处理速率跟不上数据接收速率，而对上游进行的限速。对于 Flink 来说，每个算子都有输入缓冲池和输出缓冲池，对于一个处理速率跟不上数据接收速率的算子来说，表现为输出缓冲池利用率较低，同时输入缓冲池使用率较高。</p>
<p><strong>反压的影响：</strong></p>
<ol>
<li>影响 checkpoint 时长：因为 barrier 不会越过普通数据，数据处理被阻塞会导致 barrier 流经整个数据管道时长变长，从而导致 checkpoint 完成时长变长。</li>
<li>state 大小：？在 Exactly-Once 语义下，快流 barrier 到达后，其后数据若停留在缓冲池里，则应该不影响 state 大小；若进入 task 缓存里，是怎么影响 state 大小？</li>
</ol>
<p><strong>定位反压节点：</strong>常用的 Metrics：</p>
<table>
<thead>
<tr>
<th align="left">Metris</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">outPoolUsage</td>
<td align="left">发送端 Buffer 的使用率</td>
</tr>
<tr>
<td align="left">inPoolUsage</td>
<td align="left">接收端 Buffer 的使用率</td>
</tr>
<tr>
<td align="left">floatingBuffersUsage（1.9 以上）</td>
<td align="left">接收端 Floating Buffer 的使用率</td>
</tr>
<tr>
<td align="left">exclusiveBuffersUsage （1.9 以上）</td>
<td align="left">接收端 Exclusive Buffer 的使用率</td>
</tr>
</tbody></table>
<p>其中 inPoolUsage 等于 floatingBuffersUsage 与 exclusiveBuffersUsage 的总和。</p>
<p><strong>反压有时是短暂的且影响不大，比如来自某个 Channel 的短暂网络延迟或 TaskManager 的正常 GC，这种情况下可以不用处理。</strong><br><strong>数据倾斜：</strong>数据倾斜在 MapReduce 计算框架中经常发生。通俗理解，该现象指的是在整个计算过程中，大量相同的 key 被分配到了同一个任务上，造成“一个人累死、其他人闲死”的状况，这违背了分布式计算的初衷，使得整体的执行效率十分低下。</p>
<h2 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h2><h3 id="flink-流批一体"><a href="#flink-流批一体" class="headerlink" title="flink 流批一体"></a>flink 流批一体</h3><p>意味着计算引擎同时具备流计算的低延迟和批计算的高吞吐高稳定性，提供统一编程接口开发两种场景的应用并保证它们的底层执行逻辑是一致的。</p>
<ul>
<li>流处理：接收一条数据处理一条数据；</li>
<li>批处理：积累数据到一定程度后再处理。</li>
<li>流批独立方案的问题：<ul>
<li>数据链路冗余。在很多的场景下，流和批计算内容其实是一致，但是由于是两套系统，所以相同逻辑还是需要运行两遍，产生一定的资源浪费。</li>
<li>人力成本比较高。由于流和批是两套系统，相同的逻辑需要两个团队开发两遍。</li>
<li>数据口径不一致。这个是用户遇到的最重要的问题。两套系统、两套算子，两套 UDF，一定会产生不同程度的误差，这些误差给业务方带来了非常大的困扰。这些误差不是简单依靠人力或者资源的投入就可以解决的。</li>
</ul>
</li>
<li>flink 流批一体实现：<ul>
<li>Runtime 层是统一的流处理；</li>
<li>上面分别有独立的 DataStream 和 DataSet 两个 API，两者基于不同的任务类型（Stream Task/Batch Task）和 UDF 接口（Transformation/Operator）。<ul>
<li>好处：允许 Flink 在执行层面仍沿用批处理的优化技术，并简化掉架构移除掉不需要的 watermark、checkpoint 等特性。<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/flink_6.png" class=""></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Mini-Batch"><a href="#Mini-Batch" class="headerlink" title="Mini Batch"></a>Mini Batch</h3><p>mini-batch 的主要作用是用来攒一批数据，一起计算完成后，再访问一次状态，来降低对状态的访问次数。</p>
<p><strong>支持 mini-batch 的算子</strong></p>
<ul>
<li>去重算子</li>
<li>普通聚合算子</li>
<li>window 算子（字节开发支持）</li>
</ul>
<p><strong>参数配置</strong></p>
<ul>
<li>mini-batch.allow-latency：mini-batch 最大延迟时间间隔，该间隔时间后 mini-batch 中积攒的数据必须计算一次。该值应在作业吞吐和数据时效性之间权衡；</li>
<li>table.exec.mini-batch.size：单个并发 buffer 数据的条数，建议通过合理配置该值大小控制异常流量（如数据回溯，lag 过大追数据等情况）下 buffer 的数据条数，防止上述情况 buffer 数据条数过多直接造成内存OOM。</li>
</ul>
<p><strong>作用</strong></p>
<ul>
<li>降低频繁访问状态导致的 CPU 开销<br>如果配置的 state backend 是 rocksdb 才有这个问题，如果是 filesystem，则不需要。原因是 filesystem 用的是 heap 来存储状态，状态都是以 java 对象的形式来存储，不需要做序列化和反序列化，所以每次都访问状态是没有额外的 CPU 开销的。如果是 rocksdb state backend，则每次状态读取都需要反序列化，状态写入则需要序列化，所以相对来说，会多消耗一些 CPU。<br>以聚合来讲，如果开了 mini-batch，则会攒一波数据，这波数据读取一次状态，修改聚合指标，然后统一一次写入状态，所以可以降低一些 CPU 开销。</li>
<li>减少聚合的输出量<br>如果是普通的聚合，则每来一条数据就直接输出一条当前的聚合结果。但是用了 mini-batch 之后，是一个 mini-batch 才输出一次，对于同一个 group by 的 key 如果在一个 mini-batch 内有多条数据，则只会输出一次，这样可以有效降低输出数据的量。</li>
</ul>
<h3 id="Emit-early-fire"><a href="#Emit-early-fire" class="headerlink" title="Emit early-fire"></a>Emit early-fire</h3><p><strong>作用：</strong>用来提前周期性输出一个长窗口的结果（提前触发窗口计算，并输出结果），如果有变化才下发，反之不下发。<br><strong>应用场景：</strong>如现在有一个 1 天的滚动窗口 TUMBLE(ts, INTERVAL ‘1’ DAY)。正常情况下，只有在当天结束的时候才会发送这个窗口的结果到下游。而通过配置 Emit，可实时输出窗口内计算的中间结果。<br><strong>遇到的问题：</strong>对于配置了 early-fire 为 1min 的 flink 任务，在停止任务一段时间再重启（追 lag），发现数据的输出间隔时间小于 1min。</p>
<p>理解：为保证 early-fire 时间间隔的正确，flink 会为其分配一个时间戳 timer。该 timer 成功分配需满足条件：当前时刻距上一 timer 已过去 1min。此时便会生成一个新的 timer，该 timer 距上一 timer 刚好 1min。timer 生成后，若 state 距上一 timer 的 state 发生了变化，则 flink 将该 state 的数据输出下游。</p>
<p>flink 任务在重启成功后，与之前任务停止时刻之间的时间间隔内，early-fire 会依次串行自任务停止时刻开始，间隙 1min 生成新的 timer，该 timer 要小于当前现实时刻并与上一 timer 时刻恰巧间隔 1min（现实时刻间隙小于 1min，但 timer 间隙 1min，因为 timer 小于现实时刻）。若 state 在该 timer 生成后发生了变化，即输出数据，并再次产生新的 timer。因此，在任务重启后发现数据输出间隙小于 1min，是因为 timer 不断串行生成。</p>
<h3 id="flink-WaterMark"><a href="#flink-WaterMark" class="headerlink" title="flink WaterMark"></a>flink WaterMark</h3><p>用于处理乱序事件。乱序是指事件的时间与事件到达的先后顺序不一致的情况。</p>
<ul>
<li>时间概念：<ul>
<li>Event Time：事件时间。事件在现实世界中发生的时间，它通常由事件中的时间戳描述。</li>
<li>Ingestion Time：提取时间。数据进入 Apache Flink 流处理系统的时间，也就是 Flink 读取数据源时间。</li>
<li>Processing Time：处理时间。数据流入到具体某个算子 (消息被计算处理) 时候相应的系统时间。也就是 Flink 程序处理该事件时当前系统时间。</li>
</ul>
</li>
</ul>
<h3 id="flink-savepoint：？"><a href="#flink-savepoint：？" class="headerlink" title="flink savepoint：？"></a>flink savepoint：？</h3><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><ul>
<li>spark 和 flink 的对比 <a target="_blank" rel="noopener" href="https://toutiao.io/posts/3aokfa7/preview">流计算框架 Flink 与 Spark Streaming 性能对比</a> | <a target="_blank" rel="noopener" href="http://spark.coolplayer.net/?p=3647">spark streaming 和 structured streaming 区别</a><ul>
<li>设计理念<ul>
<li>Spark 的技术理念是使用微批来模拟流的计算，基于 Micro-batch，数据流以时间为单位被切分为一个个批次，通过 RDD（Resilient Distributed Dateset弹性分布式数据集）进行批量处理，是一种伪实时。</li>
<li>Flink 是基于事件驱动的，是面向流的处理框架，Flink 基于每个事件一行一行地流式处理，是真正的流式计算. 另外他也可以基于流来模拟批进行计算实现批处理。</li>
</ul>
</li>
<li>吞吐量和延迟<ul>
<li>spark 是基于微批的，吞吐量较高，但实时性较差，只能做到秒级。</li>
<li>flink 是基于事件的，消息逐条处理，且容错机制很轻量，因此同时具备高吞吐量和低延迟，延迟能做到毫秒级。</li>
</ul>
</li>
</ul>
</li>
<li>flink 消费并发度为什么要和 kafka partition 一致？<br>  对于 kafka，一个 partition 只能由同一个 consumer group 的一个 consumer 消费。<ol>
<li>若 parallelism = partition 个数，则相当于一个线程消费一个 partition，这样消费线程的消费压力较均衡。</li>
<li>若 parallelism &gt; partition 个数，则部分线程无法消费任何数据，浪费资源。</li>
<li>若 parallelism &lt; partition 个数，则单个线程消费压力较大、或者不均匀。</li>
</ol>
</li>
<li>mini-batch 被配置为 1min 时对多算子如何保证延迟接近 1min？<br>  因为 mini-batch 配置是作用于所有算子。如若有三个算子，在数据输出时需保证延迟仅接近 1min。<br>  mini-batch 的目的不是使一条数据在某算子里停留 1min，而是希望攒一批数据，减少状态的访问和提高吞吐量。因此可利用 barrier 的原理思想，界定一批数据进行 mini-batch，这批数据在任一算子里都作为 mini-batch 的数据访问一次状态，延迟时间可接近 1min。</li>
<li>kafka 已经保存了消费 offset，为什么 flink 也保存一份 offset？<br>  因为 flink 是在 checkpoint 完成时才 commit offset。考虑这样一种情况：当 flink checkpoint-n 完成，在 commit offset 时，因为网络原因 kafka 没有收到，此时 flink 挂了。在重启时，flink checkpoint 若没有保留 commit offset，则 flink 状态从 checkpoint-n 恢复，但是消费 kafka 数据却是从 checkpoint-n-1 的 commit offset 开始，导致数据重复。</li>
<li>为什么做 spark 迁 flink 的任务？<ol>
<li>从实时性来看，flink 比 spark 更接近实时，因为 spark 是基于微批模拟流，而 flink 就是流处理，来一条数据处理一条。结果也显示 flink 比 spark 快，数据延时减少 30s。</li>
<li>从性能来看，使用的资源相近的条件下，完成迁移后，flink 消费上游 kafka 时数据即使在晚高峰也不会出现明显 lag，而 spark 消费上游 kafka 时的 lag 会不断抖动增长。</li>
</ol>
</li>
</ul>
<h2 id="内存模型"><a href="#内存模型" class="headerlink" title="内存模型"></a>内存模型</h2><h3 id="JobManager-内存模型"><a href="#JobManager-内存模型" class="headerlink" title="JobManager 内存模型"></a>JobManager 内存模型</h3><p>1.9 与 1.11 JobManager 内存模型变化如下图所示，两个版本之间最大的变化是：</p>
<ul>
<li>1.9 中只有堆内、堆外两个模块；</li>
<li>1.11 中将 1.9 的堆外部分细分为 Direct Memory、JVM Metaspace 和 JVM Overhead 三类；<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/flink_3.jpg" class="">
<strong>JM 内存配置</strong></li>
</ul>
<table>
<thead>
<tr>
<th align="left">内存模块</th>
<th align="left">参数</th>
<th align="left">含义</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Total Process Memory</td>
<td align="left">jobmanager.memory.process.size</td>
<td align="left">Dorado 平台配置的 JM 内存值就指的是这个值，也就是申请 container 时配置的内存</td>
</tr>
<tr>
<td align="left">Total Flink Memory</td>
<td align="left">jobmanager.memory.flink.size</td>
<td align="left">主要是框架和用户作业代码需要的内存，不包括 JVM Metaspace and other Overhead 部分</td>
</tr>
<tr>
<td align="left">JVM Heap</td>
<td align="left">jobmanager.memory.heap.size</td>
<td align="left">JM JVM 启动时设置 heap 大小</td>
</tr>
<tr>
<td align="left">Off-heap memory</td>
<td align="left">jobmanager.memory.off-heap.size</td>
<td align="left">-XX:MaxDirectMemorySize 限制的内存，主要是应用程序调用 native 方法使用的，包括 JM 网络通信的部分（akka），默认值是 128MB</td>
</tr>
<tr>
<td align="left">JVM Metaspace</td>
<td align="left">jobmanager.memory.jvm-metaspace.size</td>
<td align="left">-XX:MaxMetaspaceSize 限制的内存，主要用于 class load 相关（从 JDK8 开始，类的一些元数据放在叫做 Metaspace 的 Native Memory 中），默认值 256m</td>
</tr>
<tr>
<td align="left">JVM Overhead</td>
<td align="left">jobmanager.memory.jvm-overhead.min: 192m<br>jobmanager.memory.jvm-overhead.max: 1g<br>jobmanager.memory.jvm-overhead.fraction: 0.1</td>
<td align="left">保留给 JVM 其他的内存开销，例如：Thread Stack、code cache、GC 回收空间等</td>
</tr>
</tbody></table>
<h3 id="TaskManager-内存模型"><a href="#TaskManager-内存模型" class="headerlink" title="TaskManager 内存模型"></a>TaskManager 内存模型</h3><p>1.9 与 1.11 TaskManager 内存模型变化如下如所示，两个版本之间最大的变化是：</p>
<ul>
<li>1.9 中 Managed Memory 是在 heap 中管理，1.11 中单独在堆外进行管理；</li>
<li>1.11 中 RocksDB Backend 使用的内存也在 Managed Memory 中进行管理；</li>
<li>与 JM 类似，JVM MetaSpace 和 JVM Overhead 也单独区分了出来。<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/flink_4.jpg" class="">
<strong>TM 内存配置</strong></li>
</ul>
<table>
<thead>
<tr>
<th align="left">模块</th>
<th align="left">参数</th>
<th align="left">含义</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Total process Memory</td>
<td align="left">taskmanager.memory.process.size</td>
<td align="left">TM 总的内存大小配置，也就是 Dorado 配置的 TM 内存信息</td>
</tr>
<tr>
<td align="left">Total Flink Memory</td>
<td align="left">taskmanager.memory.flink.size</td>
<td align="left">Task Executor 消耗的所有内存，也就是除了 JVM Metaspace 和 JVM Overhead 其他的加在一起就是 Total Flink Memory</td>
</tr>
<tr>
<td align="left">Framework Heap Memory</td>
<td align="left">taskmanager.memory.framework.heap.size: 128MB</td>
<td align="left">Task Executor(TaskManager 框架)本身所配置的堆内存大小</td>
</tr>
<tr>
<td align="left">Task Heap Memory</td>
<td align="left">taskmanager.memory.task.heap.size</td>
<td align="left">专门用于执行 Flink 任务的堆内存空间</td>
</tr>
<tr>
<td align="left">Managed memory</td>
<td align="left">taskmanager.memory.managed.fraction: 0.25 * TotalFlinkMem</td>
<td align="left">Task Executor 管理的 off-heap 内存，主要用于排序、哈希表、中间结果缓存、RocksDB 的 backend</td>
</tr>
<tr>
<td align="left">Framework Off-heap Memory</td>
<td align="left">taskmanager.memory.framework.off-heap.size: 128MB</td>
<td align="left">Task Executor 保留的 off-heap memory，不会分配给任何 slot。</td>
</tr>
<tr>
<td align="left">Task Off-heap Memory</td>
<td align="left">taskmanager.memory.task.off-heap.size: 0</td>
<td align="left">Task Executor 执行的 Task 所使用的堆外内存。如果在 Flink 应用的代码中调用了 Native 的方法，需要用到分配到的这些 off-heap 内存</td>
</tr>
<tr>
<td align="left">Network Memory</td>
<td align="left">taskmanager.memory.network.min: 64MB<br>taskmanager.memory.network.max: 2Gb<br>taskmanager.memory.network.fraction: 0.3 * TotalFlinkMem</td>
<td align="left">用于网络传输的 Network Buffer</td>
</tr>
<tr>
<td align="left">JVM metaspace</td>
<td align="left">taskmanager.memory.jvm-metaspace.size: 256MB</td>
<td align="left">从 JDK 8 开始，JVM 把永久代拿掉了，类的一些元数据放在叫做 Metaspace 的 Native Memory</td>
</tr>
<tr>
<td align="left">JVM Overhead</td>
<td align="left">taskmanager.memory.jvm-overhead.min: 192MB<br>taskmanager.memory.jvm-overhead.max: 1GB<br>taskmanager.memory.jvm-overhead.fraction: 0.1 * TotalProcesskMem</td>
<td align="left">保留给 JVM 其他的内存开销。例如: Thread Stack、code cache、GC 回收空间等等</td>
</tr>
</tbody></table>
<h2 id="flink-参数"><a href="#flink-参数" class="headerlink" title="flink 参数"></a>flink 参数</h2><h3 id="kafka"><a href="#kafka" class="headerlink" title="kafka"></a>kafka</h3><table>
<thead>
<tr>
<th align="left">name</th>
<th align="left">meaning</th>
<th align="left">required</th>
<th align="left">default</th>
<th align="left">consumer/producer</th>
</tr>
</thead>
<tbody><tr>
<td align="left">connector.cluster</td>
<td align="left">kafka 集群名</td>
<td align="left">YES</td>
<td align="left">-</td>
<td align="left">consumer &amp; producer</td>
</tr>
<tr>
<td align="left">connector.topic</td>
<td align="left">kafka topic</td>
<td align="left">YES</td>
<td align="left">-</td>
<td align="left">consumer &amp; producer</td>
</tr>
<tr>
<td align="left">connector.group.id</td>
<td align="left">consumer group id</td>
<td align="left">YES</td>
<td align="left">-</td>
<td align="left">consumer</td>
</tr>
<tr>
<td align="left">update-mode</td>
<td align="left">更新模式, ‘append’/‘upsert’</td>
<td align="left">YES</td>
<td align="left">-</td>
<td align="left">consumer 就填 ‘append’ 就行; producer 如果是查询的结果是可以更新的就用 upsert， 如果是查询的结果是不可更新的就用 append.</td>
</tr>
<tr>
<td align="left">connector.parallelism</td>
<td align="left">并发度</td>
<td align="left">NO</td>
<td align="left">-（kafka source 建议是 partition 个数，sink 建议不要比 partition 个数大过多）</td>
<td align="left">consumer &amp; producer</td>
</tr>
<tr>
<td align="left">connector.startup-mode</td>
<td align="left">earliest-offset/<br>latest-offset/<br>group-offsets/<br>specific-timestamp，<br>详细解释如下</td>
<td align="left">NO</td>
<td align="left">group-offsets</td>
<td align="left">consumer</td>
</tr>
<tr>
<td align="left">connector.reset-to-earliest-for-new-partition</td>
<td align="left">该参数表示在任务启动时，如果用的是group-offsets配置，对于那些还没有offset的partition如何处理</td>
<td align="left">NO</td>
<td align="left">true</td>
<td align="left">consumer</td>
</tr>
<tr>
<td align="left">connector.kafka.properties.request.timeout.ms</td>
<td align="left">kafka client写入超时时间</td>
<td align="left">NO</td>
<td align="left">30000ms</td>
<td align="left">producer</td>
</tr>
<tr>
<td align="left">connector.kafka.properties.batch.size</td>
<td align="left">kafka client会按batch写入,当攒到相关batch size(这里指的是bytes)的时候写入数据</td>
<td align="left">NO</td>
<td align="left">16384（16KB）</td>
<td align="left">producer</td>
</tr>
<tr>
<td align="left">connector.kafka.properties.linger.ms</td>
<td align="left">kafka client会按batch写入,当攒到一定时间，会实际写入到kafka</td>
<td align="left">NO</td>
<td align="left">5000ms</td>
<td align="left">producer</td>
</tr>
<tr>
<td align="left">connector.kafka.properties.acks</td>
<td align="left">需要等待几个副本响应才发送下一条消息，-1 表示要等待所有副本响应</td>
<td align="left">NO</td>
<td align="left">0</td>
<td align="left">producer</td>
</tr>
<tr>
<td align="left">connector.kafka.properties.compression.type</td>
<td align="left">压缩类型:gzip,snappy,lz4,zstd</td>
<td align="left">NO</td>
<td align="left">none</td>
<td align="left">producer</td>
</tr>
<tr>
<td align="left">scan.startup.mode</td>
<td align="left">从哪里开始消费 kafka<br>earliest-offset<br>latest-offset<br>group-offsets<br>specific-offsets<br>timestamp</td>
<td align="left">NO</td>
<td align="left">group-offsets</td>
<td align="left">consumer</td>
</tr>
<tr>
<td align="left">scan.manually-commit-offsets-interval</td>
<td align="left">任务定时 commit offset</td>
<td align="left">NO</td>
<td align="left">-</td>
<td align="left">consumer</td>
</tr>
</tbody></table>
<h3 id="flink-运行参数"><a href="#flink-运行参数" class="headerlink" title="flink 运行参数"></a>flink 运行参数</h3><table>
<thead>
<tr>
<th align="left">Key</th>
<th align="left">Default</th>
<th align="left">Type</th>
<th align="left">Description</th>
<th align="left">适用场景</th>
</tr>
</thead>
<tbody><tr>
<td align="left">execution.checkpointing.enable</td>
<td align="left">false</td>
<td align="left">Boolean</td>
<td align="left">是否开启 checkpoint</td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">execution.checkpointing.interval</td>
<td align="left">20000</td>
<td align="left">ms</td>
<td align="left">checkpoint 间隔</td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">execution.checkpointing.timeout</td>
<td align="left">10000</td>
<td align="left">ms</td>
<td align="left">checkpoint 超时时间</td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">state.backend</td>
<td align="left">Java Streaming: rocksdb<br>Flink SQL: filesystem</td>
<td align="left">Enum(filesystem/rocksdb)</td>
<td align="left">状态后端，不同状态后端拥有不同的状态存储和持久化的方式</td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">state.checkpoints.namespace</td>
<td align="left">default</td>
<td align="left">String</td>
<td align="left">Checkpoint 所属的命名空间，由用户管理</td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">state.backend.incremental</td>
<td align="left">true</td>
<td align="left">Boolean</td>
<td align="left">使用 rocksdb statebackend 时是否开启增量模式</td>
<td align="left">Streaming</td>
</tr>
<tr>
<td align="left">table.exec.emit.early-fire.enabled</td>
<td align="left">false</td>
<td align="left">Boolean</td>
<td align="left">是否开启Fast Emit</td>
<td align="left">Streaming</td>
</tr>
<tr>
<td align="left">table.exec.emit.early-fire.delay</td>
<td align="left">-</td>
<td align="left">Duration</td>
<td align="left">如果开启Fast Emit，那多久emit一次</td>
<td align="left">Streaming</td>
</tr>
<tr>
<td align="left">table.exec.emit.late-fire.enabled</td>
<td align="left">false</td>
<td align="left">Boolean</td>
<td align="left">是否开启Late Emit</td>
<td align="left">Streaming</td>
</tr>
<tr>
<td align="left">table.exec.emit.late-fire.delay</td>
<td align="left">-</td>
<td align="left">Duration</td>
<td align="left">如果开启Late Emit，那多久emit一次</td>
<td align="left">Streaming</td>
</tr>
<tr>
<td align="left">table.exec.emit.unchanged.enabled</td>
<td align="left">false</td>
<td align="left">Boolean</td>
<td align="left">如果开启了Fast Emit，默认是不会发送没有变化的聚合结果的，开了这个参数的话，则会都输出，即使聚合结果没有变化</td>
<td align="left">Streaming</td>
</tr>
<tr>
<td align="left">table.exec.mini-batch.enabled</td>
<td align="left">false</td>
<td align="left">Boolean</td>
<td align="left">是否开启 mini-batch</td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">table.exec.mini-batch.allow-latency</td>
<td align="left">-</td>
<td align="left">自己填</td>
<td align="left">最长多少时间一个mini-batch</td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">table.exec.mini-batch.size</td>
<td align="left">-</td>
<td align="left">条数</td>
<td align="left">单个并发最多多少条数据一个mini-batch</td>
<td align="left">-</td>
</tr>
</tbody></table>
<h2 id="其它-2"><a href="#其它-2" class="headerlink" title="其它"></a>其它</h2><ul>
<li>flink 压测：设计 kafka - flink - kafka 数据链路。先停止 flink 任务，在上游 kafka 积攒数据；然后启动 flink 任务，观察下游 kafka 最大输入 qps，即为 flink 最大能承受 qps（即等于 flink 的最大输出 qps）。</li>
<li>flink 确定消费 kafka 的位置：先从 checkpoint 中找。若 checkpoint 中没有（最新 checkpoint），则由 scan.startup.mode 参数决定。该参数默认 group-offsets，即从 consumer group 的 offsets 中开始消费。</li>
<li>默认情况下，flink 在 checkpoint 成功时才提交 kafka offset，因此若 checkpoint interval 较大时，偶尔的 checkpoint 失败会导致误报警（上游 kafka lag 积压）。通过设置 kafka 参数 <code>scan.manually-commit-offsets-interval = &#39;5000&#39;</code>，可保证任务定时 commit offset。但如果作业 checkpoint 失败或重启，仍然会从上一次成功 checkpoint 的 offset 恢复。</li>
<li>使用窗口函数时，时间字段需要带有 time attribute（时间属性），若只是 timestamp 类型，则会报错。将 timestamp 类型经 watermark 后可使其带有 time attribute。</li>
<li>滑动窗口需在 group by 中使用，若同时 group by 其他维度，则在聚合中计算的是在时间窗口内、该 group by 维度对应的所有数据。</li>
<li>flink 监控配置<ul>
<li>重要（电话报警）<ul>
<li>上游 source topic lag 监控</li>
<li>上游 source topic 单个 partition lag 监控</li>
<li>数据写入断流监控（上下游）</li>
<li>checkpoint 失败监控</li>
</ul>
</li>
<li>不那么重要（lark 报警）<ul>
<li>sink 瞬时 qps 突增监控</li>
<li>任务重启监控</li>
</ul>
</li>
</ul>
</li>
<li>聚合方式：<ul>
<li>全局聚合 + mini-batch：没有意义，因为全局聚合得到的结果是任务启动以来各指标的聚合结果，是一个全局 sum；</li>
<li>窗口聚合 + early-fire（ + mini-batch）：如一小时聚合，能得到一小时的各指标聚合结果，进而可得到一天的、一周的等聚合结果。<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/flink_5.png" class=""></li>
</ul>
</li>
<li>Flink 程序执行流程<ol>
<li>获取执行环境</li>
<li>加载、创建初始数据  source</li>
<li>转换数据  transformation</li>
<li>放置计算结果位置  sink</li>
<li>触发程序运行</li>
</ol>
</li>
</ul>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><ul>
<li>2022-01-04：ad 粒度聚合任务修改 udf 和更新 checkpoint 后（未切 consumer group），lag 不断积累，同时 checkpoint 一直失败。但相同操作的 creative 粒度聚合任务没有这种情况。（队列有问题）</li>
<li>flink 在追 lag 时，watermark 理论上会丢弃超时的数据。但是对于 16 小时前积累起的 lag，watermark 没有丢数，表现为 ad 粒度任务验数和 creative 粒度验数 cost 对齐。</li>
<li>背景：pre agg 任务拆成了两个 flink 任务：pre agg common 和 pre agg core。common 任务在启动后不断 checkpoint 失败，表现同上 ad  粒度，checkpoint 失败时间区间[2022-01-06 22:00:00, 2022-01-07 02:00:00]。但验数结果上，22、23 点的数据对不齐，而 01、02 点的数据能对齐，不理解。</li>
</ul>
<hr>
<h1 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h1><h2 id="知识点"><a href="#知识点" class="headerlink" title="知识点"></a>知识点</h2><ol>
<li>若 hive 表结构不包含某字段，那即使上游数据中含有该字段，也不会落到 hive 表中。在表结构中新加该字段，在加上该字段前的时间，该字段的数据不可得。</li>
</ol>
<hr>
<h1 id="Elasticsearch"><a href="#Elasticsearch" class="headerlink" title="Elasticsearch"></a>Elasticsearch</h1><h2 id="es-与数据库对比"><a href="#es-与数据库对比" class="headerlink" title="es 与数据库对比"></a>es 与数据库对比</h2><img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/es1.jpg" class="">
<p><strong>es 于 7.x 移除了 mapping type</strong></p>
<p><strong>es 中 mappings 的数据类型</strong></p>
<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/es2.jpg" class="">
<p>mappings 中使用 obejct（可以理解为 json）示例，metric_data 为 obejct 类型，无需显式定义 type 属性值：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;dynamic&quot;: false,</span><br><span class="line">    &quot;_source&quot;: &#123;</span><br><span class="line">        &quot;enabled&quot;: false</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;dp_realtime_click_count&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;long&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;unfollow_in_wechat_count&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;long&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;metric_data&quot;: &#123;</span><br><span class="line">            &quot;properties&quot;: &#123;</span><br><span class="line">                &quot;cost&quot;: &#123;</span><br><span class="line">                    &quot;type&quot;: &quot;long&quot;</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;show_cnt&quot;: &#123;</span><br><span class="line">                    &quot;type&quot;: &quot;long&quot;</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;convert_cnt&quot;: &#123;</span><br><span class="line">                    &quot;type&quot;: &quot;long&quot;</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;click_cnt&quot;: &#123;</span><br><span class="line">                    &quot;type&quot;: &quot;long&quot;</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;send_cnt&quot;: &#123;</span><br><span class="line">                    &quot;type&quot;: &quot;long&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;first_agent_company_id&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;long&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h1 id="Mongodb"><a href="#Mongodb" class="headerlink" title="Mongodb"></a>Mongodb</h1><h2 id="mongodb-常用命令"><a href="#mongodb-常用命令" class="headerlink" title="mongodb 常用命令"></a>mongodb 常用命令</h2><ul>
<li>启动 mongodb：cd 到 mongodb 存储目录下的 bin 目录下，执行命令<code>mongod --dbpath /usr/local/var/mongodb --logpath /usr/local/var/log/mongodb/mongo.log --fork</code>，可在后台启动 mongodb。其中：<ul>
<li>dbpath 设置数据存放目录</li>
<li>logpath 设置日志存放目录</li>
<li>fork 在后台运行</li>
</ul>
</li>
<li>mongodb 启动成功后，使用<code>mongo</code>命令进入数据库环境</li>
<li>切换/创建数据库：<code>use &#39;dbname&#39;</code></li>
<li>查询所有数据库：<code>show dbs</code></li>
<li>删除当前使用数据库：<code>db.dropDatabase()</code></li>
<li>得到指定名称的聚集集合（table）：<code>db.getCollection(&quot;account&quot;)</code></li>
<li>得到当前db的所有聚集集合：<code>db.getCollectionNames()</code></li>
</ul>
<h2 id="pymongo"><a href="#pymongo" class="headerlink" title="pymongo"></a>pymongo</h2><blockquote>
<p>参考：<a target="_blank" rel="noopener" href="https://docs.mongoing.com/">MongoDB中文手册</a></p>
</blockquote>
<ul>
<li>创建数据库<ol>
<li>获取 MongoClient 对象：<code>myclient = pymongo.MongoClient(&quot;mongodb://localhost:27017/&quot;)</code></li>
<li>创建名为 test 的表：<code>mydb = myclient[&quot;test&quot;]</code><br><strong>在 MongoDB 中，数据库只有在内容插入后才会创建! 就是说，数据库创建后要创建集合(数据表)并插入一个文档(记录)，数据库才会真正创建，同时此时才会创建集合</strong></li>
</ol>
</li>
<li>获取 mongodb 中所有数据库：<code>myclient.list_database_names()</code><br>  <strong>Python3.7 版本之前使用 <code>myclient.database_names()</code></strong></li>
<li>创建集合：<code>mycol = mydb[&quot;test_col&quot;]</code></li>
<li>获取数据库中所有的集合：<code>mydb.list_collection_names()</code><br>  <strong>Python3.7 版本之前使用 <code>mydb.collection_names()</code></strong></li>
<li>往集合中插入一个文档：<code>x = mycol.insert_one(mydict)</code>。返回值是 InsertOneResult 对象，该对象包含 inserted_id 属性，它是插入文档的 id 值。通过 <code>x.inserted_id</code> 获取</li>
<li>往集合中插入多个文档：<code>x = mycol.insert_many(mylist)</code>。mylist 是一个字典列表。可通过 <code>x.inserted_ids</code> 输出插入的所有文档对应的 _id 值。<br>  <strong>也可通过在字典中增加 _id:value 键值对，指定文档插入的位置</strong></li>
<li>查询集合中的第一个文档：<code>x = mycol.find_one()</code></li>
<li>查询集合中的所有文档：<code>x_list = mycol.find()</code></li>
<li>查询指定列的数据，将要返回的字段对应值设置为 1：<code>x_list = mycol.find(&#123;&#125;,&#123; &quot;_id&quot;: 0, &quot;name&quot;: 1, &quot;alexa&quot;: 1 &#125;)</code>。查询的是 name 和 alexa 列的值。（除了 _id，不能在一次查询中同时指定 0 和 1）</li>
<li>查询指定行的数据（过滤）：<code>x = mycol.find(&#123;&quot;name&quot;: &quot;RUNOOB&quot;&#125;</code>。查询集合中 name=RUNOOB 的文档</li>
<li>指定查询返回文档数：<code>x = mycol.find().limit(3)</code></li>
<li>获取某字段（列）的所有枚举值：<code>mycol.distinct(&quot;label&quot;)</code>。获取 label 字段的所有枚举值</li>
</ul>
<h2 id="知识点-1"><a href="#知识点-1" class="headerlink" title="知识点"></a>知识点</h2><ol>
<li>mongodb 中存储的数据库和表，在关机后不会被清除</li>
</ol>
</article><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/01/26/%E9%87%91%E8%9E%8D%E6%9C%AF%E8%AF%AD/"><img class="prev-cover" src="/img/beijing.jpg" onerror="onerror=null;src='/img/touxiang.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">金融术语</div></div></a></div><div class="next-post pull-right"><a href="/2021/05/03/%E9%9D%A2%E8%AF%95/"><img class="next-cover" src="/img/beijing.jpg" onerror="onerror=null;src='/img/touxiang.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">面试</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">John Doe</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">3</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/zourunxin"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">多总结！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Hexo"><span class="toc-text">Hexo</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Hexo-%E5%AE%89%E8%A3%85"><span class="toc-text">Hexo 安装</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#cnpm-%E5%91%BD%E4%BB%A4%E6%97%A0%E6%95%88%E9%97%AE%E9%A2%98"><span class="toc-text">cnpm 命令无效问题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hexo-%E7%BB%88%E7%AB%AF%E5%91%BD%E4%BB%A4"><span class="toc-text">Hexo 终端命令</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hexo-%E7%9B%B8%E5%85%B3%E6%8A%A5%E9%94%99"><span class="toc-text">Hexo 相关报错</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Markdown"><span class="toc-text">Markdown</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#md-%E8%AF%AD%E6%B3%95"><span class="toc-text">md 语法</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BB%88%E7%AB%AF%E5%91%BD%E4%BB%A4"><span class="toc-text">终端命令</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Win"><span class="toc-text">Win</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Mac"><span class="toc-text">Mac</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Maven"><span class="toc-text">Maven</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#maven-%E5%91%BD%E4%BB%A4"><span class="toc-text">maven 命令</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Maven-%E8%AF%AD%E6%B3%95"><span class="toc-text">Maven 语法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B6%E5%AE%83"><span class="toc-text">其它</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%97%AE%E9%A2%98"><span class="toc-text">问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Gradle"><span class="toc-text">Gradle</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%95%E5%85%A5%E4%BE%9D%E8%B5%96%E5%9F%BA%E6%9C%AC%E6%96%B9%E5%BC%8F"><span class="toc-text">引入依赖基本方式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEGradle%E4%BD%BF%E7%94%A8maven%E6%9C%AC%E5%9C%B0%E4%BB%93%E5%BA%93"><span class="toc-text">配置Gradle使用maven本地仓库</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Git"><span class="toc-text">Git</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF"><span class="toc-text">远程分支</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%AC%E5%9C%B0%E5%88%86%E6%94%AF"><span class="toc-text">本地分支</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Github"><span class="toc-text">Github</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#IDEA"><span class="toc-text">IDEA</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Kafka"><span class="toc-text">Kafka</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka-%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-text">Kafka 是什么</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ZooKeeper"><span class="toc-text">ZooKeeper</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Producer"><span class="toc-text">Producer</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Producer-%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE"><span class="toc-text">Producer 参数配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#batch-%E8%B0%83%E4%BC%98"><span class="toc-text">batch 调优</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5"><span class="toc-text">生产者分区策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B6%E5%AE%83-1"><span class="toc-text">其它</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Broker"><span class="toc-text">Broker</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#offset-%E7%BB%B4%E6%8A%A4"><span class="toc-text">offset 维护</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E5%89%AF%E6%9C%AC%E9%97%B4%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5"><span class="toc-text">主副本间数据同步</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Consumer"><span class="toc-text">Consumer</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E6%A8%A1%E5%BC%8F"><span class="toc-text">消费模式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5"><span class="toc-text">分区分配策略</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5"><span class="toc-text">Kafka 基础概念</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E9%A2%98%E4%B8%8E%E5%88%86%E5%8C%BA"><span class="toc-text">主题与分区</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6"><span class="toc-text">多副本机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E6%80%A7%E4%B8%8E%E5%AE%9E%E7%8E%B0"><span class="toc-text">特性与实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8"><span class="toc-text">数据安全</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90"><span class="toc-text">性能分析</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#RocketMQ"><span class="toc-text">RocketMQ</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#SQL"><span class="toc-text">SQL</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#sql-%E5%85%B3%E9%94%AE%E8%AF%8D"><span class="toc-text">sql 关键词</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#sql-%E5%87%BD%E6%95%B0"><span class="toc-text">sql 函数</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Flink"><span class="toc-text">Flink</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link"><span class="toc-text"></span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#flink-checkpoint"><span class="toc-text">flink checkpoint</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#flink-Exactly-once"><span class="toc-text">flink Exactly-once</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E5%BF%AB%E7%85%A7"><span class="toc-text">分布式快照</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4"><span class="toc-text">两阶段提交</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#flink-%E5%8F%8D%E5%8E%8B"><span class="toc-text">flink 反压</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%89%B9%E6%80%A7"><span class="toc-text">特性</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#flink-%E6%B5%81%E6%89%B9%E4%B8%80%E4%BD%93"><span class="toc-text">flink 流批一体</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Mini-Batch"><span class="toc-text">Mini Batch</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Emit-early-fire"><span class="toc-text">Emit early-fire</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#flink-WaterMark"><span class="toc-text">flink WaterMark</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#flink-savepoint%EF%BC%9A%EF%BC%9F"><span class="toc-text">flink savepoint：？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%9D%E8%80%83"><span class="toc-text">思考</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B"><span class="toc-text">内存模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#JobManager-%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B"><span class="toc-text">JobManager 内存模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#TaskManager-%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B"><span class="toc-text">TaskManager 内存模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#flink-%E5%8F%82%E6%95%B0"><span class="toc-text">flink 参数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#kafka"><span class="toc-text">kafka</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#flink-%E8%BF%90%E8%A1%8C%E5%8F%82%E6%95%B0"><span class="toc-text">flink 运行参数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B6%E5%AE%83-2"><span class="toc-text">其它</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-text">遇到的问题</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hive"><span class="toc-text">Hive</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9F%A5%E8%AF%86%E7%82%B9"><span class="toc-text">知识点</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Elasticsearch"><span class="toc-text">Elasticsearch</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#es-%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AF%B9%E6%AF%94"><span class="toc-text">es 与数据库对比</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Mongodb"><span class="toc-text">Mongodb</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#mongodb-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4"><span class="toc-text">mongodb 常用命令</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#pymongo"><span class="toc-text">pymongo</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9F%A5%E8%AF%86%E7%82%B9-1"><span class="toc-text">知识点</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/01/26/%E9%87%91%E8%9E%8D%E6%9C%AF%E8%AF%AD/" title="金融术语">金融术语</a><time datetime="2022-01-26T05:47:08.000Z" title="Created 2022-01-26 13:47:08">2022-01-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/" title="工具类">工具类</a><time datetime="2021-10-25T04:13:44.000Z" title="Created 2021-10-25 12:13:44">2021-10-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/05/03/%E9%9D%A2%E8%AF%95/" title="面试">面试</a><time datetime="2021-05-03T07:37:48.000Z" title="Created 2021-05-03 15:37:48">2021-05-03</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By John Doe</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div></div></body></html>