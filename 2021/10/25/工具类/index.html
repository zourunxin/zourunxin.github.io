<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>工具类 | Hexo</title><meta name="author" content="John Doe"><meta name="copyright" content="John Doe"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Hexo 参考从0开始搭建个人博客(详细步骤)mac os下搭建hexo+github博客hexo-theme-hikerhexo 文章加密hexo笔记：文章排序  Hexo 安装cnpm 命令无效问题问题描述在安装Hexo admin过程中，输入命令 cnpm install --save hexo-admin光标在控制器中静止不动，且无任何输出响应内容。此时按 crtl C 退出过程解决办法重">
<meta property="og:type" content="article">
<meta property="og:title" content="工具类">
<meta property="og:url" content="http://example.com/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="Hexo 参考从0开始搭建个人博客(详细步骤)mac os下搭建hexo+github博客hexo-theme-hikerhexo 文章加密hexo笔记：文章排序  Hexo 安装cnpm 命令无效问题问题描述在安装Hexo admin过程中，输入命令 cnpm install --save hexo-admin光标在控制器中静止不动，且无任何输出响应内容。此时按 crtl C 退出过程解决办法重">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/img/beijing.jpg">
<meta property="article:published_time" content="2021-10-25T04:13:44.000Z">
<meta property="article:modified_time" content="2022-03-08T03:45:42.215Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/beijing.jpg"><link rel="shortcut icon" href="/img/touxiang.jpg"><link rel="canonical" href="http://example.com/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '工具类',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-03-08 11:45:42'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/background.css"><meta name="generator" content="Hexo 5.4.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">12</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">1</div></a></div></div></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/beijing.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Hexo</a></span><div id="menus"><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">工具类</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2021-10-25T04:13:44.000Z" title="Created 2021-10-25 12:13:44">2021-10-25</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2022-03-08T03:45:42.215Z" title="Updated 2022-03-08 11:45:42">2022-03-08</time></span></div><div class="meta-secondline"></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Hexo"><a href="#Hexo" class="headerlink" title="Hexo"></a>Hexo</h1><blockquote>
<p>参考<br><a target="_blank" rel="noopener" href="https://blog.csdn.net/hutongxue434/article/details/106181590">从0开始搭建个人博客(详细步骤)</a><br><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/49c8168c7418">mac os下搭建hexo+github博客</a><br><a target="_blank" rel="noopener" href="https://github.com/iTimeTraveler/hexo-theme-hiker/blob/master/README.cn.md">hexo-theme-hiker</a><br><a target="_blank" rel="noopener" href="https://www.itfanr.cc/2021/04/16/hexo-blog-article-encryption/">hexo 文章加密</a><br><a target="_blank" rel="noopener" href="https://gsy00517.github.io/hexo20200207151318/">hexo笔记：文章排序</a></p>
</blockquote>
<h2 id="Hexo-安装"><a href="#Hexo-安装" class="headerlink" title="Hexo 安装"></a>Hexo 安装</h2><h3 id="cnpm-命令无效问题"><a href="#cnpm-命令无效问题" class="headerlink" title="cnpm 命令无效问题"></a>cnpm 命令无效问题</h3><p><strong>问题描述</strong><br>在安装Hexo admin过程中，输入命令 <code>cnpm install --save hexo-admin</code><br>光标在控制器中静止不动，且无任何输出响应内容。此时按 <code>crtl C</code> 退出过程<br><strong>解决办法</strong><br>重新输入代码：<code>npm config set registry http://registry.cnpmjs.org</code><br>再重新运行 <code>hexo admin</code> 安装指令即可</p>
<h2 id="Hexo-终端命令"><a href="#Hexo-终端命令" class="headerlink" title="Hexo 终端命令"></a>Hexo 终端命令</h2><ul>
<li>启动Hexo服务器：<code>hexo s</code></li>
<li>新建博客（需先进入hexo所在文件夹）<code>hexo n &quot;博客名&quot;</code></li>
<li>将仓库更新到github上<br>分成两步：<ol>
<li>生成静态文件 <code>hexo g</code></li>
<li>部署到远端服务器 <code>hexo d</code>。但会出现更新不及时的情况，即在github上的更新内容需过一段时间后才显示</li>
</ol>
</li>
</ul>
<h2 id="Hexo-相关报错"><a href="#Hexo-相关报错" class="headerlink" title="Hexo 相关报错"></a>Hexo 相关报错</h2><ul>
<li>hexo d中报443Time out错误，尝试翻墙解决</li>
<li>hexo d中报Connection was reset, errno 10054，使用hexo clean、hexo g、hexo d重走一套流程解决</li>
<li>若本机过久没和 github 建立连接，则会连接失败。重新请求 ssh key 并更新到 github 即可。<a target="_blank" rel="noopener" href="https://blog.csdn.net/Candle_light/article/details/114992784">相关链接</a></li>
</ul>
<hr>
<h1 id="Markdown"><a href="#Markdown" class="headerlink" title="Markdown"></a>Markdown</h1><blockquote>
<p>参考<br><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/399e5a3c7cc5">.MD语法入门</a><br><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/de9c98bba332">Markdown语法</a><br><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/75028c4adfcf">Markdown 实现”多级有序列表”(非完美)</a><br><a target="_blank" rel="noopener" href="https://xianbai.me/learn-md/index.html">Learning-Markdown (Markdown 入门参考)</a></p>
</blockquote>
<h2 id="md-语法"><a href="#md-语法" class="headerlink" title="md 语法"></a>md 语法</h2><p><strong>md 插入图片的第四种方法</strong></p>
<ol>
<li>在blog全局配置文件_config.yml更改设置：<code>post_asset_folder: true</code></li>
<li>当该配置被应用后，使用hexo new命令创建新文章时，会生成相同名字的文件夹，也就是文章资源文件夹。在md文件中输入以下代码可成功引入图片：<code>&#123;% asset_img image.jpg 这是一张图片 %&#125;</code></li>
</ol>
<p><strong>md 使用多级列表</strong><br>一级列表正常；二级列表：空格 + tab</p>
<p><strong>md 段落内换行</strong></p>
<ul>
<li>在要换行的地方输入<code>&lt;br&gt;</code>（该方法使用表格内换行）</li>
<li>在要换行的地方输入两个空格，再换行</li>
</ul>
<p><strong>表格内指定表格宽度</strong></p>
<ul>
<li>在表格内添加<code>&lt;img width=200/&gt;</code>标签，标签后面接要输入的文本</li>
</ul>
<p><strong>行内添加空格</strong></p>
<ul>
<li>插入一个空格：<code>&amp;nbsp;</code> 或 <code>&amp;#160;</code></li>
<li>插入两个空格：<code>&amp;ensp;</code> 或 <code>&amp;#8194;</code></li>
<li>插入四个空格：<code>&amp;emsp;</code> 或 <code>&amp;#8195;</code></li>
</ul>
<p><strong>插入一行可横向滑动的框框</strong></p>
<ul>
<li>换行 + tab</li>
</ul>
<hr>
<h1 id="终端命令"><a href="#终端命令" class="headerlink" title="终端命令"></a>终端命令</h1><blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/67513308">win 常用命令</a></p>
</blockquote>
<ul>
<li>mac 从终端进入移动硬盘：<code>cd ../</code> -&gt; <code>cd volumes</code>，即可看到移动硬盘目录。</li>
<li>win 从终端进入移动硬盘：<code>F:</code></li>
<li>文件夹开头带 . 即为隐藏文件夹（mac 和 win 都是，但 mac 仅能通过终端 mkdir 创建该类型文件夹）。mac 显示隐藏文件夹快捷键 <code>shift + command + .</code></li>
<li>win 进入终端：<code>win + R</code> -&gt; 输入 cmd；</li>
<li>win 指定文件夹下进入终端：<ul>
<li>在当前文件夹下，按住 shift 键 + 鼠标右击</li>
<li>在文件夹地址栏输入 cmd</li>
</ul>
</li>
</ul>
<hr>
<h1 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h1><blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/default7/article/details/100068256">git 设置代理的方法</a></p>
</blockquote>
<h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><ol>
<li>下载默认分支：<code>git clone &quot;ssh 地址&quot;</code>，如<code>git clone git@github.com:apache/rocketmq.git</code></li>
<li>下载指定分支：<code>git clone --branch 7.9 --single-branch https://github.com/elastic/logstash.git；</code>–branch 后是分支名</li>
<li>将远程分支更新到本地所在分支：<ul>
<li>默认远程同名分支：<code>git pull</code></li>
<li>指定远程分支：<code>git pull origin master</code>（master 为远程分支）</li>
</ul>
</li>
<li>将远程分支更新到本地指定分支：<code>git pull (--force) origin master:master</code>（第一个 master 为远程分支，第二个为本地已有分支）</li>
<li>将远程分支下载到本地新分支（本地分支将被新建）：<code>git fetch origin master:zourx</code>（将远程 master 分支下载到本地 zourx 分支）</li>
<li>查看本地历史变更记录：<code>git reflog</code>。</li>
<li>回退本地版本到指定的引用位置：<code>git reset --hard 40a9a83</code>。40a9a83 是某次变更记录的引用</li>
</ol>
<h2 id="上传"><a href="#上传" class="headerlink" title="上传"></a>上传</h2><ol>
<li>将本地文件夹初始化为 git 可管理的仓库：<code>git init</code>；</li>
<li>将本地仓库与远程仓库关联：<code>git remote add origin ssh</code>，如<code>git remote add origin git@github.com:apache/rocketmq.git</code></li>
<li>将文件添加到本地仓库：<code>git add . </code>（. 意味着整个项目的文件添加到仓库，若将 . 改为指定文件名，则添加指定文件到本地仓库）</li>
<li>评论此次仓库更新的内容：<code>git commit -m &quot;对文件的评注&quot;</code></li>
<li>将本地仓库的内容推送到远程：<code>git push origin 本地分支:远程分支</code>，如<code>git push origin master:feature/20210915_add_game_dim</code>。</li>
</ol>
<h2 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h2><ol>
<li>删除本地分支：<code>git branch -d 分支名</code>，如<code>git branch -d zourx</code></li>
<li>删除远程分支：<code>git push origin --delete 远程分支名</code>，如<code>git push origin --delete zourx</code>。</li>
</ol>
<h2 id="对本地分支的操作"><a href="#对本地分支的操作" class="headerlink" title="对本地分支的操作"></a>对本地分支的操作</h2><ol>
<li>查看冲突（查看当前分支与本地 master 分支的冲突）：<code>git rebase master</code>（在 idea 的 git 工具的 resolve conflicts 可查看发生冲突的文件。）</li>
<li>比较当前分支与本地 master 分支：<code>git diff master</code></li>
<li>合并 master 分支到当前分支：<code>git merge master</code></li>
<li>将暂存区和工作区都回退到上一次版本，并删除所有修改信息：<code>git reset --hard</code></li>
<li>新建并切换到该分支：<code>git checkout -b zourx</code> – 新建 zourx 分支并切换到该分支</li>
<li>重命名本地分支：<code>git branch -m oldName newName</code>（对于远程分支，建议删除后重新 push）</li>
</ol>
<h2 id="Github"><a href="#Github" class="headerlink" title="Github"></a>Github</h2><ol>
<li>目前终端登录 github 不再使用账号密码，而是用的 github 生成的 token（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），这个 token 会一直有效，在 mac 中的“钥匙串访问”中配置。</li>
<li>这个 token 在使用了 git 后不能再应用在 hexo 中（应用在 hexo 时“钥匙串访问“中该 token 会消失），采用新建 token 解决</li>
</ol>
<hr>
<h1 id="IDEA"><a href="#IDEA" class="headerlink" title="IDEA"></a>IDEA</h1><ol>
<li>从 git 新下载仓库，idea 打开后 build 无错误，但代码中 import 错误。分两种情况讨论：<ol>
<li>若 import 的是同一项目空间内代码报错，可能是 idea 缓存索引错误。在 file -&gt; invalidate caches 中，清除 idea 缓存，重启后即可；</li>
<li>若 import 的是不同项目空间内代码报错，可能是没有相应 jar 包。通过报错空间（或 root 空间）maven 工具的 clean、package，打包新的 jar 包，即可。</li>
</ol>
</li>
</ol>
<hr>
<h1 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h1><blockquote>
<p>幂等性：一个幂等操作的特点是执行一次或执行多次所产生的影响和执行一次所产生的影响相同<br><a target="_blank" rel="noopener" href="https://www.1024sou.com/article/542603.html">Kafka 原理分析之基础篇</a></p>
</blockquote>
<h2 id="Kafka-是什么"><a href="#Kafka-是什么" class="headerlink" title="Kafka 是什么"></a>Kafka 是什么</h2><p>Kafka 是一个分布式流式处理平台，拥有高吞吐（但不支持 topic 消息有序）、可持久化、可水平扩展、支持流数据处理等特性。<br><strong>整体可划分三个模块：</strong>  </p>
<ol>
<li>消息系统</li>
<li>存储系统</li>
<li>流式处理平台</li>
</ol>
<p><strong>典型结构</strong><br>一个典型的 kafka 体系架构包括若干 producer、若干 broker、若干 consumer，以及一个 ZooKeeper 集群。</p>
<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/kafka_1.jpg" class="">

<h2 id="ZooKeeper"><a href="#ZooKeeper" class="headerlink" title="ZooKeeper"></a>ZooKeeper</h2><p>ZooKeeper 负责 Kafka 集群元数据的管理、控制器的选举等操作。</p>
<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/Kafka_2.jpg" class="">

<h2 id="Producer"><a href="#Producer" class="headerlink" title="Producer"></a>Producer</h2><p>生产者，将消息发送到 Broker。</p>
<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/Kafka_3.jpg" class="">
<p>构造生产者及生产消息示例代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaProducerAnalysis</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String brokerList = <span class="string">&quot;localhost:9092&quot;</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String topic = <span class="string">&quot;topic-demo&quot;</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Properties <span class="title">initConfig</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);   <span class="comment">// broker 地址</span></span><br><span class="line">        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        props.put(ProducerConfig.CLIENT_ID_CONFIG, <span class="string">&quot;producer.client.id.demo&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> props;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Properties props = initConfig();</span><br><span class="line">        KafkaProducer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);</span><br><span class="line">        ProducerRecord&lt;String, String&gt; record = <span class="keyword">new</span> ProducerRecord&lt;&gt;(topic, <span class="string">&quot;hello, Kafka!&quot;</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            producer.send(record);   <span class="comment">// 返回类型为 Future&lt;RecordMetadata&gt;</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中 ProducerRecord 的成员变量如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProducerRecord</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String topic;   <span class="comment">// 主题（必填）</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Integer partition;   <span class="comment">// 分区号</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Headers;   <span class="comment">// 消息头部</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> K key;   <span class="comment">// 键</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span>  V value;   <span class="comment">// 值（必填）</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Long timestamp;   <span class="comment">// 消息的时间戳</span></span><br><span class="line">    <span class="comment">// 省略其他成员方法和构造方法</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Producer-参数配置"><a href="#Producer-参数配置" class="headerlink" title="Producer 参数配置"></a>Producer 参数配置</h3><table>
<thead>
<tr>
<th align="center">参数</th>
<th align="center">含义</th>
<th align="center">默认值</th>
<th align="center">是否必填</th>
<th align="center">备注</th>
</tr>
</thead>
<tbody><tr>
<td align="center">bootstrap.servers</td>
<td align="center">指定生产者客户端连接 kafka 集群所需的 broker 地址清单，如 host1:port1, host2:port2</td>
<td align="center">“”</td>
<td align="center">是</td>
<td align="center">并非需要所有 broker 的地址，但设置至少两个及以上</td>
</tr>
<tr>
<td align="center">key.serializer 和 value.serializer</td>
<td align="center">broker 端接收的消息必须以字节数组(byte[])的形式存在。这两个参数分别用来指定 key 和 value 序列化操作的序列化器，以将 key 和 value 转化为字节数组</td>
<td align="center">无</td>
<td align="center">是</td>
<td align="center">需填写序列化器的全限定名，也可写成 StringSerializer.class.getName()</td>
</tr>
<tr>
<td align="center">client.id</td>
<td align="center">设定 KafkaProducer 对应的客户端 id</td>
<td align="center">“”</td>
<td align="center">否</td>
<td align="center">若不填，KafkaProducer 会自动生成形如“producer-1“的非空字符串</td>
</tr>
<tr>
<td align="center">acks</td>
<td align="center">指定分区中必须要有多少个副本收到这条消息，之后生产者才认为这条消息是成功写入的</td>
<td align="center">1</td>
<td align="center">否</td>
<td align="center">acks 参数类型需是字符串。可为 1、0、(-1 和 all)（都是等待所有副本成功写入才能收到服务端的响应</td>
</tr>
<tr>
<td align="center">max.request.size</td>
<td align="center">指定生产者客户端能发生的消息的最大值</td>
<td align="center">1048576B，即 1MB</td>
<td align="center"></td>
<td align="center">一般来说，默认值即足够满足多数场景，若要修改该参数，需同时修改 broker 端的 message.max.bytes 参数</td>
</tr>
<tr>
<td align="center">retries</td>
<td align="center">用来配置生产者重试的次数</td>
<td align="center">0</td>
<td align="center"></td>
<td align="center">默认在发生异常的时候不进行任何重试动作。重试可以解决如网络抖动、leader 副本选举带来的异常</td>
</tr>
<tr>
<td align="center">retry.backoff.ms</td>
<td align="center">设定两次重试之间的时间间隔</td>
<td align="center">100</td>
<td align="center"></td>
<td align="center">与 retries 参数搭配使用。需注意不能设置太小导致无效的频繁重试，不能设置太大导致生产者过早放弃重试</td>
</tr>
<tr>
<td align="center">compression.type</td>
<td align="center">指定消息的压缩方式</td>
<td align="center">none</td>
<td align="center"></td>
<td align="center">该参数还可以配置为“gzip”、“snappy”和“lz4”。消息压缩是一种使用时间换空间的优化方式</td>
</tr>
<tr>
<td align="center">connections.max.idle.ms</td>
<td align="center">指定在多久之后关闭限制的连接</td>
<td align="center">540000ms，即 9min</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">linger.ms</td>
<td align="center">指定生产者发生 ProducerBatch 之前等待更多消息（ProducerRecord）加入 ProducerBatch 的时间</td>
<td align="center">0</td>
<td align="center"></td>
<td align="center">生产者客户端会在 ProducerBatch 被填满或等待时间超过 linger.ms 值时发生出去。增大这个参数会增加消息的延迟，但能提升一定的吞吐量，该参数与 TCP 中的 Nagle 算法有异曲同工之妙</td>
</tr>
<tr>
<td align="center">receive.buffer.bytes</td>
<td align="center">设置 Socket 接收消息缓冲区（SO_RECBUF)的大小</td>
<td align="center">32768B，即 32KB</td>
<td align="center"></td>
<td align="center">若该值设为 -1，则使用操作系统的默认值</td>
</tr>
<tr>
<td align="center">send.buffer.bytes</td>
<td align="center">设置 Socket 发送消息缓冲区（SO_SNDBUF)的大小</td>
<td align="center">131072B，即 128KB</td>
<td align="center"></td>
<td align="center">若该值设为 -1，则使用操作系统的默认值</td>
</tr>
<tr>
<td align="center">request.timeout.ms</td>
<td align="center">配置 Producer 等待请求响应的最长时间</td>
<td align="center">30000(ms)</td>
<td align="center"></td>
<td align="center">请求超时之后可以选择进行重试。该参数需要比 broker 端参数 replica.lag.time.max.ms 值要大，这样可以减少因客户端重试而引起的消息重复的概率</td>
</tr>
</tbody></table>
<h3 id="batch-调优"><a href="#batch-调优" class="headerlink" title="batch 调优"></a>batch 调优</h3><table>
<thead>
<tr>
<th align="left">参数</th>
<th align="left">默认值</th>
<th align="left">取值范围</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left">batch.size</td>
<td align="left">16K</td>
<td align="left">&gt;=0</td>
<td align="left">单个parition对应的batch大小（bytes），缓存消息达到batch size之后，立即发送</td>
</tr>
<tr>
<td align="left">linger.ms</td>
<td align="left">0ms</td>
<td align="left">&gt;=0</td>
<td align="left">消息在batch中停留时间，达到linger.ms之后，立即发送</td>
</tr>
<tr>
<td align="left">buffer.memory</td>
<td align="left">32M</td>
<td align="left">&gt;=0</td>
<td align="left">producer缓存消息，总的可用memory空间，如果memory用完，produder会立刻发送缓存中的消息</td>
</tr>
</tbody></table>
<p><strong>如何设置参数</strong><br>linger.ms = 业务能接受的延迟，比如 1000ms，5000ms<br>batch.size = 单个 producer 的消息 qps * 消息大小 * liner.ms / partition 数<br>buffer.memory &gt;= batch.size * partition数 * 2；buffer.memory 较小，可能会造成 batch 失效，qps 反而更高</p>
<h3 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h3><ul>
<li>KafkaProducer 是线程安全的，可以在多个线程中共享单个 KafkaProducer 实例，也可以将 KafkaProducer 实例进行池化供其他线程调用。</li>
<li>若在创建 KafkaProducer 实例时没有设定 key/value.serializer 这两个配置参数，那么就需要在构造方法中添加对应的序列化器。如<code>KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props, new StringSerializer(), new StringSerializer());</code></li>
<li>生产者客户端的整体架构</li>
</ul>
<h3 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h3><ul>
<li>消息入流 qps、消息出流 qps；</li>
<li>请求 qps；</li>
<li>batch size 大小（消息条数）；</li>
</ul>
<h2 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a>Broker</h2><p>服务代理节点。负责将收到的消息存储到磁盘中。一个或多个 Broker 组成了一个 Kafka 集群。</p>
<h2 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h2><p>消费者，接收信息的一方。负责从 Broker 订阅并消费消息（基于拉模式）。</p>
<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/Kafka_4.jpg" class="">

<h2 id="Kafka-基础概念"><a href="#Kafka-基础概念" class="headerlink" title="Kafka 基础概念"></a>Kafka 基础概念</h2><h3 id="主题与分区"><a href="#主题与分区" class="headerlink" title="主题与分区"></a>主题与分区</h3><p>主题（topic）是逻辑上的概念，分区（partition）在存储层面可看作一个可追加的日志文件。一个 topic 包含一个或多个 partition，但一个 partition 只属于单个 topic。<br>消息在写入某个 topic 时，实际上写入的是 topic 的某个 partition（根据分区规则决定）。消息在被追加到日志文件的时候都会被分配一个特定的偏移量（offset），用来保证消息在分区的顺序性。Kafka 保证分区有序而不是主题有序。分区规则有如下四种：</p>
<ol>
<li>specify partition</li>
<li>random</li>
<li>key hash</li>
<li>custom</li>
</ol>
<h3 id="多副本机制"><a href="#多副本机制" class="headerlink" title="多副本机制"></a>多副本机制</h3><p><strong>作用：</strong></p>
<ol>
<li>提供数据冗余（主要作用）</li>
<li>提供高伸缩性</li>
<li>改善数据局部性</li>
</ol>
<p><strong>基本概念</strong></p>
<ul>
<li>ISR：In-Sync Replics，分区（Partition）中处于同步状态的副本列表。</li>
<li>OSR：Out-of-Sync Replicas，分区中处于同步滞后过多状态的副本列表。</li>
<li>AR = ISR + OSR。</li>
<li>LEO：Log End Offset，各副本中最新消息的 Offset。</li>
<li>HW：High Watermark，高水位，由 partiton 中所有副本的最小 LEO 决定。</li>
<li>同一分区中的不同副本保存的是相同的消息（但在同一时刻，副本之间并非完全一样），副本处于不同的 broker 中，副本之间是“一主多从”关系。</li>
</ul>
<p><strong>Leader 副本</strong></p>
<ul>
<li>leader 副本负责处理读写请求。</li>
<li>leader 副本负责维护和跟踪 ISR 集合中所有 follower 副本的滞后状态。当 follower 副本落后太多或失效时，leader 副本会将其从 ISR 集合中剔除；如果 OSR 集合中有副本“追上”了 leader 副本，则 leader 副本会将它从 OSR 集合转移至 ISR 集合。可通过 Broker 端参数 replica.lag.time.max.ms 配置，默认是 10s。</li>
<li>默认情况下，当 leader 副本出现故障时，只有 ISR 集合中的副本才有资格被选举为新的 leader。但可通过 Broker 端参数 unclean.leader.election.enable 修改，即允许 OSR 列表中的副本参与 leader 选举，此称为 Unclean 领导者选举。该参数开启后，虽然保证了高可用性，但会导致数据丢失（LEO 与元 HW 相距过大，但同时 producer 不再发送这部分的间隙数据），因此不建议开启。</li>
</ul>
<p><strong>Follower 副本</strong></p>
<ul>
<li>follower 副本只负责与 leader 异步拉取消息。</li>
<li>follower 副本每次 fetch（拉取）只能更新上一次 fetch 后的 HW 值：follower fetch leader 时捎带了自身了 LEO，leader 更新 remote LEO，并根据所有副本的 LEO 更新 HW，并复制消息给 follower，更新 follower 的 HW 值。</li>
</ul>
<h3 id="特性与实现"><a href="#特性与实现" class="headerlink" title="特性与实现"></a>特性与实现</h3><ul>
<li>负载均衡：同一 topic 的不同消息分配到不同 partition，不同 partition 分配到不同机器。</li>
<li>可靠性：同一 partition 的不同副本分配到不同的机器</li>
<li>数据一致性：副本区分 leader 和 follower，producer 和 consumer 只和 leader 进行交互，follower 则不停地从 leader 同步数据。</li>
</ul>
<h3 id="数据安全"><a href="#数据安全" class="headerlink" title="数据安全"></a>数据安全</h3><ul>
<li>producer 端：为了让用户设置数据可靠性， Kafka 在 Producer 里面提供了消息确认机制。可以在定义 Producer 时通过 acks 参数指定，该参数有三个枚举值：<ul>
<li>acks = 0：意味着如果生产者能够通过网络把消息发送出去，那么就认为消息已成功写入 Kafka，不必等待 broker 端确认；</li>
<li>acks = 1：意味若 Leader 在收到消息并把它写入到分区数据文件（不一定同步到磁盘上）时会返回确认或错误响应。</li>
<li>acks = all（这个和 request.required.acks = -1 含义一样）：意味着 Leader 在返回确认或错误响应之前，会等待所有同步副本都收到悄息。如果和 min.insync.replicas 参数结合起来，就可以决定在返回确认前至少有多少个副本能够收到悄息，生产者会一直重试直到消息被成功提交。</li>
</ul>
  <strong>producer 若想保证数据不丢失，则 acks 需为 all；否则若 leader 在发送确认后，follower 在同步新消息完成前 leader 挂掉，则在 HW 和新 commit 的 ofset 间存在数据丢失的情况。</strong></li>
<li>consumer 端：限制 consumer 只能读 HW(High Water Mark) 之前的数据。HW 的值由 ISR 列表里偏移量最小的分区决定，这样一来，若 leader 挂掉，重新推举出的 leader 仍能继续向 consumer 提供服务，<strong>并保证数据不被重复消费</strong>。<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/Kafka_6.jpg" class=""></li>
<li>broker 端：基于 Topic 分区副本，当分区 leader 挂掉后，kafka 会从 ISR(in-sync replicas) 列表中选举一个 follower 成为新的 leader，<strong>保证对外继续提供服务。但对于 producer 和 consumer 端的影响，可参考上面二者的讲解。</strong></li>
</ul>
<h3 id="性能分析"><a href="#性能分析" class="headerlink" title="性能分析"></a>性能分析</h3><ul>
<li>攒 batch：即Producer 端将多个小消息合并，批量发向 Broker 的能力。kafka 采用异步发送的机制，当发送一条消息时，消息并没有发送到 broker 而是缓存起来，然后直接向业务返回成功，当缓存的消息达到一定数量时再批量发送。此时减少了网络 io，从而提高了消息发送的性能，但是如果消息发送者宕机，会导致消息丢失，业务出错，所以理论上 kafka 利用此机制提高了 io 性能却降低了可靠性。<br>  <strong>为什么 flink 的攒 batch 不会导致消息丢失？</strong><br>  flink 本质只是两个 kafka 之间的数据处理引擎，且由于它是在 checkpoint 完成后才向 producer kafka commit offset；因此若 flink 宕机或重启导致攒 batch 的消息丢失，但由此导致的 checkpoint 失败会让 flink 从上一次成功的 checkpoint 中 commit 的 offset 处重新消费，所以数据并没有丢失，而是可能发生重复（因为部分数据可能已经发送到 kafka 中了）。<br>  <strong>为什么 RocketMQ 不在 Producer 端攒 batch？</strong><ul>
<li>RocketMQ 使用 Java 编写，缓存过多容易导致 GC。</li>
<li>Producer 调用发送消息接口，消息未被发送到 Broker 就向业务返回成功，若此时 Producer 宕机，会导致消息丢失，业务出错。</li>
</ul>
</li>
<li>顺序写入：减少了寻址花费的时间。每个 Partition 其实都是一个文件，收到消息后 Kafka 会把数据插入到文件末尾。但这样 kafka 无法删除数据，因此 kafka 会把所有数据保留下来，每个消费者对每个 topic 的各 partition 都有一个 offset 指示读到了第几条数据。同时 kafka 提供了两种策略来删除数据：一是基于时间；二是基于 partition 文件的大小。</li>
<li>MMap：即 Memory Mapped Files（内存映射文件），Kafka 的数据不是实时的写入硬盘，它先写入内存，操作系统会在程序主动调用 flush 的时候才把数据真正的写到硬盘。Kafka 参数：producer.type 用来控制是否主动 flush：<ul>
<li>sync：如果 Kafka 写入到 mmap 之后就立即 flush 然后再返回 Producer 叫同步；</li>
<li>async：如果 Kafka 写入 mmap 之后立即返回 Producer 不调用 flush 叫异步。</li>
</ul>
</li>
<li>Zero Copy：<ul>
<li>传统模式下读硬盘文件：先复制到内核空间（read 是系统调用，放到了 DMA，所以用内核空间），然后复制到用户空间(1,2)；从用户空间重新复制到内核空间（你用的 socket 是系统调用，所以它也有自己的内核空间），最后发送给网卡（3、4）。<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/Kafka_7.jpg" class=""></li>
<li>Zero Copy 直接从内核空间（DMA的）到内核空间（Socket的），然后发送网卡。Java 的 NIO 提供了 FileChannle，它的 transferTo、transferFrom 方法就是 Zero Copy。<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/Kafka_8.jpg" class=""></li>
</ul>
</li>
</ul>
<hr>
<h1 id="RocketMQ"><a href="#RocketMQ" class="headerlink" title="RocketMQ"></a>RocketMQ</h1><blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/prestigeding/article/details/79156276">存储机制之 CommitLog、ConsumeQueue 和 index 文件</a></p>
</blockquote>
<ul>
<li>组成：<ul>
<li>Producer</li>
<li>Broker</li>
<li>NameServer</li>
<li>Consumer</li>
</ul>
</li>
<li>存储过程<ul>
<li>CommitLog：producer 发送消息到 topic，实质是发送到某 broker 的 commitlog（一个 broker 只有一个 commitlog，不同 topic 的消息统一存储到一个 commitlog）。commitlog 的底层存储是 mappedFileQueue  里的 mappedFile，使用 mmap 技术实现同步/异步刷盘。</li>
<li>ConsumeQueue：消费者直接消费 commitlog 效率非常低下，因此引入 consumequeue。一个 topic 可以有多个 consumequeue，但一个 consumequeue 只属于一个 topic。消费者根据 consumequeue 的索引找到指定的 commitlog 及指定消息消费。ConsumeQueue 的消息存储格式如下：<ul>
<li>CommitLog Offset</li>
<li>size</li>
<li>Tag Hash 值</li>
</ul>
</li>
<li>Index File：用于根据消息 ID 来查找和消费指定消息。</li>
</ul>
</li>
</ul>
<hr>
<h1 id="SQL"><a href="#SQL" class="headerlink" title="SQL"></a>SQL</h1><h2 id="sql-关键词"><a href="#sql-关键词" class="headerlink" title="sql 关键词"></a>sql 关键词</h2><ul>
<li>partition by col：根据 col 的值对结果进行分区。</li>
<li>distinct：仅能应用于一个字段，若有多个字段，则是这多个字段组成的数据去重。</li>
<li>union 和 union all<br>UNION 操作符用于合并两个或多个 SELECT 语句的结果集，二者的使用有以下需要注意的点：<ul>
<li>UNION 内部的 SELECT 语句必须拥有相同数量的列</li>
<li>列也必须拥有相似的数据类型</li>
<li>每条 SELECT 语句中的列的顺序必须相同</li>
<li>UNION 结果集中的列名总是等于 UNION 中第一个 SELECT 语句中的列名<br>二者的区别如下：</li>
<li>UNION：默认地，UNION 操作符选取不同的值</li>
<li>UNION ALL：如果结果集中允许重复的值，请使用 UNION ALL</li>
</ul>
</li>
<li>where 和 having<br>Where 是一个约束声明，使用 Where 约束来自数据库的数据，Where 是在结果返回之前起作用的，Where 中不能使用聚合函数。<br>Having 是一个过滤声明，是在查询返回结果集以后对查询结果进行的过滤操作，在 Having 中可以使用聚合函数。Having 必须在 gruop by 后使用<br>在查询过程中聚合语句(sum,min,max,avg,count)要比 having 子句优先执行。而 where 子句在查询过程中执行优先级高于聚合语句。</li>
</ul>
<h2 id="sql-函数"><a href="#sql-函数" class="headerlink" title="sql 函数"></a>sql 函数</h2><ul>
<li>over()<ul>
<li>定义：开窗函数。OVER 用于为<strong>行（select 时的行）</strong>定义一个窗口，它对一组值进行操作，不需要使用 GROUP BY 子句对数据进行分组，能够在同一行中同时返回基础行的列和聚合列。</li>
<li>用法：OVER 开窗函数必须与聚合函数或排序函数一起使用，聚合函数一般指SUM(),MAX(),MIN,COUNT(),AVG()等常见函数。排序函数一般指RANK(),ROW_NUMBER(),DENSE_RANK(),NTILE()等。</li>
</ul>
</li>
<li>row_number()<br>ROW_NUMBER() 是一个 Window 函数，它为<strong>结果集的分区中</strong>的每一行分配一个连续的整数（不重复）。行号以每个分区中第一行的行号开头。需与 over() 搭配使用。</li>
<li>rank()<br>与 ROW_NUMBER() 函数类似，为<strong>结果集的分区中</strong>的每一行分配一个连续的整数（排名可重复）。同样需与 over() 搭配使用。</li>
<li>coalesce()<br><code>COALESCE(field1, field2, ..., fieldn)</code>，依次参考各字段，遇到非 null 值即停止并返回该值。如果所有的表达式都是 null，最终将返回一个 null。coalesce 里的参数的类型应统一。<br>类似 <code>coalesce(ad_id, 0)</code>。若字段值不为 null，则取字段值；否则取默认值 0。</li>
<li>concat_ws()<br>concat_ws(VARCHAR delimiter, ARRAY<VARCHAR> input)<ul>
<li>delimiter：VARCHAR 类型，连接符</li>
<li>input：ARRAY 类型，需要进行连接操作的对象。<br>作用：将一个 ARRAY 进行连接操作, 每个元素间通过连接符连接，返回一个连接后的字符串。</li>
</ul>
</li>
<li>concat()<br>concat(ARRAY<VARCHAR> input)<ul>
<li>input：ARRAY 类型，需要进行连接操作的对象。<br>作用：将一个 ARRAY 进行连接操作, 返回一个连接后的字符串,连接符为空字符串””。</li>
</ul>
</li>
<li>unix_timestamp()<ul>
<li>UNIX_TIMESTAMP()：若无参数调用，则返回一个 Unix timestamp (‘1970-01-01 00:00:00’ GMT 之后的秒数) 作为无符号整数，得到当前时间戳。</li>
<li>UNIX_TIMESTAMP(date) ：若将 date 作为参数传入 UNIX_TIMESTAMP()，它会将 date 以’1970-01-01 00:00:00’ GMT后的秒数的形式返回。date 可以是一个 DATE 字符串、一个 DATETIME字符串、一个 TIMESTAMP或一个当地时间的 YYMMDD 或 YYYMMDD 格式的数字。</li>
</ul>
</li>
<li>from_unixtime()<br>from_unixtime(time,’yyyy-MM-dd HH:mm:ss’) 。其中 time 是 10 位的时间戳值，即 1970-1-1 至今的秒，而 13 位的毫秒的是不可以的；’yyyy-MM-dd HH:mm:ss’ 是 time 要转换输出的格式。</li>
</ul>
<hr>
<h1 id="Flink"><a href="#Flink" class="headerlink" title="Flink"></a>Flink</h1><blockquote>
<p><a target="_blank" rel="noopener" href="https://developer.aliyun.com/article/783112">Flink 执行引擎：流批一体的融合之路</a></p>
</blockquote>
<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_44318830/article/details/113149695">干货 | 13道精选Flink面试题</a><br><a target="_blank" rel="noopener" href="https://jishuin.proginn.com/p/763bfbd2b5a6">Flink 面试题大全(建议收藏)</a></p>
</blockquote>
<ul>
<li>flink 压测：设计 kafka - flink - kafka 数据链路。先停止 flink 任务，在上游 kafka 积攒数据；然后启动 flink 任务，观察下游 kafka 最大输入 qps，即为 flink 最大能承受 qps。</li>
<li>flink 流批一体：意味着计算引擎同时具备流计算的低延迟和批计算的高吞吐高稳定性，提供统一编程接口开发两种场景的应用并保证它们的底层执行逻辑是一致的。<ul>
<li>流处理：接收一条数据处理一条数据；</li>
<li>批处理：积累数据到一定程度后再处理。</li>
<li>流批独立方案的问题：<ul>
<li>数据链路冗余。在很多的场景下，流和批计算内容其实是一致，但是由于是两套系统，所以相同逻辑还是需要运行两遍，产生一定的资源浪费。</li>
<li>人力成本比较高。由于流和批是两套系统，相同的逻辑需要两个团队开发两遍。</li>
<li>数据口径不一致。这个是用户遇到的最重要的问题。两套系统、两套算子，两套 UDF，一定会产生不同程度的误差，这些误差给业务方带来了非常大的困扰。这些误差不是简单依靠人力或者资源的投入就可以解决的。</li>
</ul>
</li>
<li>flink 流批一体实现：<ul>
<li>Runtime 层是统一的流处理；</li>
<li>上面分别有独立的 DataStream 和 DataSet 两个 API，两者基于不同的任务类型（Stream Task/Batch Task）和 UDF 接口（Transformation/Operator）。<ul>
<li>好处：允许 Flink 在执行层面仍沿用批处理的优化技术，并简化掉架构移除掉不需要的 watermark、checkpoint 等特性。<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/flink_6.png" class=""></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>spark 和 flink 的区别<ul>
<li>设计理念<ul>
<li>Spark 的技术理念是使用微批来模拟流的计算，基于 Micro-batch，数据流以时间为单位被切分为一个个批次，通过分布式数据集 RDD 进行批量处理，是一种伪实时。</li>
<li>Flink 是基于事件驱动的，是面向流的处理框架，Flink 基于每个事件一行一行地流式处理，是真正的流式计算. 另外他也可以基于流来模拟批进行计算实现批处理。</li>
</ul>
</li>
<li>吞吐量和延迟<ul>
<li>spark 是基于微批的，而且流水线优化做的很好，所以说他的吞入量是最大的，但是付出了延迟的代价，它的延迟是秒级；</li>
<li>而 Flink 是基于事件的，消息逐条处理，而且他的容错机制很轻量级，所以他能在兼顾高吞吐量的同时又有很低的延迟，它的延迟能够达到毫秒级。（若下游是 kafka，则通过攒 batch，吞吐量实际上比 spark 更高）</li>
</ul>
</li>
<li>checkpoint：<ul>
<li>spark streaming 的 Checkpoint 仅仅是针对 driver 的故障恢复做了数据和元数据的 Checkpoint。只能保证数据不丢，但可能重复。</li>
<li>flink 的 checkpoint 采用的是轻量级的分布式快照，实现了每个算子的快照，及流动中的数据的快照。能保证 Exactly Once 语义。</li>
</ul>
</li>
<li>flink 优点：低延迟、高吞吐量、对流式数据应用场景的支持较好。</li>
</ul>
</li>
<li>flink checkpoint：一种由 Flink 自动执行的快照，本质是容错恢复机制。<ul>
<li>流程：<ol>
<li>每个需要 checkpoint 的应用在启动时，Flink 的 JobManager 为其创建一个 Checkpoint Coordinator（检查点协调器），Checkpoint Coordinator全权负责本应用的快照制作。</li>
<li>Checkpoint Coordinator 周期性的向该流应用的所有 source 算子发送 barrier（barrier 包含当前 checkpoint 的 ID）。</li>
<li>当 source 算子收到 barrier 时，会暂停数据处理过程（接收数据但缓存），然后把自己的当前状态制作成快照，并保存到指定的持久化存储中。最后向 Checkpoint Coordinator 报告自己快照制作情况，同时向自身所有下游算子广播该 barrier，恢复数据处理。（此为同步，也可异步处理）</li>
<li>同理其他算子。每个算子按步骤 3 制作快照并向下游广播 barrier，直到 barrier 传递到 sink 算子，快照制作完成。</li>
<li>当 Checkpoint Coordinator 收到所有算子的报告之后，认为该周期的快照制作成功；否则，如果在规定的时间内没有收到所有算子的报告，则认为本周期快照制作失败。</li>
</ol>
</li>
<li>StateBackend：状态后端<ul>
<li>MemoryStateBackend： 默认，小状态，本地调试使用。<ul>
<li>state 存储：TaskManager 内存中；</li>
<li>checkpoint 存储：JobManager 内存中。</li>
</ul>
</li>
<li>FsStateBackend：大状态，长窗口，高可用场景。<ul>
<li>state 存储：TaskManager 内存中；</li>
<li>checkpoint 存储：可靠的外部存储文件系统中。本地测试可以是 LocalFs，测试生产用 HDFS。</li>
</ul>
</li>
<li>RocksDBStateBackend：超大状态，长窗口，高可用场景，支持增量 checkpoint（sink 快照完成后，RocksDB 会全量刷盘，然后 flink 再选择没有上传的文件进行备份）。<ul>
<li>state 存储：TaskManager 内存数据库 RocksDB 中。RocksDB 是一个 key/value 内存存储系统，和其他的 key/value 一样，先将状态放到内存中，如果内存快满时，则写入到磁盘中。类似 Redis 内存数据库。</li>
<li>checkpoint 存储：外部文件系统。</li>
</ul>
</li>
</ul>
</li>
<li>语义<ul>
<li>At Most Once：不开启 checkpoint 时，即为 At Most Once；</li>
<li>Exactly Once：开启 checkpoint 时，各 subTask 需对齐 barrier 后，才进行快照。在对齐 barrier 前，快流的数据被缓存起来。</li>
<li>At Least Once：开启 checkpoint 时，各 subTask 无需对齐 barrier。若快流 barrier 先到达，数据继续处理，直到所有 barrier 到达后进行快照。则在快流 barrier 到达后、慢流 barrier 到达前的快流数据存在重复。比如若 barrier-100 在 source 对齐，但在某个 operator task 没对齐，operator task 消费了部分 barrier-101 的数据，在完成 checkpoint-100 后，任务挂了，则从 barrier-100 的 offset 开始消费，但是没对齐的 operator task 对部分 barrier-101 的数据会重复消费。</li>
</ul>
</li>
</ul>
</li>
<li>flink WaterMark：用于处理乱序事件。<ul>
<li>时间概念：<ul>
<li>Event Time：事件时间。事件在现实世界中发生的时间，它通常由事件中的时间戳描述。</li>
<li>Ingestion Time：提取时间。数据进入 Apache Flink 流处理系统的时间，也就是 Flink 读取数据源时间。</li>
<li>Processing Time：处理时间。数据流入到具体某个算子 (消息被计算处理) 时候相应的系统时间。也就是 Flink 程序处理该事件时当前系统时间。</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li>flink savepoint：Flink Savepoint 你可以把它当做在某个时间点程序状态全局镜像，以后程序在进行升级，或者修改并发度等情况，还能从保存的状态位继续启动恢复。Flink Savepoint 一般存储在 HDFS 上面，它需要用户主动进行触发。如果是用户自定义开发的实时程序，比如使用DataStream进行开发，建议为每个算子定义一个 uid，这样我们在修改作业时，即使导致程序拓扑图改变，由于相关算子 uid 没有变，那么这些算子还能够继续使用之前的状态，如果用户没有定义 uid ， Flink 会为每个算子自动生成 uid，如果用户修改了程序，可能导致之前的状态程序不能再进行复用。</li>
</ul>
<h2 id="Flink-程序执行流程"><a href="#Flink-程序执行流程" class="headerlink" title="Flink 程序执行流程"></a>Flink 程序执行流程</h2><ol>
<li>获取执行环境</li>
<li>加载、创建初始数据  source</li>
<li>转换数据  transformation</li>
<li>放置计算结果位置  sink</li>
<li>触发程序运行</li>
</ol>
<h2 id="内存模型"><a href="#内存模型" class="headerlink" title="内存模型"></a>内存模型</h2><h3 id="JobManager-内存模型"><a href="#JobManager-内存模型" class="headerlink" title="JobManager 内存模型"></a>JobManager 内存模型</h3><p>1.9 与 1.11 JobManager 内存模型变化如下图所示，两个版本之间最大的变化是：</p>
<ul>
<li>1.9 中只有堆内、堆外两个模块；</li>
<li>1.11 中将 1.9 的堆外部分细分为 Direct Memory、JVM Metaspace 和 JVM Overhead 三类；<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/flink_3.jpg" class=""></li>
</ul>
<p><strong>JM 内存配置</strong></p>
<table>
<thead>
<tr>
<th align="left">内存模块</th>
<th align="left">参数</th>
<th align="left">含义</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Total Process Memory</td>
<td align="left">jobmanager.memory.process.size</td>
<td align="left">Dorado 平台配置的 JM 内存值就指的是这个值，也就是申请 container 时配置的内存</td>
</tr>
<tr>
<td align="left">Total Flink Memory</td>
<td align="left">jobmanager.memory.flink.size</td>
<td align="left">主要是框架和用户作业代码需要的内存，不包括 JVM Metaspace and other Overhead 部分</td>
</tr>
<tr>
<td align="left">JVM Heap</td>
<td align="left">jobmanager.memory.heap.size</td>
<td align="left">JM JVM 启动时设置 heap 大小</td>
</tr>
<tr>
<td align="left">Off-heap memory</td>
<td align="left">jobmanager.memory.off-heap.size</td>
<td align="left">-XX:MaxDirectMemorySize 限制的内存，主要是应用程序调用 native 方法使用的，包括 JM 网络通信的部分（akka），默认值是 128MB</td>
</tr>
<tr>
<td align="left">JVM Metaspace</td>
<td align="left">jobmanager.memory.jvm-metaspace.size</td>
<td align="left">-XX:MaxMetaspaceSize 限制的内存，主要用于 class load 相关（从 JDK8 开始，类的一些元数据放在叫做 Metaspace 的 Native Memory 中），默认值 256m</td>
</tr>
<tr>
<td align="left">JVM Overhead</td>
<td align="left">jobmanager.memory.jvm-overhead.min: 192m<br>jobmanager.memory.jvm-overhead.max: 1g<br>jobmanager.memory.jvm-overhead.fraction: 0.1</td>
<td align="left">保留给 JVM 其他的内存开销，例如：Thread Stack、code cache、GC 回收空间等</td>
</tr>
</tbody></table>
<h3 id="TaskManager-内存模型"><a href="#TaskManager-内存模型" class="headerlink" title="TaskManager 内存模型"></a>TaskManager 内存模型</h3><p>1.9 与 1.11 TaskManager 内存模型变化如下如所示，两个版本之间最大的变化是：</p>
<ul>
<li>1.9 中 Managed Memory 是在 heap 中管理，1.11 中单独在堆外进行管理；</li>
<li>1.11 中 RocksDB Backend 使用的内存也在 Managed Memory 中进行管理；</li>
<li>与 JM 类似，JVM MetaSpace 和 JVM Overhead 也单独区分了出来。<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/flink_4.jpg" class=""></li>
</ul>
<p><strong>TM 内存配置</strong></p>
<table>
<thead>
<tr>
<th align="left">模块</th>
<th align="left">参数</th>
<th align="left">含义</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Total process Memory</td>
<td align="left">taskmanager.memory.process.size</td>
<td align="left">TM 总的内存大小配置，也就是 Dorado 配置的 TM 内存信息</td>
</tr>
<tr>
<td align="left">Total Flink Memory</td>
<td align="left">taskmanager.memory.flink.size</td>
<td align="left">Task Executor 消耗的所有内存，也就是除了 JVM Metaspace 和 JVM Overhead 其他的加在一起就是 Total Flink Memory</td>
</tr>
<tr>
<td align="left">Framework Heap Memory</td>
<td align="left">taskmanager.memory.framework.heap.size: 128MB</td>
<td align="left">Task Executor(TaskManager 框架)本身所配置的堆内存大小</td>
</tr>
<tr>
<td align="left">Task Heap Memory</td>
<td align="left">taskmanager.memory.task.heap.size</td>
<td align="left">专门用于执行 Flink 任务的堆内存空间</td>
</tr>
<tr>
<td align="left">Managed memory</td>
<td align="left">taskmanager.memory.managed.fraction: 0.25 * TotalFlinkMem</td>
<td align="left">Task Executor 管理的 off-heap 内存，主要用于排序、哈希表、中间结果缓存、RocksDB 的 backend</td>
</tr>
<tr>
<td align="left">Framework Off-heap Memory</td>
<td align="left">taskmanager.memory.framework.off-heap.size: 128MB</td>
<td align="left">Task Executor 保留的 off-heap memory，不会分配给任何 slot。</td>
</tr>
<tr>
<td align="left">Task Off-heap Memory</td>
<td align="left">taskmanager.memory.task.off-heap.size: 0</td>
<td align="left">Task Executor 执行的 Task 所使用的堆外内存。如果在 Flink 应用的代码中调用了 Native 的方法，需要用到分配到的这些 off-heap 内存</td>
</tr>
<tr>
<td align="left">Network Memory</td>
<td align="left">taskmanager.memory.network.min: 64MB<br>taskmanager.memory.network.max: 2Gb<br>taskmanager.memory.network.fraction: 0.3 * TotalFlinkMem</td>
<td align="left">用于网络传输的 Network Buffer</td>
</tr>
<tr>
<td align="left">JVM metaspace</td>
<td align="left">taskmanager.memory.jvm-metaspace.size: 256MB</td>
<td align="left">从 JDK 8 开始，JVM 把永久代拿掉了，类的一些元数据放在叫做 Metaspace 的 Native Memory</td>
</tr>
<tr>
<td align="left">JVM Overhead</td>
<td align="left">taskmanager.memory.jvm-overhead.min: 192MB<br>taskmanager.memory.jvm-overhead.max: 1GB<br>taskmanager.memory.jvm-overhead.fraction: 0.1 * TotalProcesskMem</td>
<td align="left">保留给 JVM 其他的内存开销。例如: Thread Stack、code cache、GC 回收空间等等</td>
</tr>
</tbody></table>
<h2 id="Exactly-once"><a href="#Exactly-once" class="headerlink" title="Exactly-once"></a>Exactly-once</h2><blockquote>
<p><a target="_blank" rel="noopener" href="https://www.ikeguang.com/?p=1955">Flink Exactly-once 实现原理解析</a><br>从结果上看（如聚合结果）是只处理了一次；但从实际处理来说，属于处理了至少一次。</p>
</blockquote>
<blockquote>
<p><strong>最多一次（At-most-Once）：</strong>用户的数据只会被处理一次，不管成功还是失败，不会重试也不会重发。<br><strong>至少一次（At-least-Once）：</strong>该语义下，系统会保证数据或事件至少被处理一次。如果中间发生错误或者丢失，那么会从源头重新发送一条然后进入处理系统，所以同一个事件或者消息会被处理至少一次。<br><strong>精确一次（Exactly-Once）：</strong>表示每一条数据只会被精确地处理一次，不多也不少。</p>
</blockquote>
<p>Flink 号称支持“端到端的精确一次”语义。它指的是 Flink 应用从 Source 端开始到 Sink 端结束，数据必须经过的起始点和结束点。Flink 自身是无法保证外部系统“精确一次”语义的，所以 Flink 若要实现所谓“端到端（End to End）的精确一次”的要求，那么外部系统必须支持“精确一次”语义；然后借助 Flink 提供的分布式快照和两阶段提交才能实现。</p>
<h3 id="分布式快照机制"><a href="#分布式快照机制" class="headerlink" title="分布式快照机制"></a>分布式快照机制</h3><blockquote>
<p>Flink 分布式快照的核心元素之一是 Barrier（数据栅栏）</p>
</blockquote>
<p><strong>Barrier</strong></p>
<ol>
<li>我们可以把 Barrier 简单地理解成一个标记</li>
<li>该标记是严格有序的，并且随着数据流往下流动。</li>
<li>每个 Barrier 都带有自己的 ID，Barrier 极其轻量，并不会干扰正常的数据处理。</li>
<li>因为 Flink 运行在分布式环境中，一个 operator 的上游会有很多流，每个流的 barrier n 到达的时间可能不一致。flink 对此的解决办法是：快流等慢流。<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/flink_1.jpg" class=""></li>
</ol>
<p><strong>异步和增量</strong><br>按照上面我们介绍的机制，每次在把快照存储到我们的状态后端时，如果是同步进行就会阻塞正常任务，从而引入延迟。因此 Flink 在做快照存储时，可采用异步方式。</p>
<p>此外，由于 checkpoint 是一个全局状态，用户保存的状态可能非常大，多数达 G 或者 T 级别。在这种情况下，checkpoint 的创建会非常慢，而且执行时占用的资源也比较多，因此 Flink 提出了增量快照的概念。也就是说，每次都是进行的全量 checkpoint，是基于上次进行更新的。</p>
<h3 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h3><ol>
<li>beginTransaction：在开启事务之前，我们在目标文件系统（状态后端）的临时目录中创建一个临时文件，后面在处理数据时将数据写入此文件；</li>
<li>preCommit：在预提交阶段，刷写（flush）文件，然后关闭文件，之后就不能写入到文件了，我们还将为属于下一个检查点的任何后续写入启动新事务；</li>
<li>commit：在提交阶段，我们将预提交的文件原子性移动到真正的目标目录中，请注意，这会增加输出数据可见性的延迟；（同时 sink kafka，这一起是一个原子操作）</li>
<li>abort：在中止阶段，我们删除临时文件。</li>
</ol>
<p><strong>在 checkpoint 中的应用</strong></p>
<ol>
<li>当 checkpoint 开始时，标志着 preCommit 阶段开始。<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/flink_7.png" class=""></li>
<li>checkpoint 完成后，preCommit 阶段结束。<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/flink_8.png" class=""></li>
<li>JobManager 为应用程序中的每个 operator 发出 Checkpoint 完成的回调通知，告知所有 operator Checkpoint 已经成功，这是两阶段提价协议的提交阶段。<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/flink_9.png" class=""></li>
</ol>
<h2 id="flink-反压"><a href="#flink-反压" class="headerlink" title="flink 反压"></a>flink 反压</h2><blockquote>
<p>参考：<a target="_blank" rel="noopener" href="https://developer.aliyun.com/article/727389">如何分析及处理 Flink 反压？</a></p>
</blockquote>
<blockquote>
<p>反压（backpressure）是实时计算应用开发中，特别是流式计算中，十分常见的问题。反压意味着数据管道中某个节点成为瓶颈，处理速率跟不上上游发送数据的速率，而需要对上游进行限速。由于实时计算应用通常使用消息队列来进行生产端和消费端的解耦，消费端数据源是 pull-based 的，所以反压通常是从某个节点传导至数据源并降低数据源（比如 Kafka consumer）的摄入速率。</p>
</blockquote>
<p>简单来说，Flink 拓扑中每个节点（Task）间的数据都以阻塞队列的方式传输，下游来不及消费导致队列被占满后，上游的生产也会被阻塞，最终导致数据源的摄入被阻塞。<br>Flink任务的组成由基本的“流”和“算子”构成，“流”中的数据在“算子”间进行计算和转换时，会被放入分布式的阻塞队列中。当消费者的阻塞队列满时，则会降低生产者的数据生产速度。</p>
<h3 id="反压的影响"><a href="#反压的影响" class="headerlink" title="反压的影响"></a>反压的影响</h3><p>反压并不会直接影响作业的可用性，它表明作业处于亚健康的状态，有潜在的性能瓶颈并可能导致更大的数据处理延迟。通常来说，对于一些对延迟要求不太高或者数据量比较小的应用来说，反压的影响可能并不明显，然而对于规模比较大的 Flink 作业来说反压可能会导致严重的问题。<br>这是因为 Flink 的 checkpoint 机制，反压还会影响到两项指标: checkpoint 时长和 state 大小。</p>
<ul>
<li>前者是因为 checkpoint barrier 是不会越过普通数据的，数据处理被阻塞也会导致 checkpoint barrier 流经整个数据管道的时长变长，因而 checkpoint 总体时间（End to End Duration）变长。</li>
<li>后者是因为为保证 EOS（Exactly-Once-Semantics，准确一次），对于有两个以上输入管道的 Operator，checkpoint barrier 需要对齐（Alignment），接受到较快的输入管道的 barrier 后，它后面数据会被缓存起来但不处理，直到较慢的输入管道的 barrier 也到达，这些被缓存的数据会被放到state 里面，导致 TashManager 内存使用率增大，可能导致 full GC 频繁甚至 OOM。</li>
</ul>
<p>这两个影响对于生产环境的作业来说是十分危险的，因为 checkpoint 是保证数据一致性的关键，checkpoint 时间变长有可能导致 checkpoint 超时失败，而 state 大小同样可能拖慢 checkpoint 甚至导致 OOM （使用 Heap-based StateBackend）或者物理内存使用超出容器资源（使用 RocksDBStateBackend）的稳定性问题。<br>因此，我们在生产中要尽量避免出现反压的情况（顺带一提，为了缓解反压给 checkpoint 造成的压力，社区提出了 FLIP-76: Unaligned Checkpoints 来解耦反压和 checkpoint）。</p>
<h3 id="定位反压节点"><a href="#定位反压节点" class="headerlink" title="定位反压节点"></a>定位反压节点</h3><p>要解决反压首先要做的是定位到造成反压的节点，这主要有两种办法:</p>
<ul>
<li>通过 Flink Web UI 自带的反压监控面板；</li>
<li>通过 Flink Task Metrics。</li>
</ul>
<p>前者比较容易上手，适合简单分析，后者则提供了更加丰富的信息，适合用于监控系统。因为反压会向上游传导，这两种方式都要求我们从 Source 节点到 Sink 的逐一排查，直到找到造成反压的根源原因</p>
<p><strong>通过 Task Metrics 定位反压节点</strong></p>
<blockquote>
<p><strong>TaskManager</strong> 传输数据时，不同的 TaskManager 上的两个 Subtask 间通常根据 key 的数量有多个 Channel，这些 Channel 会复用同一个 TaskManager 级别的 TCP 链接，并且共享接收端 Subtask 级别的 Buffer Pool。<br><strong>在接收端</strong>，每个 Channel 在初始阶段会被分配固定数量的 Exclusive Buffer，这些 Buffer 会被用于存储接受到的数据，交给 Operator 使用后再次被释放。Channel 接收端空闲的 Buffer 数量称为 Credit，Credit 会被定时同步给发送端被后者用于决定发送多少个 Buffer 的数据。<br><strong>在流量较大时</strong>，Channel 的 Exclusive Buffer 可能会被写满，此时 Flink 会向 Buffer Pool 申请剩余的 Floating Buffer。这些 Floating Buffer 属于备用 Buffer，哪个 Channel 需要就去哪里。而在 Channel 发送端，一个 Subtask 所有的 Channel 会共享同一个 Buffer Pool，这边就没有区分 Exclusive Buffer 和 Floating Buffer。</p>
</blockquote>
<p>我们在监控反压时会用到的 Metrics 主要和 Channel 接受端的 Buffer 使用率有关，最为有用的是以下几个 Metrics:</p>
<table>
<thead>
<tr>
<th align="left">Metris</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">outPoolUsage</td>
<td align="left">发送端 Buffer 的使用率</td>
</tr>
<tr>
<td align="left">inPoolUsage</td>
<td align="left">接收端 Buffer 的使用率</td>
</tr>
<tr>
<td align="left">floatingBuffersUsage（1.9 以上）</td>
<td align="left">接收端 Floating Buffer 的使用率</td>
</tr>
<tr>
<td align="left">exclusiveBuffersUsage （1.9 以上）</td>
<td align="left">接收端 Exclusive Buffer 的使用率</td>
</tr>
</tbody></table>
<p>其中 inPoolUsage 等于 floatingBuffersUsage 与 exclusiveBuffersUsage 的总和。</p>
<p><strong>分析反压的思路：</strong></p>
<ol>
<li>outPoolUsage（发送端 Buffer）和 inPoolUsage（接受端 Buffer）同为低表明当前 Subtask 正常；</li>
<li>outPoolUsage 和 inPoolUsage 同为高表明当前 Subtask 处于被下游反压。</li>
<li>outPoolUsage 和 inPoolUsage 表现不同时，则可能是处于反压传导的中间状态或者表明该 Subtask 就是反压的根源。<br> 如果一个 Subtask 的 outPoolUsage 是低，但其 inPoolUsage是高，则表明它有可能是反压的根源；</li>
</ol>
<p><strong>导致反压的几种可能性</strong></p>
<ol>
<li>数据倾斜：可以在 Flink 的后台管理页面看到每个 Task 处理数据的大小。当数据倾斜出现时，通常是简单地使用类似 KeyBy 等分组聚合函数导致的，需要用户将热点 Key 进行预处理，降低或者消除热点 Key 的影响</li>
<li>GC：不合理的设置 TaskManager 的垃圾回收参数会导致严重的 GC 问题，我们可以通过 -XX:+PrintGCDetails 参数查看 GC 的日志。</li>
<li>代码本身：开发者错误地使用 Flink 算子，没有深入了解算子的实现机制导致性能问题。我们可以通过查看运行机器节点的 CPU 和内存情况定位问题</li>
</ol>
<p>值得注意的是，反压有时是短暂的且影响不大，比如来自某个 Channel 的短暂网络延迟或者 TaskManager 的正常 GC，这种情况下我们可以不用处理。</p>
<p>至此，我们已经有比较丰富的手段定位反压的根源是出现在哪个节点，但是具体的原因还没有办法找到。另外基于网络的反压 metrics 并不能定位到具体的 Operator，只能定位到 Task。特别是 embarrassingly parallel（易并行）的作业（所有的 Operator 会被放入一个 Task，因此只有一个节点），反压 metrics 则派不上用场。</p>
<p><strong>补充</strong><br>数据倾斜：数据倾斜在 MapReduce 计算框架中经常发生。通俗理解，该现象指的是在整个计算过程中，大量相同的 key 被分配到了同一个任务上，造成“一个人累死、其他人闲死”的状况，这违背了分布式计算的初衷，使得整体的执行效率十分低下。</p>
<h2 id="flink-参数"><a href="#flink-参数" class="headerlink" title="flink 参数"></a>flink 参数</h2><h3 id="kafka"><a href="#kafka" class="headerlink" title="kafka"></a>kafka</h3><table>
<thead>
<tr>
<th align="left">name</th>
<th align="left">meaning</th>
<th align="left">required</th>
<th align="left">default</th>
<th align="left">consumer/producer</th>
</tr>
</thead>
<tbody><tr>
<td align="left">connector.cluster</td>
<td align="left">kafka 集群名</td>
<td align="left">YES</td>
<td align="left">-</td>
<td align="left">consumer &amp; producer</td>
</tr>
<tr>
<td align="left">connector.topic</td>
<td align="left">kafka topic</td>
<td align="left">YES</td>
<td align="left">-</td>
<td align="left">consumer &amp; producer</td>
</tr>
<tr>
<td align="left">connector.group.id</td>
<td align="left">consumer group id</td>
<td align="left">YES</td>
<td align="left">-</td>
<td align="left">consumer</td>
</tr>
<tr>
<td align="left">update-mode</td>
<td align="left">更新模式, ‘append’/‘upsert’</td>
<td align="left">YES</td>
<td align="left">-</td>
<td align="left">consumer 就填 ‘append’ 就行; producer 如果是查询的结果是可以更新的就用 upsert， 如果是查询的结果是不可更新的就用 append.</td>
</tr>
<tr>
<td align="left">connector.parallelism</td>
<td align="left">并发度</td>
<td align="left">NO</td>
<td align="left">-（kafka source 建议是 partition 个数，sink 建议不要比 partition 个数大过多）</td>
<td align="left">consumer &amp; producer</td>
</tr>
<tr>
<td align="left">connector.startup-mode</td>
<td align="left">earliest-offset/<br>latest-offset/<br>group-offsets/<br>specific-timestamp，<br>详细解释如下</td>
<td align="left">NO</td>
<td align="left">group-offsets</td>
<td align="left">consumer</td>
</tr>
<tr>
<td align="left">connector.reset-to-earliest-for-new-partition</td>
<td align="left">该参数表示在任务启动时，如果用的是group-offsets配置，对于那些还没有offset的partition如何处理</td>
<td align="left">NO</td>
<td align="left">true</td>
<td align="left">consumer</td>
</tr>
<tr>
<td align="left">connector.kafka.properties.request.timeout.ms</td>
<td align="left">kafka client写入超时时间</td>
<td align="left">NO</td>
<td align="left">30000ms</td>
<td align="left">producer</td>
</tr>
<tr>
<td align="left">connector.kafka.properties.batch.size</td>
<td align="left">kafka client会按batch写入,当攒到相关batch size(这里指的是bytes)的时候写入数据</td>
<td align="left">NO</td>
<td align="left">16384（16KB）</td>
<td align="left">producer</td>
</tr>
<tr>
<td align="left">connector.kafka.properties.linger.ms</td>
<td align="left">kafka client会按batch写入,当攒到一定时间，会实际写入到kafka</td>
<td align="left">NO</td>
<td align="left">5000ms</td>
<td align="left">producer</td>
</tr>
<tr>
<td align="left">connector.kafka.properties.acks</td>
<td align="left">需要等待几个副本响应才发送下一条消息，-1 表示要等待所有副本响应</td>
<td align="left">NO</td>
<td align="left">0</td>
<td align="left">producer</td>
</tr>
<tr>
<td align="left">connector.kafka.properties.compression.type</td>
<td align="left">压缩类型:gzip,snappy,lz4,zstd</td>
<td align="left">NO</td>
<td align="left">none</td>
<td align="left">producer</td>
</tr>
<tr>
<td align="left">scan.startup.mode</td>
<td align="left">从哪里开始消费 kafka<br>earliest-offset<br>latest-offset<br>group-offsets<br>specific-offsets<br>timestamp</td>
<td align="left">NO</td>
<td align="left">group-offsets</td>
<td align="left">consumer</td>
</tr>
<tr>
<td align="left">scan.manually-commit-offsets-interval</td>
<td align="left">任务定时 commit offset</td>
<td align="left">NO</td>
<td align="left">-</td>
<td align="left">consumer</td>
</tr>
</tbody></table>
<h3 id="flink-运行参数"><a href="#flink-运行参数" class="headerlink" title="flink 运行参数"></a>flink 运行参数</h3><table>
<thead>
<tr>
<th align="left">Key</th>
<th align="left">Default</th>
<th align="left">Type</th>
<th align="left">Description</th>
<th align="left">适用场景</th>
</tr>
</thead>
<tbody><tr>
<td align="left">execution.checkpointing.enable</td>
<td align="left">false</td>
<td align="left">Boolean</td>
<td align="left">是否开启 checkpoint</td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">execution.checkpointing.interval</td>
<td align="left">20000</td>
<td align="left">ms</td>
<td align="left">checkpoint 间隔</td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">execution.checkpointing.timeout</td>
<td align="left">10000</td>
<td align="left">ms</td>
<td align="left">checkpoint 超时时间</td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">state.backend</td>
<td align="left">Java Streaming: rocksdb<br>Flink SQL: filesystem</td>
<td align="left">Enum(filesystem/rocksdb)</td>
<td align="left">状态后端，不同状态后端拥有不同的状态存储和持久化的方式</td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">state.checkpoints.namespace</td>
<td align="left">default</td>
<td align="left">String</td>
<td align="left">Checkpoint 所属的命名空间，由用户管理</td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">state.backend.incremental</td>
<td align="left">true</td>
<td align="left">Boolean</td>
<td align="left">使用 rocksdb statebackend 时是否开启增量模式</td>
<td align="left">Streaming</td>
</tr>
<tr>
<td align="left">table.exec.emit.early-fire.enabled</td>
<td align="left">false</td>
<td align="left">Boolean</td>
<td align="left">是否开启Fast Emit</td>
<td align="left">Streaming</td>
</tr>
<tr>
<td align="left">table.exec.emit.early-fire.delay</td>
<td align="left">-</td>
<td align="left">Duration</td>
<td align="left">如果开启Fast Emit，那多久emit一次</td>
<td align="left">Streaming</td>
</tr>
<tr>
<td align="left">table.exec.emit.late-fire.enabled</td>
<td align="left">false</td>
<td align="left">Boolean</td>
<td align="left">是否开启Late Emit</td>
<td align="left">Streaming</td>
</tr>
<tr>
<td align="left">table.exec.emit.late-fire.delay</td>
<td align="left">-</td>
<td align="left">Duration</td>
<td align="left">如果开启Late Emit，那多久emit一次</td>
<td align="left">Streaming</td>
</tr>
<tr>
<td align="left">table.exec.emit.unchanged.enabled</td>
<td align="left">false</td>
<td align="left">Boolean</td>
<td align="left">如果开启了Fast Emit，默认是不会发送没有变化的聚合结果的，开了这个参数的话，则会都输出，即使聚合结果没有变化</td>
<td align="left">Streaming</td>
</tr>
<tr>
<td align="left">table.exec.mini-batch.enabled</td>
<td align="left">false</td>
<td align="left">Boolean</td>
<td align="left">是否开启 mini-batch</td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">table.exec.mini-batch.allow-latency</td>
<td align="left">-</td>
<td align="left">自己填</td>
<td align="left">最长多少时间一个mini-batch</td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">table.exec.mini-batch.size</td>
<td align="left">-</td>
<td align="left">条数</td>
<td align="left">单个并发最多多少条数据一个mini-batch</td>
<td align="left">-</td>
</tr>
</tbody></table>
<h3 id="checkpoint-Interval-amp-Timeout"><a href="#checkpoint-Interval-amp-Timeout" class="headerlink" title="checkpoint Interval &amp; Timeout"></a>checkpoint Interval &amp; Timeout</h3><p>常见调参为 checkpoint interval 和 checkpoint timeout：</p>
<ul>
<li>checkpoint interval: Checkpoint 触发的时间间隔，也可以理解为是 commit offset 的间隔。</li>
<li>checkpoint timeout: 过短会造成 checkpoint 频繁失败。</li>
</ul>
<p>每个作业的状态、并行度、拓扑都不一样，在这里无法给出具体的计算数值的方法，给一个大概的参考值，具体还需要根据用户作业的实际运行情况去调整：</p>
<ul>
<li>如果 state 为 KB / MB / &lt; 10GB 级别，interval 和 timeout 调整为 3min 左右</li>
<li>如果 state 为 &gt;10GB / TB 级别，interval 和 timeout 调整为 10min+</li>
</ul>
<p>通常来讲，interval 取决于你的业务需要（比如能容忍多长时间（interval + timeout）不 commit offsets 产生的 lag）；timeout 是对 lag 和 checkpoint 的一个权衡，如果 timeout 设置过短，作业可能由于流量陡增、短暂时间的倾斜、或者 Hdfs 慢导致 checkpoint 超时失败；如果设置过长，那么产生的 lag 也会相对大一些，timeout 的调整根据上述的建议值来设置。</p>
<h3 id="StateBackend-选择"><a href="#StateBackend-选择" class="headerlink" title="StateBackend 选择"></a>StateBackend 选择</h3><blockquote>
<p>注：使用 RocksDBStateBackend 一般需要和 SSD 相配合使用，否则处理速率相对较慢。用户直接切换到带有 SSD 的队列并将 state backend 类型改为 rocksdb 即可。（使用 SSD 前请确认阅读过下方的性能优化部分）</p>
</blockquote>
<p>目前有两种 StateBackend 供选择：FsStateBackend 和 RocksDBStateBackend，在这里简单介绍一下，更细致的介绍见: <a target="_blank" rel="noopener" href="https://www.ververica.com/blog/stateful-stream-processing-apache-flink-state-backends">Stateful Stream Processing: Apache Flink State Backends</a></p>
<ul>
<li>FsStateBackend: State 以内存形式存在于 Flink 进程中，Checkpoint 触发时将内存中的数据 dump 到 HDFS 上。优点：速度快，缺点：容量小，容易产生 GC 问题。</li>
<li>RocksDBStateBackend: 每个 Task 维护一个 RocksDB 存储，状态以 RocksDB 为存储介质，Checkpoint 触发时，Task 将自己维护的增量状态文件 copy 到 HDFS 上。（因为 RocksDB 是 append-only 的）优点：容量不受限，缺点：速度慢。</li>
</ul>
<h3 id="Emit-配置"><a href="#Emit-配置" class="headerlink" title="Emit 配置"></a>Emit 配置</h3><blockquote>
<p>Emit 主要是用来提前周期性输出一个长窗口的结果。<br>比如现在有一个 1 天的滚动窗口TUMBLE(ts, INTERVAL ‘1’ DAY)。正常情况下，这个窗口只有在当天结束的时候才会发送这个窗口的结果到下游。<br>如果我们想让这个窗口提前把窗口的实时计算结果输出出来，然后不断更新这个结果，那就是 Emit 的功能了。</p>
</blockquote>
<p>Emit的基本原理是，每一个聚合的key在来第一条数据的时候，开始设置一个周期性的处理时间定时器，定时器到了的时候，就检查一下当前的结果是否跟之前发送的结果有变化，有的话，则发送一下当前最新的结果；没有的话，则不发送。<br>如果想要不管是否结果有变化，都将当前结果发送出来，则可以通过配置一个动态参数来解决。<code>table.exec.emit.unchanged.enabled = true</code></p>
<p><strong>Emit 相关问题</strong></p>
<blockquote>
<p>为保证 early-fire 时间间隔的正确，flink 会为其分配一个时间戳 timer。该 timer 成功分配需满足条件：当前时刻距上一 timer 已过去 1min。此时便会生成一个新的 timer，该 timer 距上一 timer 刚好 1min。timer 生成后，若 state 距上一 timer 的 state 发生了变化，则 flink 将该 state 的数据输出下游。</p>
</blockquote>
<p>对于配置了 early-fire 为 1min 的 flink 任务，在停止任务一段时间再重启（追 lag），发现任务的输出间隔时间小于 1min。</p>
<p>flink 任务在重启成功后，与之前任务停止时刻之间的时间间隔内，early-fire 会依次串行自任务停止时刻开始，间隙 1min 生成新的 timer，该 timer 要小于当前现实时刻并与上一 timer 时刻恰巧间隔 1min（现实时刻间隙小于 1min，但 timer 间隙 1min，因为 timer 小于现实时刻）。若 state 在该 timer 生成后发生了变化，即输出数据，并再次产生新的 timer。因此，在任务重启后发现数据输出间隙小于 1min，是因为 timer 不断串行生成。</p>
<h3 id="Mini-Batch-配置"><a href="#Mini-Batch-配置" class="headerlink" title="Mini Batch 配置"></a>Mini Batch 配置</h3><p>mini-batch的主要作用是用来攒一批数据，一起计算完成后，再访问一次状态，来降低对状态的访问次数。</p>
<p><strong>支持 mini-batch 的算子</strong></p>
<ul>
<li>去重算子</li>
<li>普通聚合算子</li>
<li>window 算子（字节开发支持）</li>
</ul>
<p><strong>参数配置建议</strong></p>
<ul>
<li>mini-batch.allow-latency：可直接根据业务需要配置，在作业吞吐和数据时效性之间权衡；</li>
<li>table.exec.mini-batch.size：单个并发 buffer 数据的条数，建议通过合理配置该值大小控制异常流量（如数据回溯，lag 过大追数据等情况）下 buffer 的数据条数，防止上述情况 buffer 数据条数过多直接造成内存OOM。</li>
</ul>
<p><strong>作用</strong></p>
<ul>
<li>降低频繁访问状态导致的 CPU 开销<br>如果配置的 state backend 是 rocksdb 才有这个问题，如果是 filesystem，则不需要。原因是 filesystem 用的是 heap 来存储状态，状态都是以 java 对象的形式来存储，不需要做序列化和反序列化，所以每次都访问状态是没有额外的 CPU 开销的。如果是 rocksdb state backend，则每次状态读取都需要反序列化，状态写入则需要序列化，所以相对来说，会多消耗一些 CPU。<br>以聚合来讲，如果开了 mini-batch，则会攒一波数据，这波数据读取一次状态，修改聚合指标，然后统一一次写入状态，所以可以降低一些 CPU 开销。</li>
<li>减少聚合的输出量<br>如果是普通的聚合，则每来一条数据就直接输出一条当前的聚合结果。但是用了 mini-batch 之后，是一个 mini-batch 才输出一次，对于同一个 group by 的 key 如果在一个 mini-batch 内有多条数据，则只会输出一次，这样可以有效降低输出数据的量。</li>
</ul>
<h2 id="知识点"><a href="#知识点" class="headerlink" title="知识点"></a>知识点</h2><ul>
<li>默认情况下，flink 的状态会保存在 taskmanager 的内存中，而 checkpoint 会保存在 jobManager 的内存中。</li>
<li>flink 确定消费 kafka 的位置：先从 checkpoint 中找。若 checkpoint 中没有（最新 checkpoint），则由 scan.startup.mode 参数决定。该参数默认 group-offsets，即从 consumer group 的 offsets 中开始消费。</li>
<li>默认情况下，flink 在 checkpoint 成功时才提交 kafka offset，因此若 checkpoint interval 较大时，偶尔的 checkpoint 失败会导致误报警（上游 kafka lag 积压）。通过设置 kafka 参数 <code>scan.manually-commit-offsets-interval = &#39;5000&#39;</code>，可保证任务定时 commit offset。但如果作业 checkpoint 失败或重启，仍然会从上一次成功 checkpoint 的 offset 恢复。</li>
<li>使用窗口函数时，时间字段需要带有 time attribute（时间属性），若只是 timestamp 类型，则会报错。将 timestamp 类型经 watermark 后可使其带有 time attribute。</li>
<li>滑动窗口需在 group by 中使用，若同时 group by 其他维度，则在聚合中计算的是在时间窗口内、该 group by 维度对应的所有数据。</li>
<li>flink 监控配置<ul>
<li>重要（电话报警）<ul>
<li>上游 source topic lag 监控</li>
<li>上游 source topic 单个 partition lag 监控</li>
<li>数据写入断流监控（上下游）</li>
<li>checkpoint 失败监控</li>
</ul>
</li>
<li>不那么重要（lark 报警）<ul>
<li>sink 瞬时 qps 突增监控</li>
<li>任务重启监控</li>
</ul>
</li>
</ul>
</li>
<li>聚合方式：<ul>
<li>全局聚合 + mini-batch：没有意义，因为全局聚合得到的结果是任务启动以来各指标的聚合结果，是一个全局 sum；</li>
<li>窗口聚合 + early-fire（ + mini-batch）：如一小时聚合，能得到一小时的各指标聚合结果，进而可得到一天的、一周的等聚合结果。<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/flink_5.png" class=""></li>
</ul>
</li>
</ul>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><ul>
<li>2022-01-04：ad 粒度聚合任务修改 udf 和更新 checkpoint 后（未切 consumer group），lag 不断积累，同时 checkpoint 一直失败。但相同操作的 creative 粒度聚合任务没有这种情况。（队列有问题）</li>
<li>flink 在追 lag 时，watermark 理论上会丢弃超时的数据。但是对于 16 小时前积累起的 lag，watermark 没有丢数，表现为 ad 粒度任务验数和 creative 粒度验数 cost 对齐。</li>
<li>背景：pre agg 任务拆成了两个 flink 任务：pre agg common 和 pre agg core。common 任务在启动后不断 checkpoint 失败，表现同上 ad  粒度，checkpoint 失败时间区间[2022-01-06 22:00:00, 2022-01-07 02:00:00]。但验数结果上，22、23 点的数据对不齐，而 01、02 点的数据能对齐，不理解。</li>
</ul>
<hr>
<h1 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h1><h2 id="知识点-1"><a href="#知识点-1" class="headerlink" title="知识点"></a>知识点</h2><ol>
<li>若 hive 表结构不包含某字段，那即使上游数据中含有该字段，也不会落到 hive 表中。在表结构中新加该字段，在加上该字段前的时间，该字段的数据不可得。</li>
</ol>
<hr>
<h1 id="Elasticsearch"><a href="#Elasticsearch" class="headerlink" title="Elasticsearch"></a>Elasticsearch</h1><h2 id="es-与数据库对比"><a href="#es-与数据库对比" class="headerlink" title="es 与数据库对比"></a>es 与数据库对比</h2><img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/es1.jpg" class="">
<p><strong>es 于 7.x 移除了 mapping type</strong></p>
<p><strong>es 中 mappings 的数据类型</strong></p>
<img src="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/es2.jpg" class="">
<p>mappings 中使用 obejct（可以理解为 json）示例，metric_data 为 obejct 类型，无需显式定义 type 属性值：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;dynamic&quot;: false,</span><br><span class="line">    &quot;_source&quot;: &#123;</span><br><span class="line">        &quot;enabled&quot;: false</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;dp_realtime_click_count&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;long&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;unfollow_in_wechat_count&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;long&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;metric_data&quot;: &#123;</span><br><span class="line">            &quot;properties&quot;: &#123;</span><br><span class="line">                &quot;cost&quot;: &#123;</span><br><span class="line">                    &quot;type&quot;: &quot;long&quot;</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;show_cnt&quot;: &#123;</span><br><span class="line">                    &quot;type&quot;: &quot;long&quot;</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;convert_cnt&quot;: &#123;</span><br><span class="line">                    &quot;type&quot;: &quot;long&quot;</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;click_cnt&quot;: &#123;</span><br><span class="line">                    &quot;type&quot;: &quot;long&quot;</span><br><span class="line">                &#125;,</span><br><span class="line">                &quot;send_cnt&quot;: &#123;</span><br><span class="line">                    &quot;type&quot;: &quot;long&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;first_agent_company_id&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;long&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h1 id="Mongodb"><a href="#Mongodb" class="headerlink" title="Mongodb"></a>Mongodb</h1><h2 id="mongodb-常用命令"><a href="#mongodb-常用命令" class="headerlink" title="mongodb 常用命令"></a>mongodb 常用命令</h2><ul>
<li>启动 mongodb：cd 到 mongodb 存储目录下的 bin 目录下，执行命令<code>mongod --dbpath /usr/local/var/mongodb --logpath /usr/local/var/log/mongodb/mongo.log --fork</code>，可在后台启动 mongodb。其中：<ul>
<li>dbpath 设置数据存放目录</li>
<li>logpath 设置日志存放目录</li>
<li>fork 在后台运行</li>
</ul>
</li>
<li>mongodb 启动成功后，使用<code>mongo</code>命令进入数据库环境</li>
<li>切换/创建数据库：<code>use &#39;dbname&#39;</code></li>
<li>查询所有数据库：<code>show dbs</code></li>
<li>删除当前使用数据库：<code>db.dropDatabase()</code></li>
<li>得到指定名称的聚集集合（table）：<code>db.getCollection(&quot;account&quot;)</code></li>
<li>得到当前db的所有聚集集合：<code>db.getCollectionNames()</code></li>
</ul>
<h2 id="pymongo"><a href="#pymongo" class="headerlink" title="pymongo"></a>pymongo</h2><blockquote>
<p>参考：<a target="_blank" rel="noopener" href="https://docs.mongoing.com/">MongoDB中文手册</a></p>
</blockquote>
<ul>
<li>创建数据库<ol>
<li>获取 MongoClient 对象：<code>myclient = pymongo.MongoClient(&quot;mongodb://localhost:27017/&quot;)</code></li>
<li>创建名为 test 的表：<code>mydb = myclient[&quot;test&quot;]</code></li>
</ol>
  <strong>在 MongoDB 中，数据库只有在内容插入后才会创建! 就是说，数据库创建后要创建集合(数据表)并插入一个文档(记录)，数据库才会真正创建，同时此时才会创建集合</strong></li>
<li>获取 mongodb 中所有数据库：<code>myclient.list_database_names()</code><br>  <strong>Python3.7 版本之前使用 <code>myclient.database_names()</code></strong></li>
<li>创建集合：<code>mycol = mydb[&quot;test_col&quot;]</code></li>
<li>获取数据库中所有的集合：<code>mydb.list_collection_names()</code><br>  <strong>Python3.7 版本之前使用 <code>mydb.collection_names()</code></strong></li>
<li>往集合中插入一个文档：<code>x = mycol.insert_one(mydict)</code>。返回值是 InsertOneResult 对象，该对象包含 inserted_id 属性，它是插入文档的 id 值。通过 <code>x.inserted_id</code> 获取</li>
<li>往集合中插入多个文档：<code>x = mycol.insert_many(mylist)</code>。mylist 是一个字典列表。可通过 <code>x.inserted_ids</code> 输出插入的所有文档对应的 _id 值。<br>  <strong>也可通过在字典中增加 _id:value 键值对，指定文档插入的位置</strong></li>
<li>查询集合中的第一个文档：<code>x = mycol.find_one()</code></li>
<li>查询集合中的所有文档：<code>x_list = mycol.find()</code></li>
<li>查询指定列的数据，将要返回的字段对应值设置为 1：<code>x_list = mycol.find(&#123;&#125;,&#123; &quot;_id&quot;: 0, &quot;name&quot;: 1, &quot;alexa&quot;: 1 &#125;)</code>。查询的是 name 和 alexa 列的值。（除了 _id，不能在一次查询中同时指定 0 和 1）</li>
<li>查询指定行的数据（过滤）：<code>x = mycol.find(&#123;&quot;name&quot;: &quot;RUNOOB&quot;&#125;</code>。查询集合中 name=RUNOOB 的文档</li>
<li>指定查询返回文档数：<code>x = mycol.find().limit(3)</code></li>
<li>获取某字段（列）的所有枚举值：<code>mycol.distinct(&quot;label&quot;)</code>。获取 label 字段的所有枚举值</li>
</ul>
<h2 id="知识点-2"><a href="#知识点-2" class="headerlink" title="知识点"></a>知识点</h2><ol>
<li>mongodb 中存储的数据库和表，在关机后不会被清除</li>
</ol>
</article><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/10/25/%E5%B7%A5%E4%BD%9C%E7%A7%AF%E7%B4%AF/"><img class="prev-cover" src="/img/beijing.jpg" onerror="onerror=null;src='/img/touxiang.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">工作积累</div></div></a></div><div class="next-post pull-right"><a href="/2021/05/31/%E9%80%89%E8%B0%83%E7%9B%B8%E5%85%B3/"><img class="next-cover" src="/img/beijing.jpg" onerror="onerror=null;src='/img/touxiang.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">选调相关</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">John Doe</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">12</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">1</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/zourunxin"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">勤加注释！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Hexo"><span class="toc-text">Hexo</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Hexo-%E5%AE%89%E8%A3%85"><span class="toc-text">Hexo 安装</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#cnpm-%E5%91%BD%E4%BB%A4%E6%97%A0%E6%95%88%E9%97%AE%E9%A2%98"><span class="toc-text">cnpm 命令无效问题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hexo-%E7%BB%88%E7%AB%AF%E5%91%BD%E4%BB%A4"><span class="toc-text">Hexo 终端命令</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hexo-%E7%9B%B8%E5%85%B3%E6%8A%A5%E9%94%99"><span class="toc-text">Hexo 相关报错</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Markdown"><span class="toc-text">Markdown</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#md-%E8%AF%AD%E6%B3%95"><span class="toc-text">md 语法</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BB%88%E7%AB%AF%E5%91%BD%E4%BB%A4"><span class="toc-text">终端命令</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Git"><span class="toc-text">Git</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BD"><span class="toc-text">下载</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%8A%E4%BC%A0"><span class="toc-text">上传</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%A0%E9%99%A4"><span class="toc-text">删除</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%B9%E6%9C%AC%E5%9C%B0%E5%88%86%E6%94%AF%E7%9A%84%E6%93%8D%E4%BD%9C"><span class="toc-text">对本地分支的操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Github"><span class="toc-text">Github</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#IDEA"><span class="toc-text">IDEA</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Kafka"><span class="toc-text">Kafka</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka-%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-text">Kafka 是什么</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ZooKeeper"><span class="toc-text">ZooKeeper</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Producer"><span class="toc-text">Producer</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Producer-%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE"><span class="toc-text">Producer 参数配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#batch-%E8%B0%83%E4%BC%98"><span class="toc-text">batch 调优</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A1%A5%E5%85%85"><span class="toc-text">补充</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%91%E6%8E%A7"><span class="toc-text">监控</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Broker"><span class="toc-text">Broker</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Consumer"><span class="toc-text">Consumer</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5"><span class="toc-text">Kafka 基础概念</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E9%A2%98%E4%B8%8E%E5%88%86%E5%8C%BA"><span class="toc-text">主题与分区</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6"><span class="toc-text">多副本机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E6%80%A7%E4%B8%8E%E5%AE%9E%E7%8E%B0"><span class="toc-text">特性与实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8"><span class="toc-text">数据安全</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90"><span class="toc-text">性能分析</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#RocketMQ"><span class="toc-text">RocketMQ</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#SQL"><span class="toc-text">SQL</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#sql-%E5%85%B3%E9%94%AE%E8%AF%8D"><span class="toc-text">sql 关键词</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#sql-%E5%87%BD%E6%95%B0"><span class="toc-text">sql 函数</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Flink"><span class="toc-text">Flink</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9D%A2%E8%AF%95%E9%A2%98"><span class="toc-text">面试题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Flink-%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B"><span class="toc-text">Flink 程序执行流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B"><span class="toc-text">内存模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#JobManager-%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B"><span class="toc-text">JobManager 内存模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#TaskManager-%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B"><span class="toc-text">TaskManager 内存模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Exactly-once"><span class="toc-text">Exactly-once</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E5%BF%AB%E7%85%A7%E6%9C%BA%E5%88%B6"><span class="toc-text">分布式快照机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4"><span class="toc-text">两阶段提交</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#flink-%E5%8F%8D%E5%8E%8B"><span class="toc-text">flink 反压</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%8D%E5%8E%8B%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-text">反压的影响</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%BD%8D%E5%8F%8D%E5%8E%8B%E8%8A%82%E7%82%B9"><span class="toc-text">定位反压节点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#flink-%E5%8F%82%E6%95%B0"><span class="toc-text">flink 参数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#kafka"><span class="toc-text">kafka</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#flink-%E8%BF%90%E8%A1%8C%E5%8F%82%E6%95%B0"><span class="toc-text">flink 运行参数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#checkpoint-Interval-amp-Timeout"><span class="toc-text">checkpoint Interval &amp; Timeout</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#StateBackend-%E9%80%89%E6%8B%A9"><span class="toc-text">StateBackend 选择</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Emit-%E9%85%8D%E7%BD%AE"><span class="toc-text">Emit 配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Mini-Batch-%E9%85%8D%E7%BD%AE"><span class="toc-text">Mini Batch 配置</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9F%A5%E8%AF%86%E7%82%B9"><span class="toc-text">知识点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-text">遇到的问题</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hive"><span class="toc-text">Hive</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9F%A5%E8%AF%86%E7%82%B9-1"><span class="toc-text">知识点</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Elasticsearch"><span class="toc-text">Elasticsearch</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#es-%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AF%B9%E6%AF%94"><span class="toc-text">es 与数据库对比</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Mongodb"><span class="toc-text">Mongodb</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#mongodb-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4"><span class="toc-text">mongodb 常用命令</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#pymongo"><span class="toc-text">pymongo</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9F%A5%E8%AF%86%E7%82%B9-2"><span class="toc-text">知识点</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/01/26/%E9%87%91%E8%9E%8D%E6%9C%AF%E8%AF%AD/" title="金融术语">金融术语</a><time datetime="2022-01-26T05:47:08.000Z" title="Created 2022-01-26 13:47:08">2022-01-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/01/23/hello-world/" title="Hello World">Hello World</a><time datetime="2022-01-23T14:49:13.969Z" title="Created 2022-01-23 22:49:13">2022-01-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/01/19/%E7%94%9F%E6%B4%BB%E6%94%BB%E7%95%A5/" title="生活攻略">生活攻略</a><time datetime="2022-01-19T02:39:43.000Z" title="Created 2022-01-19 10:39:43">2022-01-19</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/01/18/%E4%B9%B0%E4%B9%B0%E4%B9%B0%E6%94%BB%E7%95%A5/" title="买买买攻略">买买买攻略</a><time datetime="2022-01-18T14:52:34.000Z" title="Created 2022-01-18 22:52:34">2022-01-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/10/25/%E8%AF%BE%E7%A8%8B/" title="课程">课程</a><time datetime="2021-10-25T05:20:25.000Z" title="Created 2021-10-25 13:20:25">2021-10-25</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By John Doe</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div></div></body></html>