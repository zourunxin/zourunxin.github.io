<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>工作积累 | Hexo</title><meta name="author" content="John Doe"><meta name="copyright" content="John Doe"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="组会 Stanford吴恩达教授网课笔记  8.28 – one_hot 总结这是进行数据 one_hot 编码的第三周，困难比较多。目前的尝试： 1. 在数据喂入模型前进行 one_hot 编码。在 model_exp.py 中，训练模型的 train() 方法，在数据喂入模型前loss, match &#x3D; self._train_step(features, labels)  # batch l">
<meta property="og:type" content="article">
<meta property="og:title" content="工作积累">
<meta property="og:url" content="http://example.com/2021/10/25/%E5%B7%A5%E4%BD%9C%E7%A7%AF%E7%B4%AF/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="组会 Stanford吴恩达教授网课笔记  8.28 – one_hot 总结这是进行数据 one_hot 编码的第三周，困难比较多。目前的尝试： 1. 在数据喂入模型前进行 one_hot 编码。在 model_exp.py 中，训练模型的 train() 方法，在数据喂入模型前loss, match &#x3D; self._train_step(features, labels)  # batch l">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/img/beijing.jpg">
<meta property="article:published_time" content="2021-10-25T05:16:26.000Z">
<meta property="article:modified_time" content="2022-02-26T02:23:37.179Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/beijing.jpg"><link rel="shortcut icon" href="/img/touxiang.jpg"><link rel="canonical" href="http://example.com/2021/10/25/%E5%B7%A5%E4%BD%9C%E7%A7%AF%E7%B4%AF/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '工作积累',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-02-26 10:23:37'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/background.css"><meta name="generator" content="Hexo 5.4.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">12</div></a></div></div></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/beijing.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Hexo</a></span><div id="menus"><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">工作积累</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2021-10-25T05:16:26.000Z" title="Created 2021-10-25 13:16:26">2021-10-25</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2022-02-26T02:23:37.179Z" title="Updated 2022-02-26 10:23:37">2022-02-26</time></span></div><div class="meta-secondline"></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="组会"><a href="#组会" class="headerlink" title="组会"></a>组会</h1><blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_36815313/article/details/105728919">Stanford吴恩达教授网课笔记</a></p>
</blockquote>
<h2 id="8-28-–-one-hot-总结"><a href="#8-28-–-one-hot-总结" class="headerlink" title="8.28 – one_hot 总结"></a>8.28 – one_hot 总结</h2><p>这是进行数据 one_hot 编码的第三周，困难比较多。目前的尝试：</p>
<h3 id="1-在数据喂入模型前进行-one-hot-编码。"><a href="#1-在数据喂入模型前进行-one-hot-编码。" class="headerlink" title="1. 在数据喂入模型前进行 one_hot 编码。"></a>1. 在数据喂入模型前进行 one_hot 编码。</h3><p>在 model_exp.py 中，训练模型的 train() 方法，在数据喂入模型前<code>loss, match = self._train_step(features, labels)  # batch loss</code>，对数据进行 one_hot 编码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">features = tf.cast(features, tf.int32)</span><br><span class="line">features = tf.one_hot(indices=features, depth=<span class="number">256</span>, on_value=<span class="number">1</span>, off_value=<span class="number">0</span>, axis=-<span class="number">1</span>, dtype=<span class="literal">None</span>)</span><br><span class="line">features = tf.cast(features, tf.float32)</span><br></pre></td></tr></table></figure>
<p>这里面有问题：features 的形式为 tf.tensor(256,20,256)。各数据含义如下：</p>
<ul>
<li>256：batch_size 大小</li>
<li>20：样本的包数量</li>
<li>256：每个包的字节大小<br>此时输入数据是三维的，进行 one_hot 编码后，数据被变成四维：tf.tensor(256,20,256,256)，若使用一维卷积缩减一维，则会报错。因为一维卷积的输入只能是三维。</li>
</ul>
<h3 id="2-在数据从-tfrecord-中读出来后，在-batch-256-之前，进行-one-hot-编码"><a href="#2-在数据从-tfrecord-中读出来后，在-batch-256-之前，进行-one-hot-编码" class="headerlink" title="2. 在数据从 tfrecord 中读出来后，在 batch 256 之前，进行 one_hot 编码"></a>2. 在数据从 tfrecord 中读出来后，在 batch 256 之前，进行 one_hot 编码</h3><p>在方法 _generate_ds() 中，在数据读出来后，进行 batch 前<code>ds = ds.batch(self._batch_size, drop_remainder=False)</code>，进行独热编码。此时 ds 的形式为 tf.EagerTensor(20,256)，one_hot 编码后为 tf.EagerTensor(20,256,256)，满足一维卷积的数据输入要求。<br>但是这里面有问题：数据（输入特征）读出来后是 int64 类型，此时 label 也生成了，说明此时一个 int64 大小的数据与一个 label 进行了对应。若我们此时再进行 one_hot 编码（在这之前先转化为 byte，因为要求是一个字节编码成 256 维），也只是将 256 个 int64 的数字转化为一个 byte 的数字，此时造成了数据的大量丢失，one_hot 编码也变得没有意义。</p>
<h3 id="3-在读-pcap-文件时，文件中包的存储单位是-byte，因此边读包边进行-one-hot-编码。"><a href="#3-在读-pcap-文件时，文件中包的存储单位是-byte，因此边读包边进行-one-hot-编码。" class="headerlink" title="3. 在读 pcap 文件时，文件中包的存储单位是 byte，因此边读包边进行 one_hot 编码。"></a>3. 在读 pcap 文件时，文件中包的存储单位是 byte，因此边读包边进行 one_hot 编码。</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># too2.py</span></span><br><span class="line"><span class="keyword">with</span> PcapReader(path) <span class="keyword">as</span> pr:</span><br><span class="line">	<span class="comment"># 读文件</span></span><br><span class="line">	<span class="keyword">for</span> pkt <span class="keyword">in</span> pr:</span><br><span class="line">		<span class="comment"># 读 pcap 里的包</span></span><br><span class="line">		bytes_array = pkt.original</span><br><span class="line">		<span class="keyword">for</span> i <span class="keyword">in</span> bytes_array:</span><br><span class="line">			...</span><br></pre></td></tr></table></figure>
<p>如上，从 pcap 文件中读包时，可以从每个包中获取字节串（一般为 48 字节的长度），使用 for 循环遍历，即可获得包中的每个字节。<br>但这里面有问题：djt 学长的论文中，one_hot 编码后，需要进行一维卷积。过程大致如下：输入数据形式为 (256,256)（即一个包，256 字节 * 256 维）。利用一维卷积（textcnn）和池化，输出为 (256,1)，即最终还是一个包，256 字节。<br>这么一来，若直接读 pcap 文件，获取每个字节进行 one_hot 编码，则输入为 (1,256)（即 1 字节 * 256 维），如此，则无法使用一维卷积和池化，无法扩大感受野。<br>当然，也可能说，若使用列表把每个包的字节先存储起来，够了 256 字节后，再进行 one_hot 编码和一维卷积。这个想法理论上可以，但实际遇到的困难会比较多，列举如下：</p>
<ol>
<li>每个包需要对包头的 mac 和 ip 地址进行匿名化，即全置 0。（这个可以解决，不算难）</li>
<li>一个 pcap 文件里的所有包，是否就是一个会话？因为只有一个 pcap 文件里的包都是一个会话的，才可以使用 textcnn 进行一维卷积。否则，不属于一个会话的，使用 textcnn，反而会带来负面效果。（从学长冗余的代码来看，大概率不是）</li>
<li>无论一个 pcap 文件里的包是否都属于一个会话，都会出现当前会话结束时，存储的字节数量不够 256 字节。这些数据应当丢弃还是补齐，都不是一种好办法。</li>
</ol>
<hr>
<h1 id="python"><a href="#python" class="headerlink" title="python"></a>python</h1><blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/SmartDemo/article/details/105030576">pip 安装tensorflow超时解决方案</a></p>
</blockquote>
<h2 id="项目开发"><a href="#项目开发" class="headerlink" title="项目开发"></a>项目开发</h2><ol>
<li>只在项目根目录运行 Python。</li>
<li>项目启动文件只放在项目根目录，如要放在子目录中，则使用 python -m 启动。</li>
<li>在所有基于文件夹组织的模块中，一定要放 <strong>init</strong>.py。</li>
<li>不要在项目根目录放 <strong>init</strong>.py。</li>
</ol>
<h2 id="import"><a href="#import" class="headerlink" title="import"></a>import</h2><h3 id="sys-path"><a href="#sys-path" class="headerlink" title="sys.path"></a>sys.path</h3><p>sys.path 是 Python 的模块系统的重要部分。sys.path 保存了一个 list，里面含本机的一系列文件路径，在 import 一个模块的时候，会从前往后的在这些文件路径里根据规则寻找对应的模块，如果找到就返回。这意味着如果在 sys.path 里有多个同名的模块，只有在 sys.path 的前面模块会生效。<br>sys.path 有默认值，一般是 [“当前文件夹”, “Python 自带标准库目录”, “通过 pip 等命令安装的第三方库的目录”] 的顺序。如果当前环境变量配置了 PYTHONPATH，配置的值也会被添加到这个列表内，在当前文件夹之后。PYTHONPATH 默认是空的，一般也不会配置这个环境变量。</p>
<ul>
<li>sys.path.append()：添加要导入包的地址；</li>
<li>sys.path.insert()：添加要导入的包并定义搜索顺序。序号从 0 开始，表示最大优先级。（一般填 1）</li>
</ul>
<p>以上两种方法添加的均是临时搜索路径，程序退出后失效。</p>
<ol>
<li>python3 区分了相对导入和绝对导入。绝对导入的情况有两种：<ol>
<li>导入 sys.path 中的包（可通过<code>import sys; print(sys.path)</code>查看，为 python 库的安装目录）。</li>
<li>运行文件所在目录下的包</li>
</ol>
</li>
<li>一般情况下，使用相对导入的安全性高些。举例如下：<br>对于结构树形如：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Tree</span><br><span class="line">|____ m1.py</span><br><span class="line">|____ m2.py</span><br><span class="line">|____ Branch</span><br><span class="line">     |____m3.py</span><br><span class="line">     |____m4.py</span><br></pre></td></tr></table></figure>
在 m1.py 中<code>from branch import m3.py</code>，在 m3.py 中<code>import m4.py</code>。当运行 m3.py 时是不会出问题，但是运行 m1.py 时会报错，因为在绝对导入下，m1.py 是无法通过<code>import m4.py</code>导入 m4.py 的。<br>此时若在 m3.py 中使用相对导入<code>from . import m4.py</code>，则运行 m1.py 不会报错。</li>
<li>在第 2 点的例子中，m1.py 称为运行入口文件，运行入口文件可以使用绝对导入，但其他文件为避免不必要的报错建议使用相对导入。但综上，普遍使用相对导入即可。</li>
</ol>
<p><strong>相对导入</strong><br>使用相对导入需满足 package 所对应的文件夹必须正确的被 python 解释器视作 package，而不是普通文件夹。</p>
<ul>
<li><code>from . import module_name</code>。导入和自己同目录下的模块。</li>
<li><code>from .package_name import module_name</code>。导入和自己同目录的包的模块。</li>
<li><code>from .. import module_name</code>。导入上级目录的模块。</li>
<li><code>from ...package_name import module_name</code>。导入位于上级目录下的包的模块。</li>
</ul>
<p><strong>在 … 基础上，每多一个 .，再多往上一层目录。</strong></p>
<h2 id="argparse-ArgumentParser"><a href="#argparse-ArgumentParser" class="headerlink" title="argparse.ArgumentParser()"></a>argparse.ArgumentParser()</h2><ol>
<li>parser 是什么<br>所谓 parser，一般是指把某种格式的文本（字符串）转换成某种数据结构的过程。最常见的 parser，是把程序文本转换成编译器内部的一种叫做“抽象语法树”（AST）的数据结构。也有简单一些的 parser，用于处理 CSV，JSON，XML 之类的格式。</li>
<li>基本使用<ul>
<li>导入 argparse 模块：<code>import argparse</code></li>
<li>创建 ArgumentParser 对象：<br><code>parser = argparse.ArgumentParser(description=&#39;Process some integers.&#39;)</code><br>ArgumentParser 对象包含将命令行解析成 Python 数据类型所需的全部信息。description 参数用作解释。</li>
<li>获取帮助：<code>python demo.py -h</code>。</li>
</ul>
</li>
<li>进阶使用<br>parser.add_argument() 参数说明：<ul>
<li>第一个参数：参数名（默认位置传参，关键词传参需在参数名前添加’–’）</li>
<li>type：要传入参数的数据类型</li>
<li>help：该参数的提示信息</li>
<li>nargs：’+’ 表示传入至少一个参数</li>
<li>default：设置参数默认值</li>
<li>required：设置参数为必须</li>
</ul>
</li>
<li>parser 使用举例<figure class="highlight python"><figcaption><span>demo.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">&#x27;命令行中传入一个数字&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取单个参数（默认位置传参）</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;integers&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;传入的数字&#x27;</span>)</span><br><span class="line"><span class="comment"># 获取多个参数</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;integers&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, nargs =<span class="string">&#x27;+&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;传入的数字&#x27;</span>)</span><br><span class="line"><span class="comment"># 关键词传参（在参数名前面添加 &#x27;--&#x27;）</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--family&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;姓&#x27;</span>, required=<span class="literal">True</span>, default=<span class="string">&#x27;张&#x27;</span>)</span><br><span class="line"></span><br><span class="line">args = parser.parse_args()</span><br><span class="line"><span class="built_in">print</span>(args.integers)   <span class="comment"># 获得integers参数</span></span><br></pre></td></tr></table></figure>
对于位置传参，无需写参数名即可调起任务：<code>python demo.py 5</code>（若传入多个参数，使用空格间隔）。<br>对于关键词传参，需指定参数名：<code>python demo.py --family=张 --name=三</code>。<br>若 required=True，即使该参数存在默认值，也仍需传参，否则会报错。</li>
</ol>
<h2 id="知识点"><a href="#知识点" class="headerlink" title="知识点"></a>知识点</h2><ul>
<li>查看当前 python 的路径：<code>print(sys.executable)</code></li>
<li>json() 函数<ol>
<li><code>json.dumps</code>：将 Python 对象编码成 JSON 字符串</li>
<li><code>json.loads</code>：将已编码的 JSON 字符串解码为 Python 对象</li>
</ol>
</li>
<li>tqdm<br>tqdm 模块是 python 进度条库，可基于迭代对象运行: tqdm(iterator)。eg：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm, trange</span><br><span class="line"></span><br><span class="line"><span class="comment"># trange(i) 是 tqdm(range(i)) 的一种简单写法</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> trange(<span class="number">100</span>):</span><br><span class="line">    time.sleep(<span class="number">0.05</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(<span class="number">100</span>), desc=<span class="string">&#x27;Processing&#x27;</span>):</span><br><span class="line">    time.sleep(<span class="number">0.05</span>)</span><br></pre></td></tr></table></figure></li>
<li>“\t”：横向制表符。类似 tab 键，但缩进 8 个字符位置。</li>
<li>set 集合运算<br>x = set(), y = set()<ul>
<li>x&amp;y、x.intersection(y)：集合取交集</li>
<li>x|y、x.union(y)：集合取并集</li>
<li>x-y、x.difference(y)：集合取差集（x 与 y 的差集）</li>
</ul>
</li>
<li>Counter()<ul>
<li>统计列表/字符串中各元素出现的次数：<code>counter = Counter(list)</code>，以类似字典形式返回。如{9: 3}</li>
<li>统计出现次数最多的元素：<code>counter.most_common(1)</code>。统计出现次数最多的一个元素，以列表形式返回。如[{9, 3}]</li>
</ul>
</li>
<li>round()<br>对浮点数进行近似取值，保留几位小数。一般形式 round(x,n)<ul>
<li>round(x)：不含 n 时，输出为 x 的整数；</li>
<li>round(x,n)：对浮点数 x 取小数点后 n 位的四舍五入值</li>
</ul>
</li>
<li>range()<ul>
<li>range(end)：遍历从 0 到 end-1 的所有整数</li>
<li>range(start, end)：遍历从 start 到 end-1 的所有整数</li>
<li>range(start, end, step)：从 start 开始，每隔 step 个数输出整数遍历</li>
</ul>
</li>
<li>os.path.join()<br>用于文件路径的拼接，可传入多个参数。<ul>
<li>若有多个以 “/“ 开头的参数，从最后 “/“ 开头的的开始往后拼接，之前的参数全部丢弃；</li>
<li>若没有 “/“ 开头的参数，则在拼接的参数间自动添加 “/“；</li>
<li>在确保以上情况下，若出现 “./“ 开头的参数，会从 “./“ 开头的参数的上一个参数开始拼接。</li>
</ul>
</li>
<li>class 中特殊函数<ol>
<li><strong>init</strong>() 函数：等同于类的构造器，作用是初始化一个实例</li>
<li><strong>call</strong>() 函数：将一个类实例当做函数调用。举例：若类 X 中实现了如下方法：<code>def __call__(self, *args)</code>，而 x 是类 X 的一个实例，那么<code>x.__call__(1,2)</code>等同于<code>x(1,2)</code>。</li>
<li><strong>del</strong>() 函数：等同于类的析构函数。</li>
</ol>
</li>
<li>命令行执行 .py 文件<ol>
<li><code>python xxx.py</code>。直接运行，脚本的<code>&#39;__name__&#39;</code>为’main’。</li>
<li><code>python -m xxx</code>。把模块当作脚本启动，相当于 import，此时脚本的<code>&#39;__name__&#39;</code>相当于’xxx’。这种启动方式后面最好不要带后缀 .py。<br>这两种加载方式的差异，主要是影响 sys.path 这个属性。直接启动：把 xxx.py 文件所在的目录放到了 sys.path 属性中。<br>模块启动：把命令行执行的当前路径放到了 sys.path 属性中。</li>
</ol>
  <strong>补充：通过<code>print(__name__)</code>可看到包路径</strong></li>
<li>//：整除运算符，返回商的整数部分</li>
<li>for 循环<ul>
<li><code>for _ in range(2)</code>：其中的 “_” 仅起到循环数字的作用，该字符在此轮循环中不会用到</li>
</ul>
</li>
</ul>
<h2 id="virtualenvwrapper"><a href="#virtualenvwrapper" class="headerlink" title="virtualenvwrapper"></a>virtualenvwrapper</h2><blockquote>
<p>virtualenv 的一个最大的缺点就是，每次开启虚拟环境之前要去虚拟环境所在目录下的 bin 目录下 source 一下 activate，这就需要我们记住每个虚拟环境所在的目录。<br>Virtaulenvwrapper是virtualenv的扩展包，用于更方便管理虚拟环境，它可以做：<br>1. 将所有虚拟环境组织在一个目录下；<br>2. 管理（新增，删除，复制）虚拟环境；<br>3. 更方便的在不同的虚拟环境下进行切换</p>
</blockquote>
<ul>
<li>安装：<code>pip install virtualenvwrapper-win</code></li>
<li>配置：virtualenvwrapper 需要指定一个环境变量，叫做 WORKON_HOME，该目录可用来存放各种虚拟环境目录。</li>
<li>列出所有虚拟环境：<code>lsvirtualenv</code></li>
<li>创建虚拟环境：<ul>
<li><code>mkvirtualenv test</code></li>
<li><code>virtualenv --no-site-packages test</code>（不带任何系统 python 环境的第三方包）</li>
<li><code>mkvirtualenv -p python3.5 test</code>（指定 python 版本）</li>
</ul>
</li>
<li>进入虚拟环境：<code>workon test</code></li>
<li>删除虚拟环境：<code>rmvirtualenv test</code></li>
<li>退出当前的虚拟环境：<code>deactivate</code></li>
</ul>
<hr>
<h1 id="Tensorflow"><a href="#Tensorflow" class="headerlink" title="Tensorflow"></a>Tensorflow</h1><blockquote>
<p><a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf">Tensorflow API 官方</a></p>
</blockquote>
<h2 id="常用方法"><a href="#常用方法" class="headerlink" title="常用方法"></a>常用方法</h2><ul>
<li><code>tf.cast(x, dtype, name=None)</code>：tensor 类型强转。<ul>
<li>x：输入的 tensor；</li>
<li>dtype：要转换的类型，如 tf.int32。</li>
</ul>
</li>
<li><code>tf.compat.v1.nn.rnn_cell.LSTMCell(num_units, use_peepholes=False, cell_clip=None, initializer=None, num_proj=None, proj_clip=None, num_unit_shards=None, num_proj_shards=None, forget_bias=1.0, state_is_tuple=True, activation=None, reuse=None, name=None, dtype=None,**kwargs)</code>：用于获取长短期记忆单元 (LSTM) 循环网络单元。<ul>
<li>num_units：整数，LSTM 单元中的单元数。</li>
<li>use_peepholes：布尔类型，若为 True 则启用对角线/窥视孔连接。</li>
</ul>
</li>
<li><code>tf.compat.v1.nn.rnn_cell.DropoutWrapper(*args, **kwargs)</code>：操控添加 dropout 到给定单元的输入和输出。<ul>
<li>cell：一个 rnn 单元。</li>
<li>input_keep_prob：Tensor or float，在 0 和 1 之间，表示输入保持概率。如果它是常数且为 1，则不会添加输​​入 dropout。</li>
<li>output_keep_prob：Tensor or float，在 0 和 1 之间，表示输出保持概率。如果它是常数且为 1，则不会添加输​出 dropout。</li>
<li>：布尔类型。如果为 True，则每次运行调用的所有时间步都应用相同的 dropout 模式。如果设置了此参数，则必须提供 input_size。<br>所谓 dropout,就是指网络中每个单元在每次有数据流入时以一定的概率(keep prob)正常工作，否则输出 0 值。这是是一种有效的正则化方法，可以有效防止过拟合。在 rnn 中进行 dropout 时，对于 rnn 的部分不进行 dropout，也就是说从 t-1 时候的状态传递到 t 时刻进行计算时，这个中间不进行 memory 的 dropout；仅在同一个 t 时刻中，多层 cell 之间传递信息的时候进行 dropout。<br>Dropout只能是层与层之间（输入层与LSTM1层、LSTM1层与LSTM2层）的Dropout；同一个层里面，T时刻与T+1时刻是不会Dropout的。</li>
</ul>
</li>
<li><code>tf.compat.v1.nn.rnn_cell.MultiRNNCell(cells, state_is_tuple=True)</code>：将多个简单 cells 组成 RNN cell，用于构建多层循环神经网络。<ul>
<li>cells：一个 list，按该 list 的元素顺序组成 RNN cell 返回；</li>
<li>state_is_tuple：若为 True，则接受和返回的状态是 n 元组，其中 n = len(cells)。若为 False，则所有状态都沿列轴连接。后一种行为将很快被弃用。</li>
</ul>
</li>
<li><code>tf.compat.v1.nn.bidirectional_dynamic_rnn(   cell_fw, cell_bw, inputs, sequence_length=None, initial_state_fw=None,   initial_state_bw=None, dtype=None, parallel_iterations=None, swap_memory=False,   time_major=False, scope=None )</code>：创建双向循环神经网络的动态版本。 （已弃用）<ul>
<li>cell_fw：RNN cell，用于正向</li>
<li>cell_bw：RNN cell，用于反向</li>
<li>返回：一个元组 (outputs, output_states) ：<ul>
<li>outputs：一个元组 (output_fw, output_bw)，包含前向和后向 rnn 输出张量。</li>
<li>output_states：一个元组 (output_state_fw, output_state_bw)，包含双向 rnn 的前向和后向最终状态。</li>
</ul>
</li>
</ul>
</li>
<li><code>tf.concat(values, axis, name=&#39;concat&#39;)</code>：concat 方法将不同 tensor 在 axis 维度上合并成一个 tensor。<ul>
<li>values：元素为 tensor 类型的数组</li>
<li>axis：要拼接的维度</li>
</ul>
</li>
<li><code>tf.constant(value, dtype=None, shape=None, name=&#39;Const&#39;)</code>：将输入的 value 转化为 tf.Tensor 格式。<ul>
<li>value：输入数组，可为一维/二维或多维；</li>
<li>dtype：输出数组元素的类型；</li>
<li>shape：输出数组的形状，元素不够则补 0；tf.keras.Input</li>
</ul>
</li>
<li><code>tf.keras.Input(shape=None, batch_size=None, name=None, dtype=None, sparse=False, tensor=None, ragged=False, **kwargs)</code>：用于构建网络的第一层——输入层，该层会告诉网络我们的输入的尺寸是什么，并实例化 Keras 张量。<ul>
<li>shape：一个形状元组（整数），不包括 batch_size；</li>
<li>batch_size：喂入模型的样本大小；</li>
<li>dtype：输入期望的数据类型，如 int32。</li>
</ul>
</li>
<li><code>tf.keras.layers.Dropout(rate, noise_shape=None, seed=None, **kwargs)</code>：仅能用在训练期间，以防止模型过拟合。该方法将输入的每个值放大 (1/(1-rate)) 倍。<ul>
<li>rate：0 ~ 1 之间的小数。让神经元以一定的概率 rate 停止工作，提高模型的泛化能力。</li>
<li>noise_shape：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/42340680">dropout 中的 noise_shape 参数的作用</a></li>
<li>seed：随机种子，使结果可复现。</li>
</ul>
</li>
<li><code>tf.keras.layers.Flatten(data_format=None, **kwargs)</code>：将输入层的数据压成一维数据，一般用在卷积层和全连接层之间。因为全连接层只能接收一维数据，而卷积层可以处理二维数据。<ul>
<li>data_format：channels_last（默认） or channels_first。</li>
</ul>
</li>
<li><code>tf.math.square(x)</code>：对输入求平方，并返回。<ul>
<li>x：一个元素或数组</li>
</ul>
</li>
<li><code>tf.one_hot(indices, depth, on_value=None, off_value=None, axis=None, dtype=None, name=None)</code>，one_hot 编码，返回（输入数组的维数 + 1）维数组<ul>
<li>indices：任意维数组；</li>
<li>depth：为要扩展的维度大小；</li>
<li>on_value：索引位置处的值，默认为 1；</li>
<li>off_value：非索引位置处的值，默认为 0；</li>
<li>axis：指定扩展的维度，默认为 -1，扩展的维度在最后一维；</li>
<li>dtype：返回数组值的类型。</li>
</ul>
 <strong>注意：tf.one_hot()方法不适用元素为 float 类型的数组，故在调用该方法前，需类型强转为 int 类型。</strong></li>
<li><code>tf.reduce_max(input_tensor, axis=None, name=None, keepdims=False)</code>，按维度取最大值后返回所有值组成的数组。<ul>
<li>input_tensor：输入数据</li>
<li>axis：表示维度。0 表示最外层维度，-1表示最内层维度。从 0 开始数字每加 1 表示下一内层维度，当 axis 为默认表示求全局最大值。</li>
<li>keepdims：是否保持矩形原狀。默认为 False，此时维度减少一维。为 True 时，维度保持不变。</li>
</ul>
</li>
<li><code>tf.reduce_mean(input_tensor, axis=None, keepdims=False, name=None)</code>：用于计算张量 tensor 在某指定度上的的平均值，主要用作降维或者计算 tensor(图像)的平均值<ul>
<li>input_tensor：输入的 tensor；</li>
<li>axis：指定的轴，若无，则计算所有元素的均值；</li>
<li>keep_dims：是否保留原输入尺寸。默认为 False，输出结果会降一维，若为 True，输出结果 shape 保持不变;</li>
<li>name：操作的名称;</li>
</ul>
</li>
<li><code>tf.reshape(tensor, shape)</code>：将 tensor 转化为 shape 数组表示的多维形式。<ul>
<li>tensor：输入</li>
<li>shape：要转换的格式</li>
</ul>
</li>
<li><code>tf.sequence_mask(lengths, maxlen=None, dtype=tf.dtypes.bool, name=None)</code>：生成一个二维张量。张量行数 = lengths 元素个数；张量列数 = max(maxlen, lengths 中最大的元素值)。<ul>
<li>lengths：一维数组，每个数组元素值对应生成张量的一行中 true 元素的个数；</li>
<li>maxlen：若非 None，则该值为生成张量的每行最大列数；</li>
<li>dtype：要填充元素的类型。</li>
</ul>
</li>
<li><code>tf.sparse.slice(sp_input, start, size, name=None)</code>：将稀疏矩阵 sp_input 切片。<ul>
<li>sp_input：稀疏矩阵；</li>
<li>start：切片的起点，值一般如 [0,0]；</li>
<li>size：切片的大小，值一般如 [2,4]；</li>
</ul>
</li>
<li><code>tf.sparse.to_dense(sp_input, default_value=None, validate_indices=True, name=None)</code>：将稀疏矩阵 sp_input 转化为普通矩阵。<ul>
<li>sp_input：稀疏矩阵；</li>
<li>default_value：若稀疏矩阵某处无值，则为默认填充的值。</li>
</ul>
</li>
</ul>
<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><ul>
<li>归一化处理：将输入特征值变小至 0 - 1 之间，目的是使输入特征值更适合神经网络吸收。</li>
<li>对于输入的图像像素数组，0 表示纯黑色，255 表示纯白色。</li>
<li>tf.Tensor 是一种数据结构。shape 属性表示数组的形式，dtype 属性表示数组元素类型。</li>
<li>卷积时 padding 扩边的计算方法：将卷积核中心与左顶点对齐后，卷积核超出 feature map 的部分即为需扩边的行数。</li>
</ul>
<h2 id="知识点-1"><a href="#知识点-1" class="headerlink" title="知识点"></a>知识点</h2><ol start="11">
<li><p>Outputs random values from a normal distribution.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tf.random.normal(</span><br><span class="line">    shape, mean=<span class="number">0.0</span>, stddev=<span class="number">1.0</span>, dtype=tf.dtypes.float32, seed=<span class="literal">None</span>, name=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></li>
<li><p>将数据格式转为tf.train.Example格式</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">feature=&#123;</span><br><span class="line">	<span class="string">&quot;k1&quot;</span>: tf.train.Feature(bytes_list=tf.train.BytesList(value=]),   <span class="comment"># 对应 bytes</span></span><br><span class="line">	<span class="string">&quot;k2&quot;</span>: tf.train.Feature(bytes_list=tf.train.Int64List(value=)),   <span class="comment"># 对应 int64</span></span><br><span class="line">	<span class="string">&quot;k3&quot;</span>: tf.train.Feature(float_list=tf.train.FloatList(value=)),   <span class="comment"># 对应 float</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>要将我们的数据写入 .tfrecords 文件，需要将每一个样本数据封装为tf.train.Example格式，再将Example逐个写入文件。Example 格式中的数据基础类型是 tf.train.Feature：<code>tf.train.Example(features=tf.train.Features(feature=features))</code></p>
</li>
<li><p>tf.data.Dataset</p>
<ul>
<li>batch(batch_size, drop_remainder=False, num_parallel_calls=None, deterministic=None)<br>将数据集中的数据按顺序分批次（批次大小为 batch_size）组织。参数解释：<pre><code>  - batch_size：数据的批次大小
  - drop_remainder（可选）：最后一批不满足 batch_size 大小的数据是否丢弃。
</code></pre>
</li>
<li>interleave(map_func, cycle_length=None, block_length=None, num_parallel_calls=None, deterministic=None)<pre><code>  - map_func：取出的对象喂入的函数
  - cycle_length：每次取出对象喂入函数的个数
  - block_length：每次取出的对象喂入函数后得到的新对象
</code></pre>
</li>
</ul>
</li>
<li><p>tf.placeholder<br>placeholder，占位符，在 tensorflow 中类似于函数参数，运行时再赋具体的值。</p>
<blockquote>
<p>Tensorflow 的设计理念称之为计算流图，在编写程序时，首先构筑整个系统的 graph，代码并不会直接生效，这一点和 python 的其他数值计算库（如 Numpy 等）不同。graph 为静态的，类似于 docker 中的镜像。然后，在实际的运行时，启动一个 session，程序才会真正的运行。这样做的好处就是：避免反复地切换底层程序实际运行的上下文，tensorflow 帮你优化整个系统的代码。<br>我们知道，很多 python 程序的底层为 C 语言或者其他语言，执行一行脚本，就要切换一次，这是有成本的，tensorflow 通过计算流图的方式，帮你优化整个 session 需要执行的代码，还是很有优势的。</p>
</blockquote>
<p><strong>为什么要用placeholder?</strong><br>placeholder() 函数是在神经网络构建 graph 的时候在模型中的占位，此时并没有把要输入的数据传入模型，它只会分配必要的内存。等建立 session，在会话中，运行模型的时候通过 feed_dict() 函数向占位符喂入数据。</p>
</li>
<li><p>tf.variable_scope<br>tf.variable_scope()会在模型中开辟自己的空间，而其中的变量均在这个空间内进行管理，其目的是实现变量共享。</p>
</li>
</ol>
<ul>
<li>tf.contrib.layers.repeat<br><code>repeat(inputs, repetitions, layer, *args, **kwargs)</code><br>eg：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">y = repeat(x, <span class="number">3</span>, conv2d, <span class="number">64</span>, [<span class="number">3</span>, <span class="number">3</span>], scope=<span class="string">&#x27;conv1&#x27;</span>)</span><br><span class="line"><span class="comment"># It is equivalent to:</span></span><br><span class="line"></span><br><span class="line">x = conv2d(x, <span class="number">64</span>, [<span class="number">3</span>, <span class="number">3</span>], scope=<span class="string">&#x27;conv1/conv1_1&#x27;</span>)</span><br><span class="line">x = conv2d(x, <span class="number">64</span>, [<span class="number">3</span>, <span class="number">3</span>], scope=<span class="string">&#x27;conv1/conv1_2&#x27;</span>)</span><br><span class="line">y = conv2d(x, <span class="number">64</span>, [<span class="number">3</span>, <span class="number">3</span>], scope=<span class="string">&#x27;conv1/conv1_3&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
<li>tf.layers.separable_conv2d<br>深度可分离卷积 = Depthwise Convolution（逐通道卷积） + Pointwise Convolution（逐点卷积）<ul>
<li>Depthwise Convolution：卷积核大小为设定尺寸 kernel_size，厚度固定为 1，个数为输入通道数。对于输入的每个 feature_map，仅使用一个卷积核进行卷积，将不同卷积核卷积得到的 feature_map 组合作为下一次的输入。</li>
<li>Pointwise Convolution：卷积核大小为 1 * 1，厚度为输入通道数（默认），个数为输出通道数。此时卷积和普通卷积过程一样。</li>
</ul>
</li>
<li>tf.contrib.layers.max_pool2d()/avg_pool2d()<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool2d</span>/<span class="title">avg_pool2d</span>()(<span class="params">inputs,</span></span></span><br><span class="line"><span class="params"><span class="function">               kernel_size,   <span class="comment">#A 4-D tensor of shape `[batch_size, height, width, channels]` </span></span></span></span><br><span class="line"><span class="params"><span class="function">               stride=<span class="number">2</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">               padding=<span class="string">&#x27;VALID&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">               data_format=DATA_FORMAT_NHWC,</span></span></span><br><span class="line"><span class="params"><span class="function">               outputs_collections=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">               scope=<span class="literal">None</span></span>):</span></span><br></pre></td></tr></table></figure></li>
<li>tf.get_variable：<a target="_blank" rel="noopener" href="https://blog.csdn.net/xc_zhou/article/details/88646611">https://blog.csdn.net/xc_zhou/article/details/88646611</a></li>
</ul>
<h2 id="Sequential-搭建网络八股"><a href="#Sequential-搭建网络八股" class="headerlink" title="Sequential 搭建网络八股"></a>Sequential 搭建网络八股</h2><h3 id="六步法"><a href="#六步法" class="headerlink" title="六步法"></a>六步法</h3><ol>
<li>import</li>
<li>train, test —— 准备训练集和测试集（区分输入特征和标签）</li>
<li>model = tf.keras.models.Sequential —— 在 Sequential() 搭建网络结构，逐层描述每层结构</li>
<li>model.compile —— 在 compile() 配置训练方法，选择优化器、损失函数、评测指标 </li>
<li>model.fit —— 在 fit() 中执行训练过程，告知训练集和测试集的输入特征和标签、告知 batch 大小（样本大小），epoch 大小（迭代次数）</li>
<li>model.summary —— 使用 summary() 打印网络的结构和参数统计</li>
</ol>
<h3 id="详解"><a href="#详解" class="headerlink" title="详解"></a>详解</h3><p><strong>Sequential()</strong><br><code>model = tf.keras.models.Sequential ([ 网络结构 ])   #描述各层网络（从输入层到输出层每一层的网络结构）</code></p>
<p>网络结构举例：</p>
<ul>
<li>拉直层：<code>tf.keras.layers.Flatten()</code>，把输入特征拉直变成一维数组</li>
<li>全连接层： <code>tf.keras.layers.Dense(神经元个数, activation= &quot;激活函数“ ,kernel_regularizer=哪种正则化)</code><ul>
<li>activation（字符串给出）可选: relu、 softmax、 sigmoid 、 tanh</li>
<li>kernel_regularizer 可选: tf.keras.regularizers.l1()、tf.keras.regularizers.l2()</li>
</ul>
</li>
<li>卷积层： <code>tf.keras.layers.Conv2D(filters = 卷积核个数, kernel_size = 卷积核尺寸 strides = 卷积步长， padding = &quot; valid&quot; or &quot;same&quot;)</code></li>
<li>LSTM 层（循环神经网络层）： <code>tf.keras.layers.LSTM()</code></li>
</ul>
<p><strong>compile()</strong><br><code>model.compile(optimizer = 优化器, loss = 损失函数, metrics = [“准确率”] )</code></p>
<ul>
<li><p>Optimizer可选:<br>‘sgd’ or tf.keras.optimizers.SGD (lr=学习率,momentum=动量参数)<br>‘adagrad’ or tf.keras.optimizers.Adagrad (lr=学习率)<br>‘adadelta’ or tf.keras.optimizers.Adadelta (lr=学习率)<br>‘adam’ or tf.keras.optimizers.Adam (lr=学习率, beta_1=0.9, beta_2=0.999)</p>
</li>
<li><p>loss可选:<br>‘mse’ or tf.keras.losses.MeanSquaredError()<br>‘sparse_categorical_crossentropy’ or tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)</p>
</li>
<li><p>Metrics可选:<br>‘accuracy’ ：y_和y都是数值，如y_=[1] y=[1]<br>‘categorical_accuracy’ ：y_和y都是独热码(概率分布)，如y_=[0,1,0] y=[0.256,0.695,0.048]<br>‘sparse_categorical_accuracy’ ：y_是数值，y是独热码(概率分布),如y_=[1] y=[0.256,0.695,0.048]<strong>（重要）</strong></p>
</li>
</ul>
<p><strong>fit()</strong><br><code>model.fit(训练集的输入特征, 训练集的标签, batch_size= , epochs= , validation_data=(测试集的输入特征，测试集的标签), validation_split=从训练集划分多少比例给测试集，validation_freq = 多少次epoch测试一次)</code></p>
<ul>
<li>batch_size：样本数</li>
<li>epochs：数据集迭代次数</li>
<li>validation_data 和 validation_split 两者选一</li>
<li>validation_freq：多少次 epochs 迭代使用测试集验证一次结果</li>
</ul>
<p><strong>summary()</strong><br><code>model.summary()</code>：打印网络的结构和参数统计</p>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 准备 train、test</span></span><br><span class="line">x_train = datasets.load_iris().data</span><br><span class="line">y_train = datasets.load_iris().target</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">116</span>)</span><br><span class="line">np.random.shuffle(x_train)</span><br><span class="line">np.random.seed(<span class="number">116</span>)</span><br><span class="line">np.random.shuffle(y_train)</span><br><span class="line">tf.random.set_seed(<span class="number">116</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># models.Sequential</span></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">3</span>, activation=<span class="string">&#x27;softmax&#x27;</span>, kernel_regularizer=tf.keras.regularizers.l2())</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># model.compile</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=tf.keras.optimizers.SGD(lr=<span class="number">0.1</span>),</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># model.fit</span></span><br><span class="line">model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">500</span>, validation_split=<span class="number">0.2</span>, validation_freq=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># model.summary</span></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<p><strong>用 Sequential 可以搭出上层输出就是下层输入的顺序网络结构</strong></p>
<h2 id="类-class-搭建网络八股"><a href="#类-class-搭建网络八股" class="headerlink" title="类 class 搭建网络八股"></a>类 class 搭建网络八股</h2><h3 id="六步法-1"><a href="#六步法-1" class="headerlink" title="六步法"></a>六步法</h3><ol>
<li>import</li>
<li>train, test</li>
<li><strong>class MyModel(Model) model=MyModel()</strong></li>
<li>model.compile</li>
<li>model.fit</li>
<li>model.summary</li>
</ol>
<p><strong>可知，与使用 Sequential() 仅在第三步有所不同</strong></p>
<h3 id="详解-1"><a href="#详解-1" class="headerlink" title="详解"></a>详解</h3><p><strong>类 Class</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通用格式</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModel</span>(<span class="params">Model</span>):</span>   <span class="comment"># 继承 model 类</span></span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">	    <span class="built_in">super</span>(MyModel, self).__init__()</span><br><span class="line">	    定义网络结构块</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, x</span>):</span></span><br><span class="line">	    调用网络结构块，实现前向传播</span><br><span class="line">	    <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">model = MyModel()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 举例</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IrisModel</span>(<span class="params">Model</span>):</span></span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">	    <span class="built_in">super</span>(IrisModel, self).__init__()</span><br><span class="line">	    self.d1 = Dense(<span class="number">3</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>, kernel_regularizer=tf.keras.regularizers.l2())</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, x</span>):</span></span><br><span class="line">	    y = self.d1(x)   <span class="comment"># d1 是 Modle 里的方法</span></span><br><span class="line">	    <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">model = IrisModel()</span><br></pre></td></tr></table></figure>

<h3 id="实现-1"><a href="#实现-1" class="headerlink" title="实现"></a>实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x_train = datasets.load_iris().data</span><br><span class="line">y_train = datasets.load_iris().target</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">116</span>)</span><br><span class="line">np.random.shuffle(x_train)</span><br><span class="line">np.random.seed(<span class="number">116</span>)</span><br><span class="line">np.random.shuffle(y_train)</span><br><span class="line">tf.random.set_seed(<span class="number">116</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IrisModel</span>(<span class="params">Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(IrisModel, self).__init__()</span><br><span class="line">        self.d1 = Dense(<span class="number">3</span>, activation=<span class="string">&#x27;softmax&#x27;</span>, kernel_regularizer=tf.keras.regularizers.l2())</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        y = self.d1(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">model = IrisModel()</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=tf.keras.optimizers.SGD(lr=<span class="number">0.1</span>),</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">500</span>, validation_split=<span class="number">0.2</span>, validation_freq=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<h2 id="神经网络八股功能扩展"><a href="#神经网络八股功能扩展" class="headerlink" title="神经网络八股功能扩展"></a>神经网络八股功能扩展</h2><h3 id="六步法-2"><a href="#六步法-2" class="headerlink" title="六步法"></a>六步法</h3><ol>
<li>自制数据集，解决本领域应用。</li>
<li>数据增强，扩充数据集</li>
<li>断点续训，存取模型</li>
<li>参数提取，把参数存入文本</li>
<li>acc/loss可视化，查看训练效果</li>
<li>应用程序，给图识物</li>
</ol>
<h3 id="详解-2"><a href="#详解-2" class="headerlink" title="详解"></a>详解</h3><p><strong>断点续训，存取模型</strong></p>
<ul>
<li><p>读取模型<br>load_weights(路径文件名)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">checkpoint_save_path = <span class="string">&quot;./checkpoint/mnist.ckpt&quot;</span>   <span class="comment"># 模型文件名为 ckpt 格式</span></span><br><span class="line"><span class="keyword">if</span> os.path.exists(checkpoint_save_path + <span class="string">&#x27;.index&#x27;</span>):   <span class="comment"># 生成 ckpt 文件时会同步生成索引表 -- .index 文件</span></span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&#x27;---------------load the model----------------&#x27;</span>)</span><br><span class="line">	model.load.weights(checkpoint_save_path)</span><br></pre></td></tr></table></figure></li>
<li><p>保存模型<br>  <strong>借助 tensorflow 给出的回调函数，直接保存参数和网络</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cp_callback  = tf.keras.callbacks.ModelCheckpoint(</span><br><span class="line">						filepath=路径文件名, </span><br><span class="line">						save_weights_only=<span class="literal">True</span>/<span class="literal">False</span>,   <span class="comment"># 告知是否只保留模型参数 </span></span><br><span class="line">						save_best_only=<span class="literal">True</span>/<span class="literal">False</span>,   <span class="comment"># 告知是否只保留最优结果 </span></span><br><span class="line">						monitor=<span class="string">&#x27;val_loss&#x27;</span>, <span class="comment"># val_loss or loss)</span></span><br><span class="line">history = model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>, validation_data=(x_test, y_test), validation_freq=<span class="number">1</span>, callbacks=[cp_callback])   <span class="comment"># 训练时，加入 callbacks 选项，记录到 history</span></span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>注:monitor 配合 save_best_only 可以保存最优模型，包括:训练损失最小模型、测试损失最小模型、训练准确率最高模型、测试准确率最高模型等。</strong></p>
<hr>
<h1 id="算法模型"><a href="#算法模型" class="headerlink" title="算法模型"></a>算法模型</h1><h2 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h2><blockquote>
<p>卷积神经网络（Convolutional Neural Networks），多用于图像识别</p>
</blockquote>
<h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><p><strong>一维卷积</strong></p>
<blockquote>
<p>设 feature map 的宽长为 (a,b)，filters 为 x。则一维卷积后 feature map 尺寸变为 (a,x)。feature map 个数保持不变<br>即若输入为 (None,a,b)，经 x 个 filters, padding=true 卷积后输出为 (None,a,x)</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.layers.Conv1D(</span><br><span class="line">    filters, kernel_size, </span><br><span class="line">    strides=<span class="number">1</span>, padding=<span class="string">&#x27;valid&#x27;</span>, data_format=<span class="string">&#x27;channels_last&#x27;</span>,</span><br><span class="line">    dilation_rate=<span class="number">1</span>, groups=<span class="number">1</span>, activation=<span class="literal">None</span>, use_bias=<span class="literal">True</span>, </span><br><span class="line">    kernel_initializer=<span class="string">&#x27;glorot_uniform&#x27;</span>, bias_initializer=<span class="string">&#x27;zeros&#x27;</span>, </span><br><span class="line">    kernel_regularizer=<span class="literal">None</span>, bias_regularizer=<span class="literal">None</span>, activity_regularizer=<span class="literal">None</span>, </span><br><span class="line">    kernel_constraint=<span class="literal">None</span>, bias_constraint=<span class="literal">None</span>, **kwargs</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>参数解析：</p>
<ul>
<li>filters：卷积核个数</li>
<li>kernel_size：卷积核大小，在一维卷积里指卷积核宽的大小，长自动对齐 feature map</li>
<li>strides：卷积的步长</li>
<li>padding：三个枚举值（大小写敏感）<ul>
<li>“valid” 表示「不填充」，默认</li>
<li>“same” 表示填充输入以使输出具有与原始输入相同的长宽</li>
<li>“causal” 表示因果（膨胀）卷积。</li>
</ul>
</li>
<li>data_format：表示输入的维度顺序，有两个枚举值<ul>
<li>“channels_last” 对应输入尺寸为 (batch, height, weight, channels)，默认</li>
<li>“channels_first” 对应输入尺寸为 (batch, channels, height, weight)</li>
</ul>
</li>
<li>dilation_rate：指膨胀卷积的膨胀率。不可同时指定 dilation_rate != 1 &amp;&amp; stride != 1</li>
<li>activation：要使用的激活函数。如未指定，则不使用激活函数(即线性激活：a(x) = x)。</li>
<li>use_bias：布尔值，该层是否使用偏置向量。</li>
<li>kernel_initializer：kernel 权值矩阵的初始化器 (详见 initializers)。</li>
<li>bias_initializer：偏置向量的初始化器 (详见 initializers)。</li>
<li>kernel_regularizer：运用到 kernel 权值矩阵的正则化函数 (详见 regularizer)。</li>
<li>bias_regularizer：运用到偏置向量的正则化函数 (详见 regularizer)。</li>
<li>activity_regularizer：运用到层输出（它的激活值）的正则化函数 (详见 regularizer)。</li>
<li>kernel_constraint：运用到 kernel 权值矩阵的约束函数 (详见 constraints)。</li>
<li>bias_constraint：运用到偏置向量的约束函数 (详见 constraints)。</li>
</ul>
<p>补充：</p>
<ul>
<li>输入尺寸：3D 张量（必需），如 (batch_size * channels, height, weight)</li>
<li>输出尺寸：3D 张量，如 (batch_size * channels, height, filters)，其中 strides=1, padding=”same”</li>
<li>使用示例：<ul>
<li>outputs = tf.keras.layers.Conv1D(64, 2)(inputs)</li>
<li>outputs = tf.keras.layers.Conv1D(64, 2, input_shape=input_shape[2:])(inputs)</li>
</ul>
</li>
</ul>
<p><strong>二维卷积</strong></p>
<blockquote>
<p>若输入为 (None,c,a,b)(NCHW)，经 x 个 filters, padding=true 卷积后输出为 (None,x,a,b)</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.layers.Conv2D(</span><br><span class="line">    filters, kernel_size, </span><br><span class="line">    strides=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">&#x27;valid&#x27;</span>, data_format=<span class="literal">None</span>, </span><br><span class="line">    dilation_rate=(<span class="number">1</span>, <span class="number">1</span>), groups=<span class="number">1</span>, activation=<span class="literal">None</span>, use_bias=<span class="literal">True</span>, </span><br><span class="line">    kernel_initializer=<span class="string">&#x27;glorot_uniform&#x27;</span>, bias_initializer=<span class="string">&#x27;zeros&#x27;</span>, </span><br><span class="line">    kernel_regularizer=<span class="literal">None</span>, bias_regularizer=<span class="literal">None</span>, activity_regularizer=<span class="literal">None</span>, </span><br><span class="line">    kernel_constraint=<span class="literal">None</span>, bias_constraint=<span class="literal">None</span>, **kwargs</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>参数解析：</p>
<ul>
<li>filters：卷积核个数</li>
<li>kernel_size：卷积核大小。若为一个整数，则卷积核长宽同为该整数；若为两个整数(元组/列表)，则分别指定卷积核长宽</li>
<li>strides：卷积的步长。若为一个整数，则卷积长宽方向步长相同；若为两个整数，则分别指定卷积长宽方向步长</li>
<li>dilation_rate：指膨胀卷积的膨胀率。若为一个整数，则长宽方向膨胀率均为该值；若为两个整数，则分别指定长宽方向膨胀率。且不可同时指定 dilation_rate != 1 &amp;&amp; stride != 1<br>  <strong>其他同一维卷积</strong></li>
</ul>
<p>补充</p>
<ul>
<li>输入尺寸：4D 张量（必需），如 (batch_size, channels, height, weight)</li>
<li>输出尺寸：4D 张量，如 (batch_size, filters, height, weight)，其中 strides=1, padding=”same”</li>
<li>使用示例：<ul>
<li>outputs = tf.keras.layers.Conv2D(64, 3)(inputs)</li>
</ul>
</li>
</ul>
<p><strong>其它</strong></p>
<ul>
<li>两个 3<em>3 卷积核如何替代一个 5</em>5 卷积核<ul>
<li>假设有一个 5 * 5 的 inputs，经过一个 5 * 5 卷积核卷积后输出一个数。</li>
<li>若经过一个 3 * 3 卷积核卷积，则得到一个 3 * 3 的 feature map；再一次使用一个 3 * 3 的卷积核卷积，其输出就变为一个数，与经过一个 5 * 5 卷积核卷积得到的输出尺寸一致。<br>此即通过小卷积核 + 层层叠加代替大卷积核扩大感受野。</li>
</ul>
</li>
</ul>
<h3 id="池化"><a href="#池化" class="headerlink" title="池化"></a>池化</h3><p><strong>一维池化</strong></p>
<blockquote>
<p>以最大池化为例<br>若输入为 (None,64,64)(NCHW)，经 pool_size=2,stride=2 池化后，输出为 (None,32,64)</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.layers.MaxPool1D(</span><br><span class="line">    pool_size=<span class="number">2</span>, strides=<span class="literal">None</span>, padding=<span class="string">&#x27;valid&#x27;</span>,</span><br><span class="line">    data_format=<span class="string">&#x27;channels_last&#x27;</span>, **kwargs</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>参数解析：</p>
<ul>
<li>pool_size：池化窗口的大小。在一维池化中指窗口高度大小，长度为 1</li>
<li>strides：窗口移动的步长。当为 None 时，strides 为 pool_size 大小</li>
<li>padding：可选 “valid” 或 “same”。<ul>
<li>“valid”：output_shape = (input_shape - pool_size) / strides) + 1</li>
<li>“same”：output_shape = input_shape / strides</li>
</ul>
</li>
<li>data_format：NHWC 或 NCHW</li>
</ul>
<p>补充：</p>
<ul>
<li>输入尺寸：3D 张量（必需），如 (batch_size * channels, height, weight)</li>
<li>输出尺寸：3D 张量，如 (batch_size * channels, height / 2, weight)，其中 strides=2, padding=”same”</li>
<li>使用示例：<ul>
<li>outputs = tf.keras.layers.MaxPool1D(2, 2)(inputs)</li>
</ul>
</li>
</ul>
<p><strong>二维池化</strong></p>
<blockquote>
<p>以最大池化为例<br>若输入为 (None,8,64,64)(NCHW)，经 pool_size=(2,2),stride=(2,2) 池化后，输出为 (None,8,32,32)</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.layers.MaxPool2D(</span><br><span class="line">    pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="literal">None</span>, padding=<span class="string">&#x27;valid&#x27;</span>,</span><br><span class="line">    data_format=<span class="literal">None</span>, **kwargs</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>参数解析：</p>
<ul>
<li>pool_size：池化窗口的大小</li>
<li>strides：窗口移动的步长（二元组）。当为 None 时，strides 为 pool_size 大小</li>
<li>padding：可选 “valid” 或 “same”。<ul>
<li>“valid”：output_weight = (input_weight - pool_weight) / strides) + 1（以宽为例，高同理）</li>
<li>“same”：output_weight = input_weight / strides</li>
</ul>
</li>
<li>data_format：NHWC（默认）或 NCHW</li>
</ul>
<p>补充：</p>
<ul>
<li>输入尺寸：4D 张量（必需），如 (batch_size, channels, height, weight)</li>
<li>输出尺寸：4D 张量，如 (batch_size, channels, height / 2, weight / 2)，其中 strides=(2,2), padding=”same”</li>
<li>使用示例：<ul>
<li>outputs = tf.keras.layers.MaxPool2D((2,2), (2,2))(inputs)</li>
</ul>
</li>
</ul>
<h3 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h3><blockquote>
<p>2014 年，牛津大学计算机视觉组（Visual Geometry Group）和 Google DeepMind 公司的研究员一起研发出了新的深度卷积神经网络：VGGNet，并取得了 ILSVRC2014 比赛分类项目的第二名（第一名是 GoogleNet，也是同年提出的)。VGG 可以看成是加深版的 AlexNet，整个网络由卷积层和全连接层叠加而成，和 AlexNet 不同的是，VGG 中使用的都是小尺寸的卷积核 (3×3)。</p>
</blockquote>
<p>VGG 主要针对卷积神经网络的深度对大规模图像集识别精度的影响，主要贡献是使用很小的卷积核（3×3）构建各种深度的卷积神经网络结构，并对这些网络结构进行了评估，最终证明 16-19 层的网络深度，能够取得较好的识别精度。这也就是常用来提取图像特征的 VGG-16 和 VGG-19。</p>
<p><strong>VGG 的特点</strong></p>
<ol>
<li><p>结构简洁，如下：</p>
<img src="/2021/10/25/%E5%B7%A5%E4%BD%9C%E7%A7%AF%E7%B4%AF/vgg1.jpg" class=""></li>
<li><p>小卷积核和连续的卷积层<br>VGG中使用的都是 3×3 卷积核，并且使用了连续多个卷积层。这样做的好处：</p>
<ol>
<li>使用连续的的多个小卷积核(3×3)，来代替一个大的卷积核。对于给定的感受野（与输出有关的输入图片的局部大小），采用堆积的小卷积核是优于采用大的卷积核，因为多层非线性层可以增加网络深度来保证学习更复杂的模式，而且代价还比较小（参数更少）。</li>
<li>使用小的卷积核的问题是，其感受野必然变小。所以，VGG 中就使用连续的 3×3 卷积核，来增大感受野。VGG 认为 2 个连续的 3×3 卷积核能够替代一个 5×5 卷积核，三个连续的 3×3 能够代替一个 7×7。在保证具有相同感知野的条件下，提升了网络的深度，在一定程度上提升了神经网络的效果。<img src="/2021/10/25/%E5%B7%A5%E4%BD%9C%E7%A7%AF%E7%B4%AF/vgg2.jpg" class=""></li>
</ol>
</li>
<li><p>小池化核，使用的是 2×2</p>
</li>
<li><p>通道数更多，特征度更宽<br>每个通道代表着一个FeatureMap，更多的通道数表示更丰富的图像特征。VGG网络第一层的通道数为64，后面每层都进行了翻倍，最多到512个通道，通道数的增加，使得更多的信息可以被提取出来。</p>
</li>
<li><p>层数更深<br>使用连续的小卷积核代替大的卷积核，网络的深度更深，并且对边缘进行填充，卷积的过程并不会降低图像尺寸。仅使用小的池化单元，降低图像的尺寸。</p>
</li>
</ol>
<h3 id="MobileNets"><a href="#MobileNets" class="headerlink" title="MobileNets"></a>MobileNets</h3><blockquote>
<p>背景：随着深度学习的发展，卷积神经网络变得越来越普遍。当前发展的总体趋势，是通过更深和更复杂的网络来得到更高的精度，但是这种网络往往在模型大小和运行速度上没多大优势。一些嵌入式平台上的应用比如机器人和自动驾驶，它们的硬件资源有限，就十分需要一种轻量级、低延迟（同时精度尚可接受）的网络模型，这就是 MobileNets 的主要工作。</p>
</blockquote>
<p>MobileNets 是一个用于移动和嵌入式视觉应用的高效模型。MobileNets 是基于一个流线型的架构，它使用深度可分离的卷积来构建轻量级的深层神经网络。该模型引入两个简单的全局超参数，在延迟度和准确度之间有效地进行平衡。这两个超参数允许模型构建者根据问题的约束条件，为其应用选择合适大小的模型。</p>
<p>在建立小型和有效的神经网络上，已经有了一些工作，比如 SqueezeNet，Google Inception，Flattened network等等。大概分为压缩预训练模型和直接训练小型网络两种。MobileNets 主要关注优化延迟，同时兼顾模型大小。</p>
<p><strong>深度可分解卷积</strong><br>MobileNets 模型基于深度可分解的卷积，它可以将标准卷积分解成一个深度卷积和一个点卷积（1×1 卷积核）。深度卷积将每个卷积核应用到每一个通道，而 1×1 卷积用来组合通道卷积的输出。论文《MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications》也证明，这种分解可以有效减少计算量，降低模型大小。<br>直观上来看，这种分解在效果上是等价的。比如，输入图片维度是 11 × 11 × 3，标准卷积为 3 × 3 × 3 × 16（假设 stride 为 2，padding 为 1），那么可以得到输出为 6 × 6 × 16 的输出结果。现在输入图片不变，先通过一个维度是 3 × 3 × 1 × 3 的深度卷积（输入是 3 通道，这里有 3 个卷积核，对应着进行计算，理解成 for 循环），得到 6 × 6 × 3 的中间输出，然后再通过一个维度是 1 × 1 × 3 ×16 的 1 × 1 卷积，同样得到输出为 6 × 6 × 16。</p>
<h3 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h3><blockquote>
<p>ResNet（Residual Neural Network）由微软研究院的 Kaiming He 等四名华人提出，通过使用 ResNet Unit 成功训练出了 152 层的神经网络，并在 ILSVRC2015 比赛中取得冠军，在 top5 上的错误率为 3.57%，同时参数量比 VGGNet 低，效果非常突出。ResNet 的结构可以极快的加速神经网络的训练，模型的准确率也有比较大的提升。同时 ResNet 的推广性非常好，甚至可以直接用到 InceptionNet 网络中。</p>
</blockquote>
<p>ResNet 的主要思想是在网络中增加了直连通道，即 Highway Network 的思想。此前的网络结构是性能输入做一个非线性变换，而 Highway Network 则允许保留之前网络层的一定比例的输出。ResNet 的思想和 Highway Network 的思想也非常类似，允许原始输入信息直接传到后面的层中，如下图所示。</p>
<img src="/2021/10/25/%E5%B7%A5%E4%BD%9C%E7%A7%AF%E7%B4%AF/ResNet1.jpg" class="">

<p><strong>创新点</strong><br>提出残差学习的思想。VGGNet 和 ResNet 的对比如下图所示。</p>
<p><strong>网络结构</strong></p>
<blockquote>
<p>传统的卷积网络或者全连接网络在信息传递的时候或多或少会存在信息丢失，损耗等问题，同时还有导致梯度消失或者梯度爆炸，导致很深的网络无法训练。ResNet 在一定程度上解决了这个问题，通过直接将输入信息绕道传到输出，保护信息的完整性，整个网络只需要学习输入、输出差别的那一部分，简化学习目标和难度。ResNet 最大的特点在于有很多的旁路将输入直接连接到后面的层，这种结构也被称为 shortcut 或者 skip connections。</p>
</blockquote>
<p>在 ResNet 网络结构中会用到两种残差模块，一种是以两个 3x3 的卷积网络串接在一起作为一个残差模块，另外一种是 1x1、3x3、1x1 的 3 个卷积网络串接在一起作为一个残差模块。他们如下图所示。</p>
<img src="/2021/10/25/%E5%B7%A5%E4%BD%9C%E7%A7%AF%E7%B4%AF/ResNet3.jpg" class="">

<p>ResNet有不同的网络层数，比较常用的是 50-layer，101-layer，152-layer。他们都是由上述的残差模块堆叠在一起实现的。</p>
<img src="/2021/10/25/%E5%B7%A5%E4%BD%9C%E7%A7%AF%E7%B4%AF/ResNet4.jpg" class="">

<p><strong>和 VGGNet 的对比</strong></p>
<img src="/2021/10/25/%E5%B7%A5%E4%BD%9C%E7%A7%AF%E7%B4%AF/ResNet2.jpg" class="">

<h2 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h2><blockquote>
<p>循环神经网络（Recurrent Neural Networks），广泛应用于自然语言处理（Natural Language Processing, NLP）<br>RNNs 引入了定向循环，能够处理那些输入之间前后关联的问题</p>
</blockquote>
<h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><blockquote>
<p>长短期记忆（Long short-term memory, LSTM）是一种特殊的 RNN，主要是为了解决长序列训练过程中的梯度消失和梯度爆炸问题。简单来说，就是相比普通的 RNN，LSTM 能够在更长的序列中有更好的表现。</p>
</blockquote>
<p>RNN 与 LSTM 对比：</p>
<img src="/2021/10/25/%E5%B7%A5%E4%BD%9C%E7%A7%AF%E7%B4%AF/LSTM_1.jpg" class="" title="左图是 RNN，右图是 LSTM">

<p>基本状态：<br>首先使用 LSTM 的当前输入 <code>x^t</code> 和上一个状态传递下来的 <code>h^(t-1)</code> 拼接训练得到四个状态。<br>其中， <code>z^i</code>，<code>z^f</code>，<code>z^o</code> 是由拼接向量乘以权重矩阵之后，再通过一个 sigmod 激活函数转换成 0 到 1 之间的数值，来作为一种门控状态。而 z 则是将结果通过一个 tanh 激活函数将转换成 -1 到 1 之间的值（这里使用 tanh 是因为这里是将其作为输入数据，而不是门控信号）。</p>
<img src="/2021/10/25/%E5%B7%A5%E4%BD%9C%E7%A7%AF%E7%B4%AF/LSTM_2.png" class="">

<p><strong>LSTM 的三个阶段</strong><br><code>圆圈·</code> 是 Hadamard Product，即操作矩阵中对应的元素相乘，因此要求两个相乘矩阵是同型的。<code>圆圈＋</code> 则代表进行矩阵加法。</p>
<img src="/2021/10/25/%E5%B7%A5%E4%BD%9C%E7%A7%AF%E7%B4%AF/LSTM_3.jpg" class="">
<ol>
<li>忘记阶段。这个阶段主要是对上一个节点传进来的输入进行选择性忘记。简单来说就是会 “忘记不重要的，记住重要的”。<br>具体来说是通过计算得到的 <code>z^f</code>（f 表示 forget）来作为忘记门控，来控制上一个状态的 <code>c^(t-1)</code> 哪些需要留或忘。</li>
<li>选择记忆阶段。这个阶段将这个阶段的输入有选择性地进行“记忆”。主要是会对输入 <code>x^t</code> 进行选择记忆。哪些重要则着重记录下来，哪些不重要，则少记一些。当前的输入内容由前面计算得到的 z 表示。而选择的门控信号则是由 <code>z^i</code>（i 代表 information）来进行控制。<br> <strong>将上面两步得到的结果相加，即可得到传输给下一个状态的 <code>c^t</code>。也就是上图中的第一个公式。</strong></li>
<li>输出阶段。这个阶段将决定哪些将会被当成当前状态的输出。主要是通过 <code>z^o</code> 来进行控制的。并且还对上一阶段得到的 <code>c^o</code> 进行了放缩（通过一个 tanh 激活函数进行变化）。<br>与普通RNN类似，输出 <code>y^t</code> 往往最终也是通过 <code>h^t</code> 变化得到。</li>
</ol>
<p><strong>总结</strong><br>LSTM 通过门控状态来控制传输状态，记住需要长时间记忆的信息，且忘记不重要的信息；而不像普通的 RNN 那样“呆萌”地仅有一种记忆叠加方式。对很多需要“长期记忆”的任务来说，尤其好用。<br>但也因为引入了很多内容，导致参数变多，也使得训练难度加大了很多。因此很多时候可使用效果和 LSTM 相当但参数更少的 GRU 来构建大训练量的模型。</p>
<hr>
<h1 id="字节实习（2021-07-05-）"><a href="#字节实习（2021-07-05-）" class="headerlink" title="字节实习（2021.07.05 - ）"></a>字节实习（2021.07.05 - ）</h1><h2 id="问题排查总结"><a href="#问题排查总结" class="headerlink" title="问题排查总结"></a>问题排查总结</h2><ol>
<li><p>抖音客户端视频播放量和 ad 后台统计的播放量不一致。<br>答：一般思路，按以下两种情况排查：</p>
<ul>
<li>根据 ad_id 查询其在不同 app_name，rit（广告位）的播放量。统计所有 app_name、rit 的播放量，和 ad 后台统计的播放量进行对比，若能对齐，则没有问题。因为抖音客户端视频播放量只是其中一个 app_name，rit 的播放量。</li>
<li>由于 ad_id 可能会在某时刻更换了广告创意（item_id），因此需确认端视频的 item_id 是否和 ad_id 对应的 item_id 一样。</li>
<li>到 hive 表中查询该 ad_id 对应的播放量，若数据能和 ad 后台统计的对齐，则没有问题。</li>
</ul>
<p> 若以上数据排查没有问题，则说明 ad_id 统计的播放量没有问题。可能是客户端的统计数据出了问题。<br> <strong>补充：</strong></p>
<ul>
<li>客户端的统计播放量一般比 ad_id 对应的 app_name、rit 大，这是因为客户端播放量包括了自然流量和广告引导流量，而 ad 平台只统计广告引导流量。</li>
<li>客户端统计播放量在高并发下难免出现丢数的情况，而广告统计的数据因业务原因是保证不丢数的，因此客户端显示的播放量一般是端平台统计的播放量和广告平台统计的播放量中取最大值。</li>
<li>一个ad_id 在一个 app_name 可能存在多个 rit</li>
<li>一个视频可能有多个 ad_id（广告计划）（可增大曝光量），一个 ad_id 在某时刻只能对应一个视频（若该视频是广告创意）。ad_id 可在某时刻更换视频（广告创意）</li>
</ul>
</li>
</ol>
<h2 id="维度拼接中间件服务"><a href="#维度拼接中间件服务" class="headerlink" title="维度拼接中间件服务"></a>维度拼接中间件服务</h2><ol>
<li>传入的请求是 batchRequest，含有多个 request，每个 request 有如下成员属性：<ul>
<li>该请求中作为拼接的维度，如 adId、creativeId 等。</li>
<li>该请求请求拼接的维度 dimensionList。</li>
</ul>
</li>
<li>对于每次传入的 batchRequest，目的是构造一系列 dimQueryRequest。每个 dimQueryRequest 需做好如下成员属性配置：<ul>
<li>dimNameList。dimNameList 为查询子服务需要拼接的维度。</li>
<li>RpcFunQueryService。为需要查询的子服务。</li>
<li>dimIdValueSetMap。形如 &lt;作为拼接的维度名(如 adId), 该维度有的值&gt;</li>
</ul>
</li>
</ol>
<h3 id="中和非中构造-dimQueryRequest-的过程"><a href="#中和非中构造-dimQueryRequest-的过程" class="headerlink" title="中和非中构造 dimQueryRequest 的过程"></a>中和非中构造 dimQueryRequest 的过程</h3><ul>
<li>中：<ol>
<li>遍历 request，遍历所有作为拼接的维度，若该维度有值，放入 BatchQueryIdSetInfo 的各个成员属性 set 中。</li>
<li>遍历 dimensionList 中每个 dimensionName，根据构建的&lt;维度, rpc 子服务&gt;的 map 的映射获取 rpc 子服务，赋值给成员属性 RpcFunQueryService。</li>
<li>把当前遍历的 dimensionName 添加到成员属性 dimNameList。</li>
<li>通过 if 条件构造 dimIdValueSetMap。</li>
</ol>
</li>
<li>非中：<ol>
<li>遍历 request，遍历 dimensionList 中每个 dimName。</li>
<li>通过 dimServiceMap 根据 dimName 获取 RpcFunQueryService，并赋值给成员属性 RpcFunQueryService。</li>
<li>把当前遍历的 dimName 添加到成员属性 dimNameList。</li>
<li>根据 RpcFunQueryService 的 ServiceInfo 对象（涉嫌重复构建）的 inputDims（作为拼接的维度），从 request 中获取该 inputDims 的值，把它添加到 dimIdValueSetMap</li>
</ol>
</li>
</ul>
<h2 id="ad-粒度聚合-flink-任务-–-dws-ad-stats-ad-aggregation"><a href="#ad-粒度聚合-flink-任务-–-dws-ad-stats-ad-aggregation" class="headerlink" title="ad 粒度聚合 flink 任务 – dws_ad_stats_ad_aggregation"></a>ad 粒度聚合 flink 任务 – dws_ad_stats_ad_aggregation</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 注册udf</span></span><br><span class="line"><span class="keyword">create</span> legacy <span class="keyword">function</span> LONG_TO_TIMESTAMP <span class="keyword">as</span> <span class="string">&#x27;com.bytedance.flink.udf.udf.time.LongToTimestamp&#x27;</span>;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">function</span> aggregate_map_sum_udaf <span class="keyword">as</span> <span class="string">&#x27;com.bytedance.ad.dataplatform.flinkudf.AggregateMapSumUDAF&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- source table 定义</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> source_table (</span><br><span class="line">    advertiser_id <span class="type">BIGINT</span>,</span><br><span class="line">    advertiser_system_origin <span class="type">BIGINT</span>,</span><br><span class="line">    ad_id <span class="type">BIGINT</span>,</span><br><span class="line">    ad_record_creator_id <span class="type">BIGINT</span>,</span><br><span class="line">    anchor_id <span class="type">BIGINT</span>,</span><br><span class="line">    app_code <span class="type">BIGINT</span>,</span><br><span class="line">    auto_tool_type <span class="type">BIGINT</span>,</span><br><span class="line">    campaign_id <span class="type">BIGINT</span>,</span><br><span class="line">    campaign_type <span class="type">INT</span>,</span><br><span class="line">    cart_id <span class="type">BIGINT</span>,</span><br><span class="line">    content_type <span class="type">BIGINT</span>,</span><br><span class="line">    convert_id <span class="type">BIGINT</span>,</span><br><span class="line">    convert_type <span class="type">BIGINT</span>,</span><br><span class="line">    create_channel <span class="type">BIGINT</span>,</span><br><span class="line">    creative_material_mode <span class="type">INT</span>,</span><br><span class="line">    customer_id <span class="type">BIGINT</span>,</span><br><span class="line">    customer_name <span class="type">VARCHAR</span>,</span><br><span class="line">    deep_bid_type <span class="type">BIGINT</span>,</span><br><span class="line">    deep_external_action <span class="type">BIGINT</span>,</span><br><span class="line">    delivery_mode <span class="type">BIGINT</span>,</span><br><span class="line">    douplus_budget_type <span class="type">BIGINT</span>,</span><br><span class="line">    ecp_app_id <span class="type">BIGINT</span>,</span><br><span class="line">    ecp_user_group <span class="type">BIGINT</span>,</span><br><span class="line">    engine_ad_id <span class="type">BIGINT</span>,</span><br><span class="line">    event_time_hour <span class="type">BIGINT</span>,</span><br><span class="line">    external_action <span class="type">INT</span>,</span><br><span class="line">    first_industry_id <span class="type">BIGINT</span>,</span><br><span class="line">    first_industry_name <span class="type">VARCHAR</span>,</span><br><span class="line">    group_type <span class="type">BIGINT</span>,</span><br><span class="line">    is_brand_ad_overflow <span class="type">INT</span>,</span><br><span class="line">    is_orange <span class="type">BIGINT</span>,</span><br><span class="line">    is_startup <span class="type">BIGINT</span>,</span><br><span class="line">    landing_type <span class="type">INT</span>,</span><br><span class="line">    local_stat_time_day <span class="type">VARCHAR</span>,</span><br><span class="line">    local_stat_time_hour <span class="type">VARCHAR</span>,</span><br><span class="line">    marketing_goal <span class="type">BIGINT</span>,</span><br><span class="line">    monitor_ts <span class="type">BIGINT</span>,</span><br><span class="line">    native_type <span class="type">BIGINT</span>,</span><br><span class="line">    package_name <span class="type">VARCHAR</span>,</span><br><span class="line">    page_id <span class="type">BIGINT</span>,</span><br><span class="line">    page_type <span class="type">BIGINT</span>,</span><br><span class="line">    pricing <span class="type">INT</span>,</span><br><span class="line">    pricing_category <span class="type">INT</span>,</span><br><span class="line">    qianchuan_product_id <span class="type">BIGINT</span>,</span><br><span class="line">    rit_group_type <span class="type">INT</span>,</span><br><span class="line">    scene_type <span class="type">BIGINT</span>,</span><br><span class="line">    second_industry_id <span class="type">BIGINT</span>,</span><br><span class="line">    second_industry_name <span class="type">VARCHAR</span>,</span><br><span class="line">    site_account_id <span class="type">BIGINT</span>,</span><br><span class="line">    smart_bid_type <span class="type">BIGINT</span>,</span><br><span class="line">    stat_time_day <span class="type">VARCHAR</span>,</span><br><span class="line">    stat_time_hour <span class="type">VARCHAR</span>,</span><br><span class="line">    system_origin <span class="type">BIGINT</span>,</span><br><span class="line">    unique_id <span class="type">VARCHAR</span>,</span><br><span class="line">    platform_version <span class="type">INT</span>,</span><br><span class="line">    cdp_project_id <span class="type">BIGINT</span>,</span><br><span class="line">    cdp_promotion_id <span class="type">BIGINT</span>,</span><br><span class="line">    metric_data MAP<span class="operator">&lt;</span><span class="type">VARCHAR</span>, <span class="type">BIGINT</span><span class="operator">&gt;</span>,</span><br><span class="line">    proctime <span class="keyword">AS</span> PROCTIME(),</span><br><span class="line">    new_event_time_hour <span class="keyword">as</span> LONG_TO_TIMESTAMP(event_time_hour <span class="operator">*</span> <span class="number">1000</span>),</span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> new_event_time_hour <span class="keyword">AS</span> new_event_time_hour <span class="operator">-</span> <span class="type">interval</span> <span class="string">&#x27;2&#x27;</span> <span class="keyword">hour</span></span><br><span class="line">) <span class="keyword">with</span> (</span><br><span class="line">    <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka-0.10&#x27;</span>, </span><br><span class="line">    <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;ad_stats_pre_agg_joined_billing&#x27;</span>, </span><br><span class="line">    <span class="string">&#x27;properties.cluster&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka_huge_6th&#x27;</span>, </span><br><span class="line">    <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;flink_ad_aggregation_v1&#x27;</span>, </span><br><span class="line">    <span class="string">&#x27;parallelism&#x27;</span><span class="operator">=</span><span class="string">&#x27;300&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;group-offsets&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;scan.reset-to-earliest-for-new-partition&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;false&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;json&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;properties.ignore.dc.check&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;true&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;scan.manually-commit-offsets-interval&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;5000&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 计费事件去重</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">view</span> billing_event_distinct_table <span class="keyword">as</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    <span class="operator">*</span> </span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">        <span class="keyword">select</span></span><br><span class="line">            <span class="operator">*</span>,</span><br><span class="line">            <span class="built_in">ROW_NUMBER</span>() <span class="keyword">OVER</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> unique_id <span class="keyword">ORDER</span> <span class="keyword">BY</span> proctime <span class="keyword">ASC</span>) <span class="keyword">as</span> row_num</span><br><span class="line">        <span class="keyword">from</span> source_table</span><br><span class="line">        <span class="keyword">where</span> <span class="built_in">COALESCE</span>(metric_data[<span class="string">&#x27;cost&#x27;</span>], <span class="number">0</span>) <span class="operator">&gt;</span> <span class="number">0</span></span><br><span class="line">    )</span><br><span class="line"><span class="keyword">where</span> row_num <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 聚合操作</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">view</span> agg_table <span class="keyword">as</span> </span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    advertiser_id,</span><br><span class="line">    <span class="built_in">max</span>(advertiser_system_origin) <span class="keyword">as</span> advertiser_system_origin,</span><br><span class="line">    ad_id,</span><br><span class="line">    ad_record_creator_id,</span><br><span class="line">    <span class="built_in">max</span>(anchor_id) <span class="keyword">as</span> anchor_id,</span><br><span class="line">    app_code,</span><br><span class="line">    <span class="built_in">min</span>(<span class="keyword">case</span> <span class="keyword">when</span> create_channel <span class="operator">=</span> <span class="number">21</span> <span class="keyword">or</span> create_channel <span class="operator">=</span> <span class="number">23</span> <span class="keyword">then</span> <span class="number">1</span> <span class="keyword">when</span> smart_bid_type <span class="operator">=</span> <span class="number">1</span> <span class="keyword">or</span> smart_bid_type <span class="operator">=</span> <span class="number">2</span> <span class="keyword">then</span> <span class="number">2</span> <span class="keyword">else</span> <span class="number">3</span> <span class="keyword">end</span>) <span class="keyword">as</span> auto_tool_type,</span><br><span class="line">    campaign_id,</span><br><span class="line">    <span class="built_in">max</span>(campaign_type) <span class="keyword">as</span> campaign_type,</span><br><span class="line">    <span class="built_in">max</span>(cart_id) <span class="keyword">as</span> cart_id,</span><br><span class="line">    <span class="built_in">max</span>(content_type) <span class="keyword">as</span> content_type,</span><br><span class="line">    <span class="built_in">max</span>(convert_id) <span class="keyword">as</span> convert_id,</span><br><span class="line">    <span class="built_in">max</span>(convert_type) <span class="keyword">as</span> convert_type,</span><br><span class="line">    <span class="built_in">max</span>(create_channel) <span class="keyword">as</span> create_channel,</span><br><span class="line">    <span class="built_in">max</span>(creative_material_mode) <span class="keyword">as</span> creative_material_mode,</span><br><span class="line">    <span class="built_in">max</span>(customer_id) <span class="keyword">as</span> customer_id,</span><br><span class="line">    <span class="built_in">max</span>(customer_name) <span class="keyword">as</span> customer_name,</span><br><span class="line">    <span class="built_in">max</span>(deep_bid_type) <span class="keyword">as</span> deep_bid_type,</span><br><span class="line">    <span class="built_in">max</span>(deep_external_action) <span class="keyword">as</span> deep_external_action,</span><br><span class="line">    delivery_mode,</span><br><span class="line">    <span class="built_in">max</span>(douplus_budget_type) <span class="keyword">as</span> douplus_budget_type,</span><br><span class="line">    <span class="built_in">max</span>(ecp_app_id) <span class="keyword">as</span> ecp_app_id,</span><br><span class="line">    ecp_user_group,</span><br><span class="line">    engine_ad_id,</span><br><span class="line">    event_time_hour,</span><br><span class="line">    <span class="built_in">max</span>(external_action) <span class="keyword">as</span> external_action,</span><br><span class="line">    <span class="built_in">max</span>(first_industry_id) <span class="keyword">as</span> first_industry_id,</span><br><span class="line">    <span class="built_in">max</span>(first_industry_name) <span class="keyword">as</span> first_industry_name,</span><br><span class="line">    <span class="built_in">max</span>(group_type) <span class="keyword">as</span> group_type,</span><br><span class="line">    <span class="built_in">max</span>(is_brand_ad_overflow) <span class="keyword">as</span> is_brand_ad_overflow,</span><br><span class="line">    <span class="built_in">max</span>(is_orange) <span class="keyword">as</span> is_orange,</span><br><span class="line">    <span class="built_in">max</span>(is_startup) <span class="keyword">as</span> is_startup,</span><br><span class="line">    <span class="built_in">max</span>(landing_type) <span class="keyword">as</span> landing_type,</span><br><span class="line">    local_stat_time_day,</span><br><span class="line">    local_stat_time_hour,</span><br><span class="line">    <span class="built_in">max</span>(marketing_goal) <span class="keyword">as</span> marketing_goal,</span><br><span class="line">    <span class="built_in">max</span>(monitor_ts) <span class="keyword">as</span> monitor_ts,</span><br><span class="line">    <span class="built_in">max</span>(native_type) <span class="keyword">as</span> native_type,</span><br><span class="line">    <span class="built_in">max</span>(package_name) <span class="keyword">as</span> package_name,</span><br><span class="line">    <span class="built_in">max</span>(page_id) <span class="keyword">as</span> page_id,</span><br><span class="line">    <span class="built_in">max</span>(page_type) <span class="keyword">as</span> page_type,</span><br><span class="line">    <span class="built_in">max</span>(pricing) <span class="keyword">as</span> pricing,</span><br><span class="line">    <span class="built_in">max</span>(pricing_category) <span class="keyword">as</span> pricing_category,</span><br><span class="line">    qianchuan_product_id,</span><br><span class="line">    rit_group_type,</span><br><span class="line">    <span class="built_in">max</span>(scene_type) <span class="keyword">as</span> scene_type,</span><br><span class="line">    <span class="built_in">max</span>(second_industry_id) <span class="keyword">as</span> second_industry_id,</span><br><span class="line">    <span class="built_in">max</span>(second_industry_name) <span class="keyword">as</span> second_industry_name,</span><br><span class="line">    <span class="built_in">max</span>(site_account_id) <span class="keyword">as</span> site_account_id,</span><br><span class="line">    <span class="built_in">max</span>(smart_bid_type) <span class="keyword">as</span> smart_bid_type,</span><br><span class="line">    stat_time_day,</span><br><span class="line">    stat_time_hour,</span><br><span class="line">    <span class="built_in">max</span>(system_origin) <span class="keyword">as</span> system_origin,</span><br><span class="line">    platform_version,</span><br><span class="line">    cdp_project_id,</span><br><span class="line">    cdp_promotion_id,</span><br><span class="line">    MD5(</span><br><span class="line">        concat_ws(<span class="string">&#x27;-&#x27;</span>,</span><br><span class="line">                <span class="built_in">CAST</span>(<span class="built_in">COALESCE</span>(advertiser_id, <span class="number">0</span>) <span class="keyword">as</span> STRING),</span><br><span class="line">                <span class="built_in">CAST</span>(<span class="built_in">COALESCE</span>(ad_id, <span class="number">0</span>) <span class="keyword">as</span> STRING),</span><br><span class="line">                <span class="built_in">CAST</span>(<span class="built_in">COALESCE</span>(ad_record_creator_id, <span class="number">0</span>) <span class="keyword">as</span> STRING),</span><br><span class="line">                <span class="built_in">CAST</span>(<span class="built_in">COALESCE</span>(app_code, <span class="number">0</span>) <span class="keyword">as</span> STRING),</span><br><span class="line">                <span class="built_in">CAST</span>(<span class="built_in">COALESCE</span>(campaign_id, <span class="number">0</span>) <span class="keyword">as</span> STRING),</span><br><span class="line">                <span class="built_in">CAST</span>(<span class="built_in">COALESCE</span>(delivery_mode, <span class="number">0</span>) <span class="keyword">as</span> STRING),</span><br><span class="line">                <span class="built_in">CAST</span>(<span class="built_in">COALESCE</span>(ecp_user_group, <span class="number">0</span>) <span class="keyword">as</span> STRING),</span><br><span class="line">                <span class="built_in">CAST</span>(<span class="built_in">COALESCE</span>(engine_ad_id, <span class="number">0</span>) <span class="keyword">as</span> STRING),</span><br><span class="line">                <span class="built_in">CAST</span>(<span class="built_in">COALESCE</span>(event_time_hour, <span class="number">0</span>) <span class="keyword">as</span> STRING),</span><br><span class="line">                local_stat_time_day,</span><br><span class="line">                local_stat_time_hour,</span><br><span class="line">                <span class="built_in">CAST</span>(<span class="built_in">COALESCE</span>(qianchuan_product_id, <span class="number">0</span>) <span class="keyword">as</span> STRING),</span><br><span class="line">                <span class="built_in">CAST</span>(<span class="built_in">COALESCE</span>(rit_group_type, <span class="number">0</span>) <span class="keyword">as</span> STRING),</span><br><span class="line">                stat_time_day,</span><br><span class="line">                stat_time_hour,</span><br><span class="line">                <span class="built_in">CAST</span>(<span class="built_in">COALESCE</span>(platform_version, <span class="number">0</span>) <span class="keyword">as</span> STRING),</span><br><span class="line">                <span class="built_in">CAST</span>(<span class="built_in">COALESCE</span>(cdp_project_id, <span class="number">0</span>) <span class="keyword">as</span> STRING),</span><br><span class="line">                <span class="built_in">CAST</span>(<span class="built_in">COALESCE</span>(cdp_promotion_id, <span class="number">0</span>) <span class="keyword">as</span> STRING)</span><br><span class="line">        )</span><br><span class="line">    ) <span class="keyword">as</span> doc_id,</span><br><span class="line">    aggregate_map_sum_udaf(metric_data) <span class="keyword">as</span> metric_data,</span><br><span class="line">    (unix_timestamp() <span class="operator">-</span> <span class="built_in">max</span>(monitor_ts)) <span class="operator">*</span> <span class="number">1000</span> <span class="keyword">as</span> batch_metrics_ts</span><br><span class="line"><span class="keyword">from</span> </span><br><span class="line">    (</span><br><span class="line">        <span class="keyword">select</span></span><br><span class="line">            <span class="operator">*</span></span><br><span class="line">        <span class="keyword">from</span> billing_event_distinct_table</span><br><span class="line">        <span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line">        <span class="keyword">select</span></span><br><span class="line">            <span class="operator">*</span>,</span><br><span class="line">            <span class="number">1</span> <span class="comment">-- 用于对齐union两端的列，增加一个1作为row_num的占位</span></span><br><span class="line">        <span class="keyword">from</span> source_table</span><br><span class="line">        <span class="keyword">where</span> <span class="built_in">COALESCE</span>(metric_data[<span class="string">&#x27;cost&#x27;</span>], <span class="number">0</span>) <span class="operator">=</span> <span class="number">0</span> <span class="keyword">and</span> <span class="keyword">CARDINALITY</span>(metric_data) <span class="operator">&gt;</span> <span class="number">0</span></span><br><span class="line">    ) union_tab</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span></span><br><span class="line">    advertiser_id,</span><br><span class="line">    ad_id,</span><br><span class="line">    ad_record_creator_id,</span><br><span class="line">    app_code,</span><br><span class="line">    campaign_id,</span><br><span class="line">    delivery_mode,</span><br><span class="line">    ecp_user_group,</span><br><span class="line">    engine_ad_id,</span><br><span class="line">    event_time_hour,</span><br><span class="line">    local_stat_time_day,</span><br><span class="line">    local_stat_time_hour,</span><br><span class="line">    qianchuan_product_id,</span><br><span class="line">    rit_group_type,</span><br><span class="line">    stat_time_day,</span><br><span class="line">    stat_time_hour,</span><br><span class="line">    platform_version,</span><br><span class="line">    cdp_project_id,</span><br><span class="line">    cdp_promotion_id,</span><br><span class="line">    tumble(new_event_time_hour, <span class="type">INTERVAL</span> <span class="string">&#x27;1&#x27;</span> <span class="keyword">HOUR</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- sink table 定义</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> sink_table (</span><br><span class="line">    advertiser_system_origin <span class="type">BIGINT</span>,</span><br><span class="line">    anchor_id <span class="type">BIGINT</span>,</span><br><span class="line">    auto_tool_type <span class="type">INT</span>,</span><br><span class="line">    campaign_type <span class="type">INT</span>,</span><br><span class="line">    cart_id <span class="type">BIGINT</span>,</span><br><span class="line">    content_type <span class="type">BIGINT</span>,</span><br><span class="line">    convert_id <span class="type">BIGINT</span>,</span><br><span class="line">    convert_type <span class="type">BIGINT</span>,</span><br><span class="line">    create_channel <span class="type">BIGINT</span>,</span><br><span class="line">    creative_material_mode <span class="type">INT</span>,</span><br><span class="line">    customer_id <span class="type">BIGINT</span>,</span><br><span class="line">    customer_name <span class="type">VARCHAR</span>,</span><br><span class="line">    deep_bid_type <span class="type">BIGINT</span>,</span><br><span class="line">    deep_external_action <span class="type">BIGINT</span>,</span><br><span class="line">    douplus_budget_type <span class="type">BIGINT</span>,</span><br><span class="line">    ecp_app_id <span class="type">BIGINT</span>,</span><br><span class="line">    external_action <span class="type">INT</span>,</span><br><span class="line">    first_industry_id <span class="type">BIGINT</span>,</span><br><span class="line">    first_industry_name <span class="type">VARCHAR</span>,</span><br><span class="line">    group_type <span class="type">BIGINT</span>,</span><br><span class="line">    is_brand_ad_overflow <span class="type">INT</span>,</span><br><span class="line">    is_orange <span class="type">BIGINT</span>,</span><br><span class="line">    is_startup <span class="type">BIGINT</span>,</span><br><span class="line">    landing_type <span class="type">INT</span>,</span><br><span class="line">    marketing_goal <span class="type">BIGINT</span>,</span><br><span class="line">    monitor_ts <span class="type">BIGINT</span>,</span><br><span class="line">    native_type <span class="type">BIGINT</span>,</span><br><span class="line">    package_name <span class="type">VARCHAR</span>,</span><br><span class="line">    page_id <span class="type">BIGINT</span>,</span><br><span class="line">    page_type <span class="type">BIGINT</span>,</span><br><span class="line">    pricing <span class="type">INT</span>,</span><br><span class="line">    pricing_category <span class="type">INT</span>,</span><br><span class="line">    scene_type <span class="type">BIGINT</span>,</span><br><span class="line">    second_industry_id <span class="type">BIGINT</span>,</span><br><span class="line">    second_industry_name <span class="type">VARCHAR</span>,</span><br><span class="line">    site_account_id <span class="type">BIGINT</span>,</span><br><span class="line">    smart_bid_type <span class="type">BIGINT</span>,</span><br><span class="line">    system_origin <span class="type">BIGINT</span>,</span><br><span class="line">    advertiser_id <span class="type">BIGINT</span>,</span><br><span class="line">    ad_id <span class="type">BIGINT</span>,</span><br><span class="line">    ad_record_creator_id <span class="type">BIGINT</span>,</span><br><span class="line">    app_code <span class="type">BIGINT</span>,</span><br><span class="line">    campaign_id <span class="type">BIGINT</span>,</span><br><span class="line">    delivery_mode <span class="type">BIGINT</span>,</span><br><span class="line">    ecp_user_group <span class="type">BIGINT</span>,</span><br><span class="line">    engine_ad_id <span class="type">BIGINT</span>,</span><br><span class="line">    event_time_hour <span class="type">BIGINT</span>,</span><br><span class="line">    local_stat_time_day <span class="type">VARCHAR</span>,</span><br><span class="line">    local_stat_time_hour <span class="type">VARCHAR</span>,</span><br><span class="line">    qianchuan_product_id <span class="type">BIGINT</span>,</span><br><span class="line">    rit_group_type <span class="type">INT</span>,</span><br><span class="line">    stat_time_day <span class="type">VARCHAR</span>,</span><br><span class="line">    stat_time_hour <span class="type">VARCHAR</span>,</span><br><span class="line">    platform_version <span class="type">INT</span>,</span><br><span class="line">    cdp_project_id <span class="type">BIGINT</span>,</span><br><span class="line">    cdp_promotion_id <span class="type">BIGINT</span>,</span><br><span class="line"></span><br><span class="line">    doc_id <span class="type">VARCHAR</span>,</span><br><span class="line">    process_time <span class="type">BIGINT</span>,</span><br><span class="line">    metric_data MAP<span class="operator">&lt;</span><span class="type">VARCHAR</span>, <span class="type">BIGINT</span><span class="operator">&gt;</span>,</span><br><span class="line">    <span class="keyword">PRIMARY</span> KEY (doc_id) <span class="keyword">NOT</span> ENFORCED </span><br><span class="line">)<span class="keyword">with</span>(</span><br><span class="line">    <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka-0.10&#x27;</span>, </span><br><span class="line">    <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;ad_stats_ad_aggregation&#x27;</span>, </span><br><span class="line">    <span class="string">&#x27;properties.cluster&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka_huge_6th&#x27;</span>, </span><br><span class="line">    <span class="string">&#x27;properties.request.timeout.ms&#x27;</span><span class="operator">=</span><span class="string">&#x27;180000&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;json&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;properties.batch.size&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;100000&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;properties.linger.ms&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;5000&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;properties.buffer.memory&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;209715200&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;properties.compression.type&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;gzip&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;parallelism&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;30&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;properties.acks&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;-1&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;sink.partitioner&#x27;</span><span class="operator">=</span><span class="string">&#x27;row-fields-hash&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;sink.partition-fields&#x27;</span><span class="operator">=</span><span class="string">&#x27;doc_id&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;json.unwrapped-filed-names&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;metric_data&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 写入下游</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> sink_table</span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    advertiser_system_origin,</span><br><span class="line">    anchor_id,</span><br><span class="line">    auto_tool_type,</span><br><span class="line">    campaign_type,</span><br><span class="line">    cart_id,</span><br><span class="line">    content_type,</span><br><span class="line">    convert_id,</span><br><span class="line">    convert_type,</span><br><span class="line">    create_channel,</span><br><span class="line">    creative_material_mode,</span><br><span class="line">    customer_id,</span><br><span class="line">    customer_name,</span><br><span class="line">    deep_bid_type,</span><br><span class="line">    deep_external_action,</span><br><span class="line">    douplus_budget_type,</span><br><span class="line">    ecp_app_id,</span><br><span class="line">    external_action,</span><br><span class="line">    first_industry_id,</span><br><span class="line">    first_industry_name,</span><br><span class="line">    group_type,</span><br><span class="line">    is_brand_ad_overflow,</span><br><span class="line">    is_orange,</span><br><span class="line">    is_startup,</span><br><span class="line">    landing_type,</span><br><span class="line">    marketing_goal,</span><br><span class="line">    monitor_ts,</span><br><span class="line">    native_type,</span><br><span class="line">    package_name,</span><br><span class="line">    page_id,</span><br><span class="line">    page_type,</span><br><span class="line">    pricing,</span><br><span class="line">    pricing_category,</span><br><span class="line">    scene_type,</span><br><span class="line">    second_industry_id,</span><br><span class="line">    second_industry_name,</span><br><span class="line">    site_account_id,</span><br><span class="line">    smart_bid_type,</span><br><span class="line">    system_origin,</span><br><span class="line">    advertiser_id,</span><br><span class="line">    ad_id,</span><br><span class="line">    ad_record_creator_id,</span><br><span class="line">    app_code,</span><br><span class="line">    campaign_id,</span><br><span class="line">    delivery_mode,</span><br><span class="line">    ecp_user_group,</span><br><span class="line">    engine_ad_id,</span><br><span class="line">    event_time_hour,</span><br><span class="line">    local_stat_time_day,</span><br><span class="line">    local_stat_time_hour,</span><br><span class="line">    qianchuan_product_id,</span><br><span class="line">    rit_group_type,</span><br><span class="line">    stat_time_day,</span><br><span class="line">    stat_time_hour,</span><br><span class="line">    platform_version,</span><br><span class="line">    cdp_project_id,</span><br><span class="line">    cdp_promotion_id,</span><br><span class="line">    </span><br><span class="line">    doc_id,</span><br><span class="line">    unix_timestamp() <span class="keyword">as</span> process_time,</span><br><span class="line">    metric_data</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    agg_table</span><br><span class="line"><span class="keyword">WHERE</span></span><br><span class="line">    local_stat_time_hour <span class="operator">&gt;=</span> <span class="string">&#x27;2022-01-10 16:00:00&#x27;</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">--延迟监控打点</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> metric_sink(</span><br><span class="line">    type <span class="type">varchar</span>,</span><br><span class="line">    name <span class="type">varchar</span>,</span><br><span class="line">    val <span class="keyword">double</span>,</span><br><span class="line">    tags <span class="type">varchar</span></span><br><span class="line">) <span class="keyword">with</span>(</span><br><span class="line">    <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;metrics&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;metrics-prefix&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;ad.stats.draco_realtime.ad_aggregation.dws_ad_stats_ad_aggregation&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span></span><br><span class="line">    metric_sink</span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    <span class="string">&#x27;TIMER&#x27;</span> <span class="keyword">as</span> type,</span><br><span class="line">    <span class="string">&#x27;latency&#x27;</span> <span class="keyword">as</span> name,</span><br><span class="line">    <span class="built_in">cast</span>(</span><br><span class="line">        if(</span><br><span class="line">            batch_metrics_ts <span class="operator">&gt;</span> <span class="number">0</span> <span class="keyword">and</span> batch_metrics_ts <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">            batch_metrics_ts,</span><br><span class="line">            <span class="number">0</span></span><br><span class="line">        ) <span class="keyword">as</span> <span class="keyword">double</span></span><br><span class="line">    ) <span class="keyword">as</span> val,</span><br><span class="line">    <span class="string">&#x27;&#123;type=adAggBatch&#125;&#x27;</span> <span class="keyword">as</span> tags</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    agg_table</span><br><span class="line"><span class="keyword">where</span></span><br><span class="line">    monitor_ts <span class="operator">&gt;</span> <span class="number">0</span>;</span><br></pre></td></tr></table></figure>












</article><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/10/25/%E8%AF%BE%E7%A8%8B/"><img class="prev-cover" src="/img/beijing.jpg" onerror="onerror=null;src='/img/touxiang.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">课程</div></div></a></div><div class="next-post pull-right"><a href="/2021/10/25/%E5%B7%A5%E5%85%B7%E7%B1%BB/"><img class="next-cover" src="/img/beijing.jpg" onerror="onerror=null;src='/img/touxiang.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">工具类</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">John Doe</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">12</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/zourunxin"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">勤加注释！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BB%84%E4%BC%9A"><span class="toc-text">组会</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#8-28-%E2%80%93-one-hot-%E6%80%BB%E7%BB%93"><span class="toc-text">8.28 – one_hot 总结</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%9C%A8%E6%95%B0%E6%8D%AE%E5%96%82%E5%85%A5%E6%A8%A1%E5%9E%8B%E5%89%8D%E8%BF%9B%E8%A1%8C-one-hot-%E7%BC%96%E7%A0%81%E3%80%82"><span class="toc-text">1. 在数据喂入模型前进行 one_hot 编码。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%9C%A8%E6%95%B0%E6%8D%AE%E4%BB%8E-tfrecord-%E4%B8%AD%E8%AF%BB%E5%87%BA%E6%9D%A5%E5%90%8E%EF%BC%8C%E5%9C%A8-batch-256-%E4%B9%8B%E5%89%8D%EF%BC%8C%E8%BF%9B%E8%A1%8C-one-hot-%E7%BC%96%E7%A0%81"><span class="toc-text">2. 在数据从 tfrecord 中读出来后，在 batch 256 之前，进行 one_hot 编码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%9C%A8%E8%AF%BB-pcap-%E6%96%87%E4%BB%B6%E6%97%B6%EF%BC%8C%E6%96%87%E4%BB%B6%E4%B8%AD%E5%8C%85%E7%9A%84%E5%AD%98%E5%82%A8%E5%8D%95%E4%BD%8D%E6%98%AF-byte%EF%BC%8C%E5%9B%A0%E6%AD%A4%E8%BE%B9%E8%AF%BB%E5%8C%85%E8%BE%B9%E8%BF%9B%E8%A1%8C-one-hot-%E7%BC%96%E7%A0%81%E3%80%82"><span class="toc-text">3. 在读 pcap 文件时，文件中包的存储单位是 byte，因此边读包边进行 one_hot 编码。</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#python"><span class="toc-text">python</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91"><span class="toc-text">项目开发</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#import"><span class="toc-text">import</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#sys-path"><span class="toc-text">sys.path</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#argparse-ArgumentParser"><span class="toc-text">argparse.ArgumentParser()</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9F%A5%E8%AF%86%E7%82%B9"><span class="toc-text">知识点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#virtualenvwrapper"><span class="toc-text">virtualenvwrapper</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Tensorflow"><span class="toc-text">Tensorflow</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95"><span class="toc-text">常用方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-text">基本概念</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9F%A5%E8%AF%86%E7%82%B9-1"><span class="toc-text">知识点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Sequential-%E6%90%AD%E5%BB%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1"><span class="toc-text">Sequential 搭建网络八股</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%AD%E6%AD%A5%E6%B3%95"><span class="toc-text">六步法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%A6%E8%A7%A3"><span class="toc-text">详解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0"><span class="toc-text">实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%B1%BB-class-%E6%90%AD%E5%BB%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1"><span class="toc-text">类 class 搭建网络八股</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%AD%E6%AD%A5%E6%B3%95-1"><span class="toc-text">六步法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%A6%E8%A7%A3-1"><span class="toc-text">详解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0-1"><span class="toc-text">实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E5%8A%9F%E8%83%BD%E6%89%A9%E5%B1%95"><span class="toc-text">神经网络八股功能扩展</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%AD%E6%AD%A5%E6%B3%95-2"><span class="toc-text">六步法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%A6%E8%A7%A3-2"><span class="toc-text">详解</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E6%A8%A1%E5%9E%8B"><span class="toc-text">算法模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#CNN"><span class="toc-text">CNN</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF"><span class="toc-text">卷积</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B1%A0%E5%8C%96"><span class="toc-text">池化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#VGG"><span class="toc-text">VGG</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MobileNets"><span class="toc-text">MobileNets</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ResNet"><span class="toc-text">ResNet</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RNN"><span class="toc-text">RNN</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#LSTM"><span class="toc-text">LSTM</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AD%97%E8%8A%82%E5%AE%9E%E4%B9%A0%EF%BC%882021-07-05-%EF%BC%89"><span class="toc-text">字节实习（2021.07.05 - ）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E6%80%BB%E7%BB%93"><span class="toc-text">问题排查总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%B4%E5%BA%A6%E6%8B%BC%E6%8E%A5%E4%B8%AD%E9%97%B4%E4%BB%B6%E6%9C%8D%E5%8A%A1"><span class="toc-text">维度拼接中间件服务</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%AD%E5%92%8C%E9%9D%9E%E4%B8%AD%E6%9E%84%E9%80%A0-dimQueryRequest-%E7%9A%84%E8%BF%87%E7%A8%8B"><span class="toc-text">中和非中构造 dimQueryRequest 的过程</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ad-%E7%B2%92%E5%BA%A6%E8%81%9A%E5%90%88-flink-%E4%BB%BB%E5%8A%A1-%E2%80%93-dws-ad-stats-ad-aggregation"><span class="toc-text">ad 粒度聚合 flink 任务 – dws_ad_stats_ad_aggregation</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/01/26/%E9%87%91%E8%9E%8D%E6%9C%AF%E8%AF%AD/" title="金融术语">金融术语</a><time datetime="2022-01-26T05:47:08.000Z" title="Created 2022-01-26 13:47:08">2022-01-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/01/23/hello-world/" title="Hello World">Hello World</a><time datetime="2022-01-23T14:49:13.969Z" title="Created 2022-01-23 22:49:13">2022-01-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/01/19/%E7%94%9F%E6%B4%BB%E6%94%BB%E7%95%A5/" title="生活攻略">生活攻略</a><time datetime="2022-01-19T02:39:43.000Z" title="Created 2022-01-19 10:39:43">2022-01-19</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/01/18/%E4%B9%B0%E4%B9%B0%E4%B9%B0%E6%94%BB%E7%95%A5/" title="买买买攻略">买买买攻略</a><time datetime="2022-01-18T14:52:34.000Z" title="Created 2022-01-18 22:52:34">2022-01-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/10/25/%E8%AF%BE%E7%A8%8B/" title="课程">课程</a><time datetime="2021-10-25T05:20:25.000Z" title="Created 2021-10-25 13:20:25">2021-10-25</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By John Doe</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div></div></body></html>